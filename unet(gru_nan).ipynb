{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BPyKhCY_51Zz",
    "outputId": "4c1597f5-a7fd-4d71-e541-52fc06810ead"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_output',\n",
       " 'test_output(without_gru)',\n",
       " 'test_output(gru_nan)',\n",
       " '__pycache__',\n",
       " 'test',\n",
       " 'labels',\n",
       " 'images',\n",
       " 'dataloader.py']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import scipy.ndimage.morphology as morph\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "os.listdir('../test_r_unet/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8xmzATXD6EYM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arguments\n",
    "timesteps = 3\n",
    "batch_size = 4\n",
    "num_epochs = 500\n",
    "input_size = 128\n",
    "num_classes = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "gru_nan = False\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                              transforms.Resize((128, 128), interpolation = 0),\n",
    "#                               transforms.RandomHorizontalFlip(p=0.5),\n",
    "#                               transforms.RandomVerticalFlip(p=0.5),\n",
    "                              transforms.ToTensor()\n",
    "                              ])\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# decive\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QKWrQABp6WbP"
   },
   "outputs": [],
   "source": [
    "# way to the data folders\n",
    "folder_data = \"../test_r_unet/data/images\"\n",
    "folder_mask = \"../test_r_unet/data/labels\"\n",
    "folder_test = \"../test_r_unet/data/test\"\n",
    "\n",
    "file_names = sorted(os.listdir('../test_r_unet/data/images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(object):\n",
    "    label1 = (object==0).float()\n",
    "    label2 = (label1==0).float()\n",
    "    labels = torch.stack([label1, label2], dim=1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g2IQuWm36YiO"
   },
   "outputs": [],
   "source": [
    "class MedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time = timesteps\n",
    "        self.folder_data = folder_data\n",
    "        self.folder_mask = folder_mask\n",
    "        self.file_names = file_names\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_data + '/' + file_names[idx+i])).unsqueeze(0))\n",
    "        gif_data = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(get_labels(transform(Image.open(self.folder_mask + '/' + file_names[idx+i]))).unsqueeze(0))\n",
    "        gif_mask = torch.stack(gif_list).squeeze(dim=2)\n",
    "        #gif_mask = gif_mask[:,:,0,:,:,:]\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            img = Image.open(folder_mask + '/' + file_names[idx+i])\n",
    "            img = img.resize((128, 128), resample=Image.NEAREST)\n",
    "            gif_list.append(to_tensor(morph.distance_transform_edt(np.asarray(img)/255)).unsqueeze(0))\n",
    "        gif_depth = torch.stack(gif_list)\n",
    "        return gif_data, gif_mask, gif_depth\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1\n",
    "    \n",
    "    \n",
    "class TestMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__\n",
    "        self.time = timesteps\n",
    "        self.folder_test = folder_test\n",
    "        self.file_names = file_names\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_test + '/' + file_names[idx+i])).unsqueeze(0))\n",
    "        gif_test = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        return gif_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bSn_QdInV-y2",
    "outputId": "33035b3a-0e3d-4554-f115-4b940e8aa356"
   },
   "outputs": [],
   "source": [
    "dataset = MedData()\n",
    "test_dataset = TestMedData()\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=2,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=1,\n",
    "                         num_workers=2,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ifi9yFmPWJGp"
   },
   "outputs": [],
   "source": [
    "class GruCell(nn.Module):\n",
    "    \n",
    "    def __init__(self, channel):\n",
    "        super(GruCell, self).__init__()\n",
    "        self.conv_relu_for_input = nn.Sequential(nn.Conv2d(in_channels=channel, out_channels=channel, kernel_size=3, stride=1, padding=1),\n",
    "                                                 nn.Conv2d(in_channels=channel, out_channels=channel, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        self.conv_relu_for_hidden = nn.Sequential(nn.Conv2d(in_channels=channel, out_channels=channel, kernel_size=3, stride=1, padding=1),\n",
    "                                                  nn.Conv2d(in_channels=channel, out_channels=channel, kernel_size=3, stride=1, padding=1)\n",
    "                               )\n",
    "        \n",
    "        self.conv_relu_2x_update = nn.Sequential(nn.Conv2d(in_channels=channel+channel, out_channels=channel, kernel_size=3, stride=1, padding=1),\n",
    "                                                 nn.Conv2d(in_channels=channel, out_channels=channel, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        self.conv_relu_2x_reset = nn.Sequential(nn.Conv2d(in_channels=channel+channel, out_channels=channel, kernel_size=3, stride=1, padding=1),\n",
    "                                                nn.Conv2d(in_channels=channel, out_channels=channel, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "     \n",
    "    def forward(self, x, hidden):\n",
    "        input = torch.cat([x, hidden],dim=1)\n",
    "\n",
    "        update_gate = self.conv_relu_2x_update(input)\n",
    "        update_gate = self.sig((update_gate)) ### output after update gate\n",
    "        reset_gate = self.conv_relu_2x_reset(input)\n",
    "        reset_gate = self.sig((reset_gate)) ### output after reset gate\n",
    "        \n",
    "        \n",
    "        memory_gate_for_input = self.conv_relu_for_input(x)\n",
    "        memory_gate_for_hidden = self.conv_relu_for_hidden(hidden)\n",
    "\n",
    "        memory_content = memory_gate_for_input + (reset_gate * memory_gate_for_hidden) ### output for reset gate(affects how the reset gate do work)\n",
    "        memory_content = self.sig(memory_content)\n",
    "\n",
    "        hidden = (update_gate * hidden) + ((1 - update_gate) * memory_content) # torch.ones(input_size, hidden_size)\n",
    "\n",
    "        return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhKh4Y4tWNLo"
   },
   "outputs": [],
   "source": [
    "# create class Gru\n",
    "class Gru(nn.Module):\n",
    "\n",
    "    def __init__(self, channels_size, gru_input_size): # arg for gru layer\n",
    "        super(Gru, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.timesteps = timesteps\n",
    "        self.channels_size = channels_size\n",
    "        self.input_size = gru_input_size\n",
    "        self.hidden_size = (self.batch_size, channels_size, gru_input_size, gru_input_size)\n",
    "        \n",
    "        self.gru_layer0 = GruCell(channels_size)\n",
    "        self.init_hidden = torch.zeros(self.hidden_size).to(device)\n",
    "        self.gru_nan = gru_nan\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_cells = None\n",
    "        x_list = []\n",
    "        if self.gru_nan == False:\n",
    "            try:\n",
    "                x = x.reshape(batch_size, timesteps, self.channels_size, self.input_size, self.input_size)\n",
    "                x = x.permute(1, 0, 2, 3, 4)\n",
    "                for i in range(timesteps):\n",
    "                    if x_cells is None:\n",
    "                        x_cells, hidden = self.gru_layer0(x[i], self.init_hidden)\n",
    "                        x_list.append(x_cells)\n",
    "                    else:\n",
    "                        x_i, hidden = self.gru_layer0(x[i], hidden)\n",
    "                        x_list.append(x_i)\n",
    "                x_cells = torch.stack(x_list)\n",
    "\n",
    "             ##### FOR LAST BATCH\n",
    "            except RuntimeError:\n",
    "                x = x.reshape(1, timesteps, self.channels_size, self.input_size, self.input_size) #last batch is (15), but batch_size = 16, #arg.timesteps = 2 \n",
    "                x = x.permute(1, 0, 2, 3, 4)\n",
    "                hidden_zero = torch.zeros_like(x)\n",
    "                for i in range(timesteps):\n",
    "                    if x_cells is None:\n",
    "                        x_cells, hidden = self.gru_layer0(x[i], hidden_zero[0])\n",
    "                        x_list.append(x_cells)\n",
    "                    else:\n",
    "                        x_i, hidden = self.gru_layer0(x[i], hidden)\n",
    "                        x_list.append(x_i)\n",
    "                x_cells = torch.stack(x_list)\n",
    "             #####\n",
    "        elif self.gru_nan == True:\n",
    "            try:\n",
    "                x = x.reshape(batch_size, timesteps, self.channels_size, self.input_size, self.input_size)\n",
    "                x = x.permute(1, 0, 2, 3, 4)\n",
    "                for i in range(timesteps):\n",
    "                    if x_cells is None:\n",
    "                        x_cells, hidden = self.gru_layer0(x[i], self.init_hidden)\n",
    "                        x_list.append(x_cells)\n",
    "                    else:\n",
    "                        x_i, hidden = self.gru_layer0(x[i], self.init_hidden)\n",
    "                        x_list.append(x_i)\n",
    "                x_cells = torch.stack(x_list)\n",
    "\n",
    "             ##### FOR LAST BATCH\n",
    "            except RuntimeError:\n",
    "                x = x.reshape(1, timesteps, self.channels_size, self.input_size, self.input_size) #last batch is (15), but batch_size = 16, #arg.timesteps = 2 \n",
    "                x = x.permute(1, 0, 2, 3, 4)\n",
    "                hidden_zero = torch.zeros_like(x)\n",
    "                for i in range(timesteps):\n",
    "                    if x_cells is None:\n",
    "                        x_cells, hidden = self.gru_layer0(x[i], hidden_zero[0])\n",
    "                        x_list.append(x_cells)\n",
    "                    else:\n",
    "                        x_i, hidden = self.gru_layer0(x[i], hidden_zero[0])\n",
    "                        x_list.append(x_i)\n",
    "                x_cells = torch.stack(x_list)\n",
    "             #####\n",
    "        else:\n",
    "            print('gru_nan can be only True or False')\n",
    "            quit()\n",
    "        x_cells = x_cells.reshape(-1, self.channels_size, self.input_size, self.input_size)\n",
    "\n",
    "        return x_cells  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5qiHVAwWTcq"
   },
   "outputs": [],
   "source": [
    "class Conv3x3Small(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(Conv3x3Small, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_feat, out_feat,\n",
    "                                             kernel_size=3,\n",
    "                                             stride=1,\n",
    "                                             padding=1),\n",
    "                                   nn.ELU(),\n",
    "                                   nn.Dropout(p=0.2))\n",
    "\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(out_feat, out_feat,\n",
    "                                             kernel_size=3,\n",
    "                                             stride=1,\n",
    "                                             padding=1),\n",
    "                                   nn.ELU())\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "    \n",
    "class Conv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UpConcat(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(UpConcat, self).__init__()\n",
    "\n",
    "        self.up = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "\n",
    "        # self.deconv = nn.ConvTranspose2d(in_feat, out_feat,\n",
    "        #                                  kernel_size=3,\n",
    "        #                                  stride=1,\n",
    "        #                                  dilation=1)\n",
    "\n",
    "        self.deconv = nn.ConvTranspose2d(in_feat,\n",
    "                                         out_feat,\n",
    "                                         kernel_size=2,\n",
    "                                         stride=2)\n",
    "\n",
    "    def forward(self, inputs, down_outputs):\n",
    "        # TODO: Upsampling required after deconv?\n",
    "        # outputs = self.up(inputs)\n",
    "        outputs = self.deconv(inputs)\n",
    "        out = torch.cat([down_outputs, outputs], 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(UpSample, self).__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "        self.deconv = nn.ConvTranspose2d(in_feat,\n",
    "                                         out_feat,\n",
    "                                         kernel_size=2,\n",
    "                                         stride=2)\n",
    "\n",
    "    def forward(self, inputs, down_outputs):\n",
    "        # TODO: Upsampling required after deconv?\n",
    "        outputs = self.up(inputs)\n",
    "        # outputs = self.deconv(inputs)\n",
    "        out = torch.cat([outputs, down_outputs], 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet_All(nn.Module):\n",
    "    def __init__(self, num_channels=1, num_classes=2):\n",
    "        super(UNet_All, self).__init__()\n",
    "        num_feat = [32, 64, 128, 256]\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.down1 = nn.Sequential(DoubleConv(num_channels, num_feat[0]))\n",
    "\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                   Conv(num_feat[0], num_feat[0]),\n",
    "                                   Gru(num_feat[0], gru_input_size=64),\n",
    "                                   Conv(num_feat[0], num_feat[1]))\n",
    "\n",
    "        self.down3 = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                   Conv(num_feat[1], num_feat[1]),\n",
    "                                   Gru(num_feat[1], gru_input_size=32),\n",
    "                                   Conv(num_feat[1], num_feat[2]))\n",
    "\n",
    "        self.bottom = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                    Conv(num_feat[2], num_feat[2]),\n",
    "                                    Gru(num_feat[2], gru_input_size=16),\n",
    "                                    Conv(num_feat[2], num_feat[3]))\n",
    "\n",
    "        self.up1 = UpSample(num_feat[3], num_feat[2])\n",
    "        self.upconv1 = nn.Sequential(Conv(num_feat[3] + num_feat[2], num_feat[2]),\n",
    "                                     Gru(num_feat[2], gru_input_size=32))\n",
    "\n",
    "        self.up2 = UpSample(num_feat[2], num_feat[1])\n",
    "        self.upconv2 = nn.Sequential(Conv(num_feat[2] + num_feat[1], num_feat[1]),\n",
    "                                     Gru(num_feat[1], gru_input_size=64))\n",
    "\n",
    "        self.up3 = UpSample(num_feat[1], num_feat[0])\n",
    "        self.upconv3 = nn.Sequential(Conv(num_feat[1] + num_feat[0], num_feat[0]),\n",
    "                                     nn.BatchNorm2d(num_feat[0]))\n",
    "\n",
    "        self.final = nn.Sequential(nn.Conv2d(num_feat[0], num_classes, kernel_size=1),\n",
    "                                   nn.Sigmoid(),\n",
    "                                   nn.Softmax()\n",
    "                                   )\n",
    "\n",
    "    def forward(self, inputs, return_features=False):\n",
    "        inputs = inputs.reshape(-1, 1, self.input_size, self.input_size)\n",
    "\n",
    "        down1_feat = self.down1(inputs)\n",
    "        down2_feat = self.down2(down1_feat)\n",
    "        down3_feat = self.down3(down2_feat)\n",
    "        bottom_feat = self.bottom(down3_feat)\n",
    "\n",
    "        up1_feat = self.up1(bottom_feat, down3_feat)\n",
    "        up1_feat = self.upconv1(up1_feat)\n",
    "\n",
    "        up2_feat = self.up2(up1_feat, down2_feat)\n",
    "        up2_feat = self.upconv2(up2_feat)\n",
    "        \n",
    "        up3_feat = self.up3(up2_feat, down1_feat)\n",
    "        up3_feat = self.upconv3(up3_feat)\n",
    "\n",
    "        if return_features:\n",
    "            outputs = up3_feat\n",
    "        else:\n",
    "            outputs = self.final(up3_feat)\n",
    "        \n",
    "        \n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNadNWr3WiVH"
   },
   "outputs": [],
   "source": [
    "class UNetDesigner(nn.Module):\n",
    "    def __init__(self, down1, down2, down3, bottom, up1, up2, up3, num_channels=1, num_classes=2):\n",
    "        super(UNetDesigner, self).__init__()\n",
    "        num_feat = [32, 64, 128, 256]\n",
    "        self.input_size = input_size\n",
    "        self.d1 = down1\n",
    "        self.d2 = down2\n",
    "        self.d3 = down3\n",
    "        self.b = bottom\n",
    "        self.u1 = up1\n",
    "        self.u2 = up2\n",
    "        self.u3 = up3\n",
    "        \n",
    "        if self.d1 == False:\n",
    "            self.down1 = nn.Sequential(DoubleConv(num_channels, num_feat[0]))\n",
    "        else:\n",
    "            self.down1 = nn.Sequential(Conv(num_channels, num_feat[0]),\n",
    "                                       Gru(num_feat[0], gru_input_size=128)) # TODO add gru\n",
    "\n",
    "        if self.d2 == False:\n",
    "            self.down2 = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                   Conv3x3Small(num_feat[0], num_feat[1]))\n",
    "        else:\n",
    "            self.down2 = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                   Gru(num_feat[0], gru_input_size=64),\n",
    "                                   Conv(num_feat[0], num_feat[1]))\n",
    "\n",
    "        if self.d3 == False:\n",
    "            self.down3 = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                   Conv3x3Small(num_feat[1], num_feat[2]))\n",
    "        else:\n",
    "            self.down3 = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                   Gru(num_feat[1], gru_input_size=32),\n",
    "                                   Conv(num_feat[1], num_feat[2]))\n",
    "\n",
    "        if self.b == False:\n",
    "            self.bottom = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                    Conv3x3Small(num_feat[2], num_feat[3])\n",
    "                                   )\n",
    "        else:\n",
    "            self.bottom = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                   Gru(num_feat[2], gru_input_size=16),\n",
    "                                   Conv(num_feat[2], num_feat[3]))\n",
    "\n",
    "        self.up1 = UpSample(num_feat[3], num_feat[2])\n",
    "        if self.u1 == False:\n",
    "            self.upconv1 = nn.Sequential(Conv3x3Small(num_feat[3] + num_feat[2], num_feat[2]),\n",
    "                                     nn.BatchNorm2d(num_feat[2]))\n",
    "        else:\n",
    "            self.upconv1 = nn.Sequential(Conv(num_feat[3] + num_feat[2], num_feat[2]),\n",
    "                                     Gru(num_feat[2], gru_input_size=32))\n",
    "\n",
    "        self.up2 = UpSample(num_feat[2], num_feat[1])\n",
    "        if self.u2 == False:\n",
    "            self.upconv2 = nn.Sequential(Conv3x3Small(num_feat[2] + num_feat[1], num_feat[1]),\n",
    "                                     nn.BatchNorm2d(num_feat[1]))\n",
    "        else:\n",
    "            self.upconv2 = nn.Sequential(Conv(num_feat[2] + num_feat[1], num_feat[1]),\n",
    "                                     Gru(num_feat[1], gru_input_size=64))\n",
    "            \n",
    "        self.up3 = UpSample(num_feat[1], num_feat[0])\n",
    "        if self.u3 == False:\n",
    "            self.upconv3 = nn.Sequential(Conv3x3Small(num_feat[1] + num_feat[0], num_feat[0]),\n",
    "                                         nn.BatchNorm2d(num_feat[0]))\n",
    "        else:\n",
    "            self.upconv3 = nn.Sequential(Conv(num_feat[1] + num_feat[0], num_feat[0]),\n",
    "                                         Gru(num_feat[0], gru_input_size=128))\n",
    "\n",
    "        self.final = nn.Sequential(nn.Conv2d(num_feat[0], num_classes, kernel_size=1),\n",
    "                                   nn.Sigmoid(),\n",
    "                                   nn.Softmax()\n",
    "                                   )\n",
    "\n",
    "    def forward(self, inputs, return_features=False):\n",
    "        inputs = inputs.reshape(-1, 1, self.input_size, self.input_size)\n",
    "        # print(inputs.data.size())\n",
    "        down1_feat = self.down1(inputs)\n",
    "        # print(down1_feat.size())\n",
    "        down2_feat = self.down2(down1_feat)\n",
    "        # print(down2_feat.size())\n",
    "        down3_feat = self.down3(down2_feat)\n",
    "        # print(down3_feat.size())\n",
    "        bottom_feat = self.bottom(down3_feat)\n",
    "\n",
    "        # print(bottom_feat.size())\n",
    "        up1_feat = self.up1(bottom_feat, down3_feat)\n",
    "        # print(up1_feat.size())\n",
    "        up1_feat = self.upconv1(up1_feat)\n",
    "        # print(up1_feat.size())\n",
    "        up2_feat = self.up2(up1_feat, down2_feat)\n",
    "        # print(up2_feat.size())\n",
    "        up2_feat = self.upconv2(up2_feat)\n",
    "        # print(up2_feat.size())\n",
    "        up3_feat = self.up3(up2_feat, down1_feat)\n",
    "        # print(up3_feat.size())\n",
    "        up3_feat = self.upconv3(up3_feat)\n",
    "        # print(up3_feat.size())\n",
    "\n",
    "        if return_features:\n",
    "            outputs = up3_feat\n",
    "        else:\n",
    "            outputs = self.final(up3_feat)\n",
    "        \n",
    "        \n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CsCDa52lWmz2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetDesigner(\n",
       "  (down1): Sequential(\n",
       "    (0): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): ELU(alpha=1.0)\n",
       "        (5): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Gru(\n",
       "      (gru_layer0): GruCell(\n",
       "        (conv_relu_for_input): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_for_hidden): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_2x_update): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_2x_reset): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (sig): Sigmoid()\n",
       "        (relu): ReLU()\n",
       "        (tanh): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (2): Conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Gru(\n",
       "      (gru_layer0): GruCell(\n",
       "        (conv_relu_for_input): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_for_hidden): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_2x_update): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_2x_reset): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (sig): Sigmoid()\n",
       "        (relu): ReLU()\n",
       "        (tanh): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (2): Conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bottom): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Gru(\n",
       "      (gru_layer0): GruCell(\n",
       "        (conv_relu_for_input): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_for_hidden): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_2x_update): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_2x_reset): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (sig): Sigmoid()\n",
       "        (relu): ReLU()\n",
       "        (tanh): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (2): Conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): UpSample(\n",
       "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (deconv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (upconv1): Sequential(\n",
       "    (0): Conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Gru(\n",
       "      (gru_layer0): GruCell(\n",
       "        (conv_relu_for_input): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_for_hidden): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_2x_update): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_2x_reset): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (sig): Sigmoid()\n",
       "        (relu): ReLU()\n",
       "        (tanh): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): UpSample(\n",
       "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (deconv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (upconv2): Sequential(\n",
       "    (0): Conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Gru(\n",
       "      (gru_layer0): GruCell(\n",
       "        (conv_relu_for_input): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_for_hidden): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_2x_update): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (conv_relu_2x_reset): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (sig): Sigmoid()\n",
       "        (relu): ReLU()\n",
       "        (tanh): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): UpSample(\n",
       "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (deconv): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (upconv3): Sequential(\n",
       "    (0): Conv3x3Small(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (final): Sequential(\n",
       "    (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Sigmoid()\n",
       "    (2): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNetDesigner(down1=False, down2=True, down3=True, bottom=True, up1=True, up2=True, up3=False)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwJ7yWfZWpHk"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def dice_loss(pred, target, depth, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "    #print(pred.shape, target.shape, depth.shape)\n",
    "    intersection = (pred * target * depth).sum(dim=2).sum(dim=2)\n",
    "    \n",
    "    loss = (1 - ((2. * intersection + smooth) / ((pred*depth).sum(dim=2).sum(dim=2) + (target*depth).sum(dim=2).sum(dim=2) + smooth)))\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "def calc_loss(prediction, target, depth, bce_weight=0.3):\n",
    "    try:\n",
    "        prediction = prediction.reshape(timesteps*batch_size, num_classes, input_size, input_size)\n",
    "        target = target.reshape(timesteps*batch_size, num_classes, input_size, input_size)\n",
    "        depth = depth.reshape(timesteps*batch_size, 1, input_size, input_size)\n",
    "    except RuntimeError:\n",
    "        prediction = prediction.reshape(timesteps*1, num_classes, input_size, input_size) # last_batch = 1\n",
    "        target = target.reshape(timesteps*1, num_classes, input_size, input_size)\n",
    "        depth = depth.reshape(timesteps*1, 1, input_size, input_size)\n",
    "    bce = F.binary_cross_entropy_with_logits(prediction, target)\n",
    "    prediction = F.sigmoid(prediction)\n",
    "    dice = dice_loss(prediction, target, depth)\n",
    "\n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "\n",
    "    return loss # dice\n",
    "\n",
    "def lossy(x, y, d):\n",
    "    return (((x - y)**2).sum(dim=1)*d**2).sum()/(256**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(pred, target):\n",
    "    tanh = nn.Tanh()\n",
    "    pred = tanh(pred)\n",
    "    pred = pred.contiguous() * (-1)\n",
    "    target = target.contiguous() * (-1)  \n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "\n",
    "    loss = (torch.abs(intersection))/(torch.abs(pred.sum(dim=2).sum(dim=2))+torch.abs(target.sum(dim=2).sum(dim=2))-torch.abs(intersection))\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "XM7j3fpLWslk",
    "outputId": "12ed7e3d-0d27-43bc-b98c-82272315942d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/headless/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "/headless/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU:  0.37241828441619873\n",
      "epoch:  1\n",
      "IoU:  0.462411363919576\n",
      "epoch:  2\n",
      "IoU:  0.4938095808029175\n",
      "epoch:  3\n",
      "IoU:  0.5151600440343221\n",
      "epoch:  4\n",
      "IoU:  0.5296818017959595\n",
      "epoch:  5\n",
      "IoU:  0.5427372852961222\n",
      "epoch:  6\n",
      "IoU:  0.5536822477976481\n",
      "epoch:  7\n",
      "IoU:  0.5592036644617716\n",
      "epoch:  8\n",
      "IoU:  0.5619568427403768\n",
      "epoch:  9\n",
      "IoU:  0.5670497020085653\n",
      "epoch:  10\n",
      "IoU:  0.5718270937601725\n",
      "epoch:  11\n",
      "IoU:  0.5759996573130289\n",
      "epoch:  12\n",
      "IoU:  0.5780249834060669\n",
      "epoch:  13\n",
      "IoU:  0.5773695707321167\n",
      "epoch:  14\n",
      "IoU:  0.5792091687520345\n",
      "epoch:  15\n",
      "IoU:  0.5825738112131754\n",
      "epoch:  16\n",
      "IoU:  0.5878854990005493\n",
      "epoch:  17\n",
      "IoU:  0.5848225752512614\n",
      "epoch:  18\n",
      "IoU:  0.5889215071996053\n",
      "epoch:  19\n",
      "IoU:  0.590395967165629\n",
      "epoch:  20\n",
      "IoU:  0.5892771482467651\n",
      "epoch:  21\n",
      "IoU:  0.5918306509653727\n",
      "epoch:  22\n",
      "IoU:  0.592981735865275\n",
      "epoch:  23\n",
      "IoU:  0.595602830251058\n",
      "epoch:  24\n",
      "IoU:  0.5963728825251261\n",
      "epoch:  25\n",
      "IoU:  0.5968693097432455\n",
      "epoch:  26\n",
      "IoU:  0.6020601987838745\n",
      "epoch:  27\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-73658a67c2b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-3e9bd0cb826d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, return_features)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mdown2_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown1_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# print(down2_feat.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mdown3_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown2_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;31m# print(down3_feat.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mbottom_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown3_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6002a6b7ce97>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mx_cells\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                         \u001b[0mx_cells\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru_layer0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                         \u001b[0mx_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cells\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-38dc172af7bb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mupdate_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_relu_2x_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mupdate_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_gate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### output after update gate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mreset_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_relu_2x_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    metric = 0\n",
    "    print('epoch: ', epoch)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        input, label, depth = data\n",
    "        input = input.to(device)\n",
    "        label = label.to(device)\n",
    "        depth = depth.to(device)\n",
    "        output = model(input)\n",
    "        loss = calc_loss(output, label, depth)      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output1 = (output>0.5).float()\n",
    "        metric_out = output1.reshape(-1, 2, 128, 128)\n",
    "        metric_label = label.reshape(-1, 2, 128, 128)\n",
    "        metric += IoU(metric_out, metric_label)\n",
    "    print(\"IoU: \", metric.item() / i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dukv8rkwWw9U"
   },
   "outputs": [],
   "source": [
    "def showw(object):\n",
    "    inp = object.reshape(-1, 1, 128, 128).cpu()\n",
    "    return to_pil(inp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6T9aYwx331wS"
   },
   "outputs": [],
   "source": [
    "showw(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "KFyAhdwfoeY_",
    "outputId": "b9c9f855-1ea8-404c-a453-ee36ff5055dc"
   },
   "outputs": [],
   "source": [
    "output1 = (output>0.3).float()\n",
    "metric_out = output.reshape(-1, 2, 128, 128)\n",
    "showw(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "7UW5u6kovNyS",
    "outputId": "5b4a843c-042b-4e2e-a4d6-47b315544de0"
   },
   "outputs": [],
   "source": [
    "metric_label = label.reshape(-1, 2, 128, 128)\n",
    "showw(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IoU(metric_out, metric_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YybJAEEGvg8a"
   },
   "outputs": [],
   "source": [
    "list_inp = []\n",
    "list_out = []\n",
    "for i, data in enumerate(test_loader):\n",
    "    input = data\n",
    "    input = input.to(device)\n",
    "    test_output = model(input)\n",
    "    list_inp.append(input)\n",
    "    list_out.append(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showw(list_inp[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showw(list_out[0][0])\n",
    "list_out[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 3 \n",
    "for i in range(len(list_out)):\n",
    "    test_out = showw(list_out[i][2][1])\n",
    "    test_out.save(\"../test_r_unet/data/test_output(gru_nan)/frame%d.png\" % index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_out[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[0][1].shape, label.shape)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Medical_test_unet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
