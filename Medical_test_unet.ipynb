{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BPyKhCY_51Zz",
    "outputId": "4c1597f5-a7fd-4d71-e541-52fc06810ead"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_output', '__pycache__', 'test', 'labels', 'images', 'dataloader.py']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import scipy.ndimage.morphology as morph\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "os.listdir('../test_r_unet/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8xmzATXD6EYM"
   },
   "outputs": [],
   "source": [
    "# arguments\n",
    "timesteps = 3\n",
    "batch_size = 4\n",
    "num_epochs = 15\n",
    "input_size = 128\n",
    "num_classes = 2\n",
    "\n",
    "gru_nan = False\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                              transforms.Resize((128, 128), interpolation = 0),\n",
    "                              transforms.ToTensor()\n",
    "                              ])\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# decive\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QKWrQABp6WbP"
   },
   "outputs": [],
   "source": [
    "# way to the data folders\n",
    "folder_data = \"../test_r_unet/data/images\"\n",
    "folder_mask = \"../test_r_unet/data/labels\"\n",
    "folder_test = \"../test_r_unet/data/test\"\n",
    "\n",
    "file_names = sorted(os.listdir('../test_r_unet/data/images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(object):\n",
    "    label1 = (object==0).float()\n",
    "    label2 = (label1==0).float()\n",
    "    labels = torch.stack([label1, label2], dim=1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g2IQuWm36YiO"
   },
   "outputs": [],
   "source": [
    "class MedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time = timesteps\n",
    "        self.folder_data = folder_data\n",
    "        self.folder_mask = folder_mask\n",
    "        self.file_names = file_names\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_data + '/' + file_names[idx+i])).unsqueeze(0))\n",
    "        gif_data = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(get_labels(transform(Image.open(self.folder_mask + '/' + file_names[idx+i]))).unsqueeze(0))\n",
    "        gif_mask = torch.stack(gif_list).squeeze(dim=2)\n",
    "        #gif_mask = gif_mask[:,:,0,:,:,:]\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            img = Image.open(folder_mask + '/' + file_names[idx+i])\n",
    "            img = img.resize((128, 128), resample=Image.NEAREST)\n",
    "            gif_list.append(to_tensor(morph.distance_transform_edt(np.asarray(img)/255)).unsqueeze(0))\n",
    "        gif_depth = torch.stack(gif_list)\n",
    "        return gif_data, gif_mask, gif_depth\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1\n",
    "    \n",
    "    \n",
    "class TestMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__\n",
    "        self.time = timesteps\n",
    "        self.folder_test = folder_test\n",
    "        self.file_names = file_names\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_test + '/' + file_names[idx+i])).unsqueeze(0))\n",
    "        gif_test = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        return gif_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bSn_QdInV-y2",
    "outputId": "33035b3a-0e3d-4554-f115-4b940e8aa356"
   },
   "outputs": [],
   "source": [
    "dataset = MedData()\n",
    "test_dataset = TestMedData()\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=2,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=1,\n",
    "                         num_workers=2,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ifi9yFmPWJGp"
   },
   "outputs": [],
   "source": [
    "class GruCell(nn.Module):\n",
    "    \n",
    "    def __init__(self, channel):\n",
    "        super(GruCell, self).__init__()\n",
    "        self.conv_relu = nn.Sequential(nn.Conv2d(in_channels=channel, out_channels=channel, kernel_size=3, stride=1, padding=1),\n",
    "                                       nn.ELU(),\n",
    "                                       nn.Dropout(p=0.2))\n",
    "        \n",
    "        self.conv_relu_2x = nn.Sequential(nn.Conv2d(in_channels=channel+channel, out_channels=channel, kernel_size=3, stride=1, padding=1),\n",
    "                                          nn.ELU(),\n",
    "                                          nn.Dropout(p=0.2))\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "     \n",
    "    def forward(self, x, hidden):\n",
    "        input = torch.cat([x, hidden],dim=1)\n",
    "\n",
    "        update_gate = self.conv_relu_2x(input)\n",
    "        update_gate = self.sig((update_gate)) ### output after update gate\n",
    "        reset_gate = self.conv_relu_2x(input)\n",
    "        reset_gate = self.sig((reset_gate)) ### output after reset gate\n",
    "        \n",
    "        \n",
    "        memory_gate_for_input = self.conv_relu(x)\n",
    "        memory_gate_for_hidden = self.conv_relu(hidden)\n",
    "\n",
    "        memory_content = memory_gate_for_input + (reset_gate * memory_gate_for_hidden) ### output for reset gate(affects how the reset gate do work)\n",
    "        memory_content = self.relu(memory_content)\n",
    "\n",
    "        hidden = (update_gate * hidden) + ((1 - update_gate) * memory_content) # torch.ones(input_size, hidden_size)\n",
    "\n",
    "        return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhKh4Y4tWNLo"
   },
   "outputs": [],
   "source": [
    "# create class Gru\n",
    "class Gru(nn.Module):\n",
    "\n",
    "    def __init__(self, channels_size, gru_input_size): # arg for gru layer\n",
    "        super(Gru, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.timesteps = timesteps\n",
    "        self.channels_size = channels_size\n",
    "        self.input_size = gru_input_size\n",
    "        self.hidden_size = (self.batch_size, channels_size, gru_input_size, gru_input_size)\n",
    "        \n",
    "        self.gru_layer0 = GruCell(channels_size)\n",
    "        self.init_hidden = torch.zeros(self.hidden_size).to(device)\n",
    "        self.gru_nan = gru_nan\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_cells = None\n",
    "        x_list = []\n",
    "        if self.gru_nan == False:\n",
    "            try:\n",
    "                x = x.reshape(batch_size, timesteps, self.channels_size, self.input_size, self.input_size)\n",
    "                x = x.permute(1, 0, 2, 3, 4)\n",
    "                for i in range(timesteps):\n",
    "                    if x_cells is None:\n",
    "                        x_cells, hidden = self.gru_layer0(x[i], self.init_hidden)\n",
    "                        x_list.append(x_cells)\n",
    "                    else:\n",
    "                        x_i, hidden = self.gru_layer0(x[i], hidden)\n",
    "                        x_list.append(x_i)\n",
    "                x_cells = torch.stack(x_list)\n",
    "\n",
    "             ##### FOR LAST BATCH\n",
    "            except RuntimeError:\n",
    "                x = x.reshape(1, timesteps, self.channels_size, self.input_size, self.input_size) #last batch is (15), but batch_size = 16, #arg.timesteps = 2 \n",
    "                x = x.permute(1, 0, 2, 3, 4)\n",
    "                hidden_zero = torch.zeros_like(x)\n",
    "                for i in range(timesteps):\n",
    "                    if x_cells is None:\n",
    "                        x_cells, hidden = self.gru_layer0(x[i], hidden_zero[0])\n",
    "                        x_list.append(x_cells)\n",
    "                    else:\n",
    "                        x_i, hidden = self.gru_layer0(x[i], hidden)\n",
    "                        x_list.append(x_i)\n",
    "                x_cells = torch.stack(x_list)\n",
    "             #####\n",
    "        elif self.gru_nan == True:\n",
    "            try:\n",
    "                x = x.reshape(batch_size, timesteps, self.channels_size, self.input_size, self.input_size)\n",
    "                x = x.permute(1, 0, 2, 3, 4)\n",
    "                for i in range(timesteps):\n",
    "                    if x_cells is None:\n",
    "                        x_cells, hidden = self.gru_layer0(x[i], self.init_hidden)\n",
    "                        x_list.append(x_cells)\n",
    "                    else:\n",
    "                        x_i, hidden = self.gru_layer0(x[i], self.init_hidden)\n",
    "                        x_list.append(x_i)\n",
    "                x_cells = torch.stack((x_cells, x_i))\n",
    "            ##### FOR LAST BATCH\n",
    "            except RuntimeError:\n",
    "                x = x.reshape(1, timesteps, self.channels_size, self.input_size, self.input_size) #last batch is (15), but batch_size = 16, #arg.timesteps = 2 \n",
    "                x = x.permute(1, 0, 2, 3, 4)\n",
    "                hidden_zero = torch.zeros_like(x)\n",
    "                for i in range(timesteps):\n",
    "                    if x_cells is None:\n",
    "                        x_cells, hidden = self.gru_layer0(x[i], hidden_zero[0])\n",
    "                        x_list.append(x_cells)\n",
    "                    else:\n",
    "                        x_i, hidden = self.gru_layer0(x[i], hidden)\n",
    "                        x_list.append(x_i)\n",
    "                x_cells = torch.stack((x_cells, x_i))\n",
    "        else:\n",
    "            print('gru_nan can be only True or False')\n",
    "            quit()\n",
    "        x_cells = x_cells.reshape(-1, self.channels_size, self.input_size, self.input_size)\n",
    "\n",
    "        return x_cells  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5qiHVAwWTcq"
   },
   "outputs": [],
   "source": [
    "class Conv3x3Small(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(Conv3x3Small, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_feat, out_feat,\n",
    "                                             kernel_size=3,\n",
    "                                             stride=1,\n",
    "                                             padding=1),\n",
    "                                   nn.ELU(),\n",
    "                                   nn.Dropout(p=0.2))\n",
    "\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(out_feat, out_feat,\n",
    "                                             kernel_size=3,\n",
    "                                             stride=1,\n",
    "                                             padding=1),\n",
    "                                   nn.ELU())\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "    \n",
    "class Conv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UpConcat(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(UpConcat, self).__init__()\n",
    "\n",
    "        self.up = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "\n",
    "        # self.deconv = nn.ConvTranspose2d(in_feat, out_feat,\n",
    "        #                                  kernel_size=3,\n",
    "        #                                  stride=1,\n",
    "        #                                  dilation=1)\n",
    "\n",
    "        self.deconv = nn.ConvTranspose2d(in_feat,\n",
    "                                         out_feat,\n",
    "                                         kernel_size=2,\n",
    "                                         stride=2)\n",
    "\n",
    "    def forward(self, inputs, down_outputs):\n",
    "        # TODO: Upsampling required after deconv?\n",
    "        # outputs = self.up(inputs)\n",
    "        outputs = self.deconv(inputs)\n",
    "        out = torch.cat([down_outputs, outputs], 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(UpSample, self).__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "        self.deconv = nn.ConvTranspose2d(in_feat,\n",
    "                                         out_feat,\n",
    "                                         kernel_size=2,\n",
    "                                         stride=2)\n",
    "\n",
    "    def forward(self, inputs, down_outputs):\n",
    "        # TODO: Upsampling required after deconv?\n",
    "        outputs = self.up(inputs)\n",
    "        # outputs = self.deconv(inputs)\n",
    "        out = torch.cat([outputs, down_outputs], 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNadNWr3WiVH"
   },
   "outputs": [],
   "source": [
    "class UNetSmall(nn.Module):\n",
    "    def __init__(self, num_channels=1, num_classes=2):\n",
    "        super(UNetSmall, self).__init__()\n",
    "        num_feat = [32, 64, 128, 256]\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.down1 = nn.Sequential(DoubleConv(num_channels, num_feat[0]))\n",
    "\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                   Gru(num_feat[0], gru_input_size=64),\n",
    "                                   Conv(num_feat[0], num_feat[1]))\n",
    "\n",
    "        self.down3 = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                   Gru(num_feat[1], gru_input_size=32),\n",
    "                                   Conv(num_feat[1], num_feat[2]))\n",
    "\n",
    "        self.bottom = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                   Gru(num_feat[2], gru_input_size=16),\n",
    "                                   Conv(num_feat[2], num_feat[3]))\n",
    "\n",
    "        self.up1 = UpSample(num_feat[3], num_feat[2])\n",
    "        self.upconv1 = nn.Sequential(Conv3x3Small(num_feat[3] + num_feat[2], num_feat[2]),\n",
    "                                     nn.BatchNorm2d(num_feat[2]))\n",
    "\n",
    "        self.up2 = UpSample(num_feat[2], num_feat[1])\n",
    "        self.upconv2 = nn.Sequential(Conv3x3Small(num_feat[2] + num_feat[1], num_feat[1]),\n",
    "                                     nn.BatchNorm2d(num_feat[1]))\n",
    "\n",
    "        self.up3 = UpSample(num_feat[1], num_feat[0])\n",
    "        self.upconv3 = nn.Sequential(Conv3x3Small(num_feat[1] + num_feat[0], num_feat[0]),\n",
    "                                     nn.BatchNorm2d(num_feat[0]))\n",
    "\n",
    "        self.final = nn.Sequential(nn.Conv2d(num_feat[0], num_classes, kernel_size=1),\n",
    "                                   nn.Sigmoid(),\n",
    "                                   nn.Softmax()\n",
    "                                   )\n",
    "\n",
    "    def forward(self, inputs, return_features=False):\n",
    "        inputs = inputs.reshape(-1, 1, self.input_size, self.input_size)\n",
    "        # print(inputs.data.size())\n",
    "        down1_feat = self.down1(inputs)\n",
    "        # print(down1_feat.size())\n",
    "        down2_feat = self.down2(down1_feat)\n",
    "        # print(down2_feat.size())\n",
    "        down3_feat = self.down3(down2_feat)\n",
    "        # print(down3_feat.size())\n",
    "        bottom_feat = self.bottom(down3_feat)\n",
    "\n",
    "        # print(bottom_feat.size())\n",
    "        up1_feat = self.up1(bottom_feat, down3_feat)\n",
    "        # print(up1_feat.size())\n",
    "        up1_feat = self.upconv1(up1_feat)\n",
    "        # print(up1_feat.size())\n",
    "        up2_feat = self.up2(up1_feat, down2_feat)\n",
    "        # print(up2_feat.size())\n",
    "        up2_feat = self.upconv2(up2_feat)\n",
    "        # print(up2_feat.size())\n",
    "        up3_feat = self.up3(up2_feat, down1_feat)\n",
    "        # print(up3_feat.size())\n",
    "        up3_feat = self.upconv3(up3_feat)\n",
    "        # print(up3_feat.size())\n",
    "\n",
    "        if return_features:\n",
    "            outputs = up3_feat\n",
    "        else:\n",
    "            outputs = self.final(up3_feat)\n",
    "        \n",
    "        \n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CsCDa52lWmz2"
   },
   "outputs": [],
   "source": [
    "model = UNetSmall()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwJ7yWfZWpHk"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "def dice_loss(pred, target, depth, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "    #print(pred.shape, target.shape, depth.shape)\n",
    "    intersection = (pred * target * depth).sum(dim=2).sum(dim=2)\n",
    "    \n",
    "    loss = (1 - ((2. * intersection + smooth) / ((pred*depth).sum(dim=2).sum(dim=2) + (target*depth).sum(dim=2).sum(dim=2) + smooth)))\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "def calc_loss(prediction, target, depth, bce_weight=0.3):\n",
    "    try:\n",
    "        prediction = prediction.reshape(timesteps*batch_size, num_classes, input_size, input_size)\n",
    "        target = target.reshape(timesteps*batch_size, num_classes, input_size, input_size)\n",
    "        depth = depth.reshape(timesteps*batch_size, 1, input_size, input_size)\n",
    "    except RuntimeError:\n",
    "        prediction = prediction.reshape(timesteps*1, num_classes, input_size, input_size) # last_batch = 1\n",
    "        target = target.reshape(timesteps*1, num_classes, input_size, input_size)\n",
    "        depth = depth.reshape(timesteps*1, 1, input_size, input_size)\n",
    "    bce = F.binary_cross_entropy_with_logits(prediction, target)\n",
    "    prediction = F.sigmoid(prediction)\n",
    "    dice = dice_loss(prediction, target, depth)\n",
    "\n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def lossy(x, y, d):\n",
    "    return (((x - y)**2).sum(dim=1)*d**2).sum()/(256**2)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "XM7j3fpLWslk",
    "outputId": "12ed7e3d-0d27-43bc-b98c-82272315942d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/headless/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "/headless/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0 avg iou_metric:  0.6495697956730018\n",
      "epoch:  1\n",
      "iter:  0 avg iou_metric:  0.6480397742039871\n",
      "epoch:  2\n",
      "iter:  0 avg iou_metric:  0.6438222285792676\n",
      "epoch:  3\n",
      "iter:  0 avg iou_metric:  0.6400205633113587\n",
      "epoch:  4\n",
      "iter:  0 avg iou_metric:  0.6367398535228558\n",
      "epoch:  5\n",
      "iter:  0 avg iou_metric:  0.6363319334797466\n",
      "epoch:  6\n",
      "iter:  0 avg iou_metric:  0.6348581924919662\n",
      "epoch:  7\n",
      "iter:  0 avg iou_metric:  0.6327062902623517\n",
      "epoch:  8\n",
      "iter:  0 avg iou_metric:  0.6310174540803553\n",
      "epoch:  9\n",
      "iter:  0 avg iou_metric:  0.6325939452090472\n",
      "epoch:  10\n",
      "iter:  0 avg iou_metric:  0.6296789775263218\n",
      "epoch:  11\n",
      "iter:  0 avg iou_metric:  0.6270663408118508\n",
      "epoch:  12\n",
      "iter:  0 avg iou_metric:  0.6257670631703159\n",
      "epoch:  13\n",
      "iter:  0 avg iou_metric:  0.6267895955654263\n",
      "epoch:  14\n",
      "iter:  0 avg iou_metric:  0.623543690781806\n",
      "epoch:  15\n",
      "iter:  0 avg iou_metric:  0.62377516677809\n",
      "epoch:  16\n",
      "iter:  0 avg iou_metric:  0.623658821990094\n",
      "epoch:  17\n",
      "iter:  0 avg iou_metric:  0.6235620223236331\n",
      "epoch:  18\n",
      "iter:  0 avg iou_metric:  0.6223330762605457\n",
      "epoch:  19\n",
      "iter:  0 avg iou_metric:  0.6210103693967182\n",
      "epoch:  20\n",
      "iter:  0 avg iou_metric:  0.6217750965772189\n",
      "epoch:  21\n",
      "iter:  0 avg iou_metric:  0.6204403528649899\n",
      "epoch:  22\n",
      "iter:  0 avg iou_metric:  0.6210344462629817\n",
      "epoch:  23\n",
      "iter:  0 avg iou_metric:  0.619804533973266\n",
      "epoch:  24\n",
      "iter:  0 avg iou_metric:  0.6198778978668809\n",
      "epoch:  25\n",
      "iter:  0 avg iou_metric:  0.6190955338458541\n",
      "epoch:  26\n",
      "iter:  0 avg iou_metric:  0.6191891508872529\n",
      "epoch:  27\n",
      "iter:  0 avg iou_metric:  0.6191031728546337\n",
      "epoch:  28\n",
      "iter:  0 avg iou_metric:  0.6181970592730583\n",
      "epoch:  29\n",
      "iter:  0 avg iou_metric:  0.6179636267384371\n",
      "epoch:  30\n",
      "iter:  0 avg iou_metric:  0.6174257026856879\n",
      "epoch:  31\n",
      "iter:  0 avg iou_metric:  0.6179235722451673\n",
      "epoch:  32\n",
      "iter:  0 avg iou_metric:  0.6168568611394218\n",
      "epoch:  33\n",
      "iter:  0 avg iou_metric:  0.6176010284891136\n",
      "epoch:  34\n",
      "iter:  0 avg iou_metric:  0.6174615994469264\n",
      "epoch:  35\n",
      "iter:  0 avg iou_metric:  0.6163681504897509\n",
      "epoch:  36\n",
      "iter:  0 avg iou_metric:  0.6151125357408137\n",
      "epoch:  37\n",
      "iter:  0 avg iou_metric:  0.6162145299682369\n",
      "epoch:  38\n",
      "iter:  0 avg iou_metric:  0.6166867892739973\n",
      "epoch:  39\n",
      "iter:  0 avg iou_metric:  0.6162392552253637\n",
      "epoch:  40\n",
      "iter:  0 avg iou_metric:  0.6163701413924336\n",
      "epoch:  41\n",
      "iter:  0 avg iou_metric:  0.6151787734459866\n",
      "epoch:  42\n",
      "iter:  0 avg iou_metric:  0.6154690698889287\n",
      "epoch:  43\n",
      "iter:  0 avg iou_metric:  0.6150460168342102\n",
      "epoch:  44\n",
      "iter:  0 avg iou_metric:  0.6140803034740652\n",
      "epoch:  45\n",
      "iter:  0 avg iou_metric:  0.6146710891623304\n",
      "epoch:  46\n",
      "iter:  0 avg iou_metric:  0.614283753454079\n",
      "epoch:  47\n",
      "iter:  0 avg iou_metric:  0.6148537541207308\n",
      "epoch:  48\n",
      "iter:  0 avg iou_metric:  0.6145495395155325\n",
      "epoch:  49\n",
      "iter:  0 avg iou_metric:  0.6138733855153935\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    # for i in range(1):\n",
    "    #     print('*'*20)\n",
    "        print('epoch: ', epoch)\n",
    "        iou_metric = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            input, label, depth = data\n",
    "            input = input.to(device)\n",
    "            label = label.to(device)\n",
    "            depth = depth.to(device)\n",
    "            output = model(input)\n",
    "            loss = calc_loss(output, label, depth)      \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if i % 9 == 0:\n",
    "                print('iter: ', i, 'avg iou_metric: ', loss.item())\n",
    "        # print('-'*20)\n",
    "        # for i in range(1):\n",
    "        #     print('*'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dukv8rkwWw9U"
   },
   "outputs": [],
   "source": [
    "def showw(object):\n",
    "    inp = object.reshape(-1, 1, 128, 128).cpu()\n",
    "    return to_pil(inp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6T9aYwx331wS"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF7E6FC6D0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showw(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "KFyAhdwfoeY_",
    "outputId": "b9c9f855-1ea8-404c-a453-ee36ff5055dc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF761AEB50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showw(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "7UW5u6kovNyS",
    "outputId": "5b4a843c-042b-4e2e-a4d6-47b315544de0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF761AEDD0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showw(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YybJAEEGvg8a"
   },
   "outputs": [],
   "source": [
    "list_inp = []\n",
    "list_out = []\n",
    "for i, data in enumerate(test_loader):\n",
    "    input = data\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    list_inp.append(input)\n",
    "    list_out.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAA9BElEQVR4nAXBBYBjhYEw4LyXF3d3t8m4247urCtrsMvCoqVQoy319kqP67V/jWuB4sV13V1HdtwySSaZuLu7/98HzFdx3GTiJSW8qQgjBO+rMBEcshDlQ/nRnjuJi78Spbh3y2VxmltMkVN/G+i5g5aoriInDqp1FQwNFrdvhBloIIFYekpEMYjW7UVjX67TLmNFggu9/LsmTvcWvUG9hlzk55DGUo8Vnmsg9Br/sgc1X88U2DT47ethiBjIk3DrAzoWziKLwBrWuiLwWz99gB8CiI57nsOMqYRMHpC56xM1XOCGSJ5osRHurb5yL67Xh5+LWvK4IIMNukjqKKIaVxZjdXBW/93xao1sCtRCem42dg9/QZBWf83c8eUq1VcoFVUaeAlXH4hKKY05ZzhYJF4AGXiYdfwNfA7rGmYpOc2DSXXmkOzYnvE7537vGDZkdeRpn3A6Of7PMqlvl5baq1UGTh2MUNYwa32L9Q09s6PNlHwHyhnvOo+fDKZxmsi1lqgn9qV/lhzAL0lKPYubENZ7on2z8SCpHL3WASaJVivHfKxtt6AvXUR85O8HCwDyjchf+jqXa/OZePFuA7v0bO/0Jz9YXjTWRuFHJzEd6m9c+1Ri0GS3X69VJsfx1hExHt2JfRUmMK2+FytTi5h5ZLyd91h+HwJbRmXwy2J690E2H+nkYKYP9/2m+VEc42emm2Kib4S+3+OGxft5htazwX8Qk5EmT9xwCrSWY61jaUZxUyQ546I0OofbMPdPNx/dMjz0VA/+l9X+fzufKd02VJB0+CLyUc7Er7IeOoK+ddlE21qZIpJGHM6OLGnaQfyCmDaFSNNAfwfzREhiSWzlP3m/w39a449l9U13pkV5mHQJH/cimZmQrg72y51PjAP8fLk3gIMED2ubg/D/BxkEez6oRVMYFv7Dwm/j5G92lFrMXU2WULq9fz6BvlAgLX+mdj3o92YmehOEYOnKKtY9inLt8wF6Kna5Q1kVkLSiN5BbaTzKhcx/9q05Ufz2aFfk7FnyHxOxcAZjk4DyFLNk6KbPA/3RYkhUjBf8nZvHjkEbPW72Bj0prnf/oytaOH73YyFL7LIzW+4+uUGnLaLBfSnXqyecldj/kPaGkLAvQWzOBLLrnKxWV/3NPxc9snSg/U5XIp9ZwnIvpzmIbAg5s3fnxi1cf8yKU2KJl0Wf1TwYpjDKWIoMuLPkMDi35d8HsMwXlfZfAJzEzXZoJFJv1/U05pyUmgB0czfjAP5MnnxvsyCnrUp8HfIZaTrxWefe0owIX42vMQf+0bUYJ9Ek+UxoTBBqop1vB6MiE0UYoLpwZXn87Uc21uvEJHNbmYGiQBihR0WaxjPuYHRiXQuWEm6wXHpUVfpJan0gO/ddzMfHWcMRoKbRbf9PGJY2MVMhpLLbFFgTiVvMWTBDMQly5HT/vdT039aJzX6B1nXwbT4wvSQltRMfwnvFbW+1yjgTyColGPDG2/vx0J9lI9VLzkd04FB82d1rr3rrH5sNi6vgSXK65BWwQ+bk5nxGbqeNOaro+5angZ23b24RnQYda3VXs8B632CgyORu3DO1/qmjI3hYDcj4DOgGHn2Ds/TqcjQzNW5hC8+kM5IJjCU8M0MSjDrWSHqcj0URLrKBGAk1zX6tQA3Jn/mZPuBcuRAc8I32iAfPtGwaCyeHUOkMknwVvY9s1fQhaC8+eP/S1TxGlJ5rk7FRVeAevvRGReLCEEpiR0Y+MLV/lUavbcidK/Eo8EQJiarWwCh4fruLSC6Xwj5vaE1dgQjuv9vNFIYIN08OOBWoKTXF44Elj0A0c3MsiZhJmDs5wWKhU+7i3xOCeg81r7JrpDamO0sQobYYtekfR1IP9M8OlcDYygUQl6tqKsQdqiYu1jA16Bvws/FVTx/Gzr3TcLwibEw7iCHf7WOYrEBcR6/PErBpRhzrRV2uKVVyX4Y/UcOF1mrW2BrD92tNRF08C2Oi6OECPJi28eh/nTPK89M44rJ3PSvD7oUilVDXnohZ8jQMzz+m8H1w3V882QMREF/0itpVa1YQxJy1cmufPBPAZJNzpBv7Snlc1OWrnCpRiLespD6/VVRw+eFEaJBuQmEcMEKaYW4jZvJRsSQ1z8P8JN8LmqOmAWx8Z2zAnHZ+35c4oHE1idwtNlxTeR5jz1b3iDJ2S7R4PklvmXTsr9zWTJB+qwVetyCZOf52Dzv2sf8F8j+7Vda1F0qA8Yzpf3Ixa2u5tIhWCRinWnVb/F62wBJZDNFSr76OFzh2qJGf7YHn0tZqKk6CZS/+gYu/KB6oedfqoff9yAMUdkQRg4FE41x82KfH4O6wcRkqjgy5ZWHs2hbRWlf6Brl75feOz6ANbA1LVq2lqFAckK901zOEFD9tKc19toK9ctjpjqdRK8WlvLMXCLHOs28f5JXlmneKQBlrgFfFtHFSleIseCFJorc+dUdpnRbqKXmSqrBtE8Nnz9cq+LQhLQWABketQM1LK0gTt45cAohOB11vjsouHPybFAdWmWj8Ue1G8aEB/lgUBpECS9gFv7BX/zBz+5WgKeo3rGGZHER+2TZIfox/vJzi4rrSCFzELlF6qdnekqCyVHx5B/rSJlw1X1ccWqYw3cY8i7hkCLsyoDGRR87F8AhzxdulICNXHOr+x9zCipwwOl/NvZg5BmxFRsFEAaO9OVkWdUijFOOb/VkCwwyFOQuVRyZW3tI/UoI38ug5yogbib9gNaMkSjjXoMy3WVmbJctCYRpcCoTiBygFKgVy1bInu0+1snB9tDt134AKJrtIjvA3AoO8OGfAXWDaUmtwESY1NVDcNISFHWDtZdRzJm76WsFnE31P1XUjZug5GFLXB5ESSj+9I+YSrEJ4f+wjNo72vSxeM9NBXY2HEqJxYQ9z2zpgLkdEcJiOjPD3qaZaUlXf1AlSHGQe4/ACmRwhKMk8zSbgWe782H1viggnYGcQW4mk9E6Z/tb5smcEv+ByrNtsVfg/6karUbC4p96yspI4UHyro9Z96MF87Q2lUnNh+f8FiolarhrrhT4qOXW4K+bFemFWR1lINXfZpJWGn+C1Nbi5ZbIYzteDRCHRxUVrMh+YSu2OdXO4Ush99rPQas05MWsZICGBIlgnE8pSX6gf7eUYT9/yMsX9VY83Kd0DBvZ0g18HE27nD7YlnnEkPss5w+vR79eVUF8end8SkltCJco6QmbuJCeeldeZmKmHaFR6ZlK/XXZUKzAw+KCxXLpC7YLbg5ohcrYBRtCmP6ziKVWo3LZDvdHZErBKYEtcBN6e64SP38b8rr5cqcM0F6UpxrII2jgHS8cfrK9B+51L8TadV38Y3vVWnqh0dQ/XPb/RFM0pbfQtq484cNbsK39R7kh3FdoRPRu3uI8ZvzgREq825TiO/vNMjnxeokVsoPoSJBvQSMhbABQy69qW+IUCQQzOXh+iPFEJ8Etn+n/zImZgm0fLCKfGZvCrw7HlIryLvx6PHc5gIUuj+bna3TtwqsS//c3rU0LDG7kLhSOkt79+usc37PrBmsHzhTheXXce1WtS9mZLroEDOaAe4cVa//W9kzgjIoZyKy5wD8Xi3ELZ00G6wj2VxZK6g7PiNze/iCuaOYrbCFJtl4s5QM323IszF2vZIco9QFKX1T+6RLx/lAk8QF/tjM7R1CSMVPelgzbAlf4u/H2joekhwfA2eYaWu2+HdUdIMIQaE6ikUwR0cvUoFYdJ3GuPI5UBSuy9p/Dw6medTxf1wlrx0ysjyDYR4395h0D71114jLyKuXl0/r14J7Mt3c4hrwjewOwI1QEBK8+C0CefCKNIsATY5k599Km4jdUL3UNxavGjSz8Uj1wQA1NE/GOMpRk2FwtQpvooctfZlfvrphqXfeXFVtRIlNDEwkEI5PXzLyQT+czj7y6eZJuDSe7veofVycKTGo++poJwSD9udbNjSf1oDQzyQ+4weQkJfxdDJWF6pdHqoApL1qx9Y4NaDt0/9DTJYQhQKXJi3Vuvlp5PiFEXJIRC2e6GvZL15lCBpumBS7W8zi6Cd4ksA2sx9U0gVTL6D68ni+s7U8mS0CM0eAKARRGdbVdyJMuCw19UlPgd5vtVW0vgNN/GhMaoifnK8+Bl0sFU7MoYybQourzvu98qCKAYAg87uPUpdKVZVVB76QPYzM98urtrf9L5SOvt8A0L0KLAICibB94jT1daa01J3nq4Txg1w6eGqwO1ovfmC041lbj00WBxcwVqQ3B790hq7vzDdr5Euausr153/ROuLu9x/sjtfOPQroIpPmiMI5NzkxQibYSzgSgZfZEEcOvNV0lZKJpp0/Qut/+3aRd/8h08irwVWYpwuXEiLbmJ+OqOW7LNt24l6PvraC8174b5wWG0KXD6+eq5eOfeh02XojAKpdvbOy0/TfHtpKcjFqlmYaQr4KrF6ZfrqqCystvHggEhHP6d1OOlcFOKHzURzc2FeD4LjyHL4B3SjEyKZnICY8ul7wc3lxayPIS1i0ZJD7PJ3YnmwoUHOyv50m3PqLxTOv7rrUR8cfbUxoccK9gCouLKSZK+HISnZPeQ1/UTtyP1GVctT8WLVrOflUgpdHQ4Q4lHBpJEAqoItzzlLBIk3YSiwyJjY8lEfnJAqmhshTZeCH6lxi7E6j1Cw+AC0PbpYtm7C+9aaMT43NXBL4OyCz/LH/SeJyJ/fO3Hqj2LeTHyu3kk6k6lbyaKSPFrejEQ6m6ZSwZi+XsEZ02AJuWRK+8NO/bCghgLZ5GbSrRk+T4nFEt80nAkU5qU5WuhXKSu5wGyv83lhOcTIN9oc5M+WmhhZbMch6Txs2J9wxHhWGefaFocqawz7dJd53mwBL1igaZO9A/9UPPORAqp2w/h1ZRF135/ETGpIeA25PBxUY2yB+f4c0xPl6x3PPpiePZSSMDoxUvJLEEck5devdt4gpw1LjiBdbudqw+myZrVSEnpToDyrxrgF3HU4GzVu1jAy+k05Ch5dzhGWhrYeBJwTEvJi9T7IQIFq34Ng+jQ3Xp0uY5qZgawGedGjmJ8857BRMtGKUF0yuB+CtfQOzrv8F03Iqlk73xLqwA3LC6G5r9CptSWlqxcRMDMt6K4HJh6uUMihMSBcdF6xg3KuPeQzcnQBny8x1DGrtbFWhq2ajZ4zY12NgvCCogbYPW+tFWyd5fvmYODNFEQ60LixWhxI0c4gDZhNs+H/WQigs3YtNQYQ9GQEVfW4WyKGTZSbUpVG4HaQW+b7HYVI5e/LfqvJ7MtJJwOv2+lATKy3IUW8FufYhQMYxPNULkT+zbpVw87IACiUejNlcdEtnA+lO4gdrIygLkbXqt98Toln1zsYpDl0+uyQjEAAcZ1T9t+w17E+vZGdECdKoeRWS1jjBUzNcIEvgd5ZWNxTZFF0w6ZKjgKeeGpLpCzGGts5AQFE5gluz+8/7JOrTi6LAYnmPx/+Z+Mzh74j3ogQQkEnFO/WVo4m1NKcKOuWXaRJxD3cFbIXU9275eW4WUKLNugCIDyeg0hGWhqZhEbQ9QNN6uNmRYORt0UAG4oqEMoYAG2U1Eh4coFXQR49q3p9N6uBKXtjauFmi/c+mDgaUyhgW3eQz/NWho0gaqeMuwPc+mg7pCsjePsFTeAAzNQDi2U5qEIZ+mOR66g/nPjPha5CEPfI8Vi0oeh5bJlIj56CglQJBe4EEtcZWl9C/mBOJeUS9hiHWk0moniTa1OXK+5tAwByDr48HQDNhhGjvYggrrit/S/L5O9NUzGmPw87NW/CxbItMEtp8d7miXz3jjxswBlGN6B5S8vBQgoQrwJbrm7Wv9ojhxX2dB5udVlUlPTUZtHmZ9XV2piyZPoLwSs8WWrqOL/cP1NL7PkaUn7Y9bJZq6yxoV7yMKodQNTzNxFUxz+/CEhlK6uQctP36Qo71LsyJ3XIqneRkjJ5ekrU2KwIdJomsXVJ7mr7mUU2JPxLnBwpHUvIXEkgz+07av39plXG4PPL54iS4wdPEKx9NDSaKc+XKU+EmCY2s/QBY0eAEr4kyxE5XZOhs0JpDCa3e7j6EEeQa7AMwfoRnVvukRkRL5xPnHhANuiefJz+SHTOhzKi224seshxRexPgWyM6K8qWqofd2VPYV/djUfn0KQUv/8rWJKt07HRFptCmf16HfbPfWJOapfOhB/vYFceCLYgVlh2VOV4g6nnR5Rm2zFXn+yWEmA3VMfEELhJjtZFVWU5nClliydthpK11GQOn8gFSONSyLjGIobpL7+3CoGppQ+ypM8WLMk1x/dnt2/bcnLXCkTOD4uMkBSwZa6OMWneW2wUVe68dYAOBZCBxNdpZah105A5L9ylhsxFp/u+AE6/XBGhaTBHqfIGdLVW7RDp9IFQJLzVOY0+cONz3on6ZmLuDLONdjtZzUIwZ8/LgySQ7xfAqfw+Ajr/4DBwGpB7cJ3JOuEbH2oND+m/NfB8A1rJt96+/9oxLeGWqxBLDzCTWeWt1NXQSAgEebqIjWWd+XsvlCBHoFvpc28dId5yimgbPcv4msRLaYWQ8s3so3wh86n5C0ucFG8LGD4Jrbke2qsmABJe5vChll6lFHgma7Qo3rWn19Cvp/CbNR1H/ZzCicpebRVxxJxGv/h2BIwvZyfp287CwscJPwH3n16uGcSExiejnShdN7nrTCSiyHzaYiIPBy1aUX616e1fXT9ta0pc4etNm/ES2r4CKca3aW6l9mjk3dvfDXQEJDjik4bueAbMcOrJVIV3EvfsbLFTeGiaEO2zVLWGpNgR8YY9L76n3Q1nQIZ15/b5L7qIDgpNITsTOsP6UC0zE3UZVV5jK7nR6c/l/p7clful1IAXrwJ5/pcZhGTsFypo08M20wk0Pmoqn2VTjuczFB6bdiMudCkPsOz1xC9DX0ARkPgDUbERuAqw441TfYptTB3PPayLIDPBKaa5p5wNZknt5xJFNKcnoZfbx+A6ZepyFHYe7seCEAHAjsCPUDuyyVk5y4ymehG0+IrVzhM4cU8qWo8EmIEVxsbcst6O7NUiLI5S4SdeQbPtUFtmf9+LpjMPHhBpK2vCKP3rne+MaUvk6GhG1j1B5s4i8OwOMFLBVVZgo8ysRXcWMxaoSffUMEFradpONRZh6hMAJe30Vfa19vJa+mlND2Kp/3H/F04te0fCsJNCUpyEt69wm5acLVake5YlysQFOeqdX54PRT0V9PY40N/oz0sdMhW2yaXT0Ri8FBhsPYhEY7PQX/f5juxebNtRZcXbpYWkDmbLYmU737fHXLW+/99OF8fvm1DYHUKD8E1aK8mz8uRbL1gBU7ALx+7/G/h08qSwDJk7J5C6OFFDnJksW4AHamuXWZ8qzT3ajmBHk94d/P/9TUudKzb25w3BmdSssYkx5hnxE/x/BJ0AUnDgAZsKt4YfK08lXX+z1WGZuIX6k5O4CNbiClaQXLt8LVrVvUR7kikT3WgsKooMXaITXrBMywiO/AXDdj5MIXNOsm7A6xvPCvxZmn16I7yu7+/M98uzj0MVikkOLdnK0HTv3MN0hdxlppIgByKSnOrcViqAKa7+90aS9AFvrOeyoKoLkNzxcqpN7wpfS2K0m0J7RsDi3QrvsEwm23CgeKQCbBmnHUNt4nU1e1bPBFWN6NtR+iPeLmAQ5WDJHH3HgSar4vXYu6rDQrxH/rSaqDPTix8R8/iIssKD4mdbJ0Xw/Zbe8mj9ol6l/usZle78ZOJG/EAC9yyeJV8PxNV5wN4vMdz5F4GBfopO8iKnp3fEdaKgjWxbIh7v/Xf0r2FM8J1LLja0YAntVNKFNQUn7F9uysdZ2KCHLAb9bgzdq83mWhv+x7kzNC4eK8QzULkAFO+w51sbOtNti2Slhh4cJKg4AiJeePZqEj17AAE3wCHVd9vLE1wH1ABsgzRskGnSpi7XaFUyA3EBTua5ob2cVpr3I//B7V6/Rv072wUkcVBFnzhSDsz3gp4ck2FvIasiONKqvnfm1bDX0/kK7kAMbFMUhJKwo5itgdlvm/5OEkqw6LIQQzKaMo0WbguWX0/jhvfoF+yJ3ElEMXnNJLg6YMZscHj+Gysj+iJtLbgPWUVol6SyyPb3614kU1hgdF63Penvc9mXXyY46fN+eXAwWJ+VmZdWdy2kZjBXjawaamu7+nt6n66lWXfv5bv4gjzawsQ4gka53tL6NkAhsDANCnneBANnzpT5lAQsM4qVZuut0NbUYXN52+1CVD07f2f0mA1CyT01uL1Gw/wRGXgM23zrx8iEtqCrq4r88Oj5UCmu6Ag5ZMApMoJsDqVxEKsIDGC5WkNk0nlwb7z1ZU+AY8qWmXPLB4XeFybP5dzuH0LgiviURu+IQpvBSoF8UdSlt9R7tDJHASJZ84OBVBpUX0yyC11AqmmJlaUiEg1Ycc9rDaPlpWH7aGdiw27BpN776dO9gF0TcqWrDlHLu6BmLB5fYSVKA2+i6E6vIgtaTIOJAHc2zsTgKXehPR/F52Yk078KLuiuAKXK/Uq7RFvaXHzznkrA5fXphK5CbuDRHI+9e0W4Getht2nSUk3TmhXdl6hjmFc9WKdl4fJXME8jHT1p0ObUOvhLV8bjVuy4kuE5h3VYB6d6Y5mdLWHTjjdOuLHZKltZR+0We5Lg8lnfthXg9zT/HQDwazSr+dFoqWdk12aTu2eoKbw0lWpE5Eoe+L1ILriLwL73VrxfRDvRaG2sxLKQGDJ8X7KnPYyQ1F8dyF+RbBVqNiEDbOTPiV1Ve4/2PIc9hBpymGr3wp3TVqvDXQKW7pQjLtk1gAjzdvyvODH2n+S3E/eeDWPguFRgs/vzl/klNoOSADid7KP0ySXULT9XxNPt3B73ZslSLEpCzi7EwCB1gH8y7rEppY6qMtABArLrPTyU1ZFkXPO+Ysc4ZUjWLrPCQhxtfwZUpfaaiHaKJRHzYjyBK3rnG3Qu4DBwHHNLlmpBuAylcvNW+yu60Jw+ZCPBJ/8rY45hSeEOslQSg7f6Pi1qAcm0szhm3BWbvEmnb0jZag0OcPJxnWIM/jbuMN8vYb/DkF0of1NruU2gpMgSnavCj7SaxhSKxnTpEUK8oKRP9eZDcWOyDfYzRcfTeucB4uIWApeqEHI2DZv1N5z7ccp044P4Zqh5w0qW08YYFtb4eAiU9dMLVDXjGNxPwJPFVcq5S0LxRMLh1EcDTHyGfMZvxxwmgRZWcoqPHmZ/FTBl/Na20AcgXoUdt704KnLgyVOJQmob9z9C9qNutj4IdXRsk3bvNHt6F6/8cdJI9uLmRqrX8nydn8gT+9MeC3XYE/bm6OBIAbo9rja2F81WOnh1i4HIjhTX1OGMgxqGJuLb3AB656A+Tt+W417RwycFvOteQQYHV6InG3CkdwUf6pSBV90vZM9zrFRdHXc8CU/7WlOWXknfHtQWrmLj2v6YEfSbhTHrKUnTJtipU6Wkbey6Zs9C6jLndX9yNNDc3iirrc9RkrN0ZZqRwusBweshkqJ0nlJGBrQtc3Yt42Xe1mZqarCoLEMQUKUrXQRQ9+/BqE2fePoOAgztppSoj9Zdy4TqPY7CA4MqWh6zIVDuDzTvFIKZMgqJZjYRO88w2ZHPvhpwOzmhIKMm3z/mHcNLA5zowahRuji9p1E1Uk0j4SaPrhBRDRFuSBU8376fJIWcgVG0Uup5UMxaLumiqBt1QGX+SJXfpl2Y69Fza44UbdEUVtRpM1IdfwnAGugC8X4O6pBgXKxkbFrT+CsIrnV70aNb24vE+RfBx4mN+XgyawU59h21VoNc2U9/GgpyDr5UtLUHmEQ3GBI9KlsAMacQ62WRt7aBX7djEMKBZo+vb8ZWUqrsKuZnBD4zM92KVKDMeanHNyAgx75p4ikLBixa1S1EjmPeuzfEVhzBMNqfdh818kYXNxLW79N8ERK9Y+Vc6+MZhN6yk7eJCKxDHaV6I2rxPav9x3UfSRaxPWv7xNm4KE1G4zffYELx0frrQ+6nBFk1E3Wb69VBIKWkrk3e2oY0AIv3XsuaN/tHeiO+hA0Ez9qvRnHypJxRD+sEmMrdDowG1AWG2o8831So/z+cC4aUp982foZNcwNkIgEjoD5/hNnRM1n1bDOFYWbNv1s7aNH7rZwU77mdVAunj6D7S+f2iMeF+vT1Hi9yj/vFKcVc3khvJ+FqIUo5fYzIOmrJtIBxwHc3RVy1aLc4DPr+2Sk3gLG52GQ6k+/J+xkiiJeJS2VqOLK7OcUjgi38wCw0QWNVY4/zkDTDHFWbGc3qmUlcVPx90rsN8HC/q/EwuWcJ8BXV02cx2go/6alGMJo4Ida+2FkVgP9iIT2oyT6wbXZ5Fagu6IC+0ikE0KLFWIqMmSriZxPqcL5kKESi1QWkJrEptbVsYJi5zkSKD0Eg//+uY9G2gaNosqwVGzZXp9EISn9G3gkmmy7S8qIYnwWM0SXRg/nfc0xPRlLWmTdzGzL1plYqJ6tHQu0yF1OpI5bDBCb0ptaw2t7aiZwcdoNYmqlEr39YYWLD14QKfGlZruI6XFvY5Ob2a/pYSPYxg0KhOjxGgKrw1M/3sf7c9Vk+E8eOcfEJVyBWGXNUGz8FOF7a8/jJ2DULci2FPBlLyW8Afn3I9edhZ9bYxuEdXjlW2URQ67wBbXu9WWggmjLNdcFqBdwFUELLgdhlih/bOr7yIC2D3WF7/Ip90RaZK4/ONP9fur/+UrFM6FdpgiDZCMuc/KbdPU8zV9IqMzrNfGcoD0ebAszbokjAv4fHhlYc6tgDayIs7nrlReJYuoA/2R476keWEukhdeGSVXv1mc8IKJ0ASsEmv0Z7pd1R2adT/ttEncIOMvVVgTxRRmesc7zB15YLJeMLJQRRSsoms5sdrLHm4DaHVHMmGETir/0oTILw6G498oYKjKGUf97nIQdwBDPHvzF/wZq9WZErS0DXl3cRzHLBn94SG1o15qbyzz6JKjKYAILJe0OGrmaeCAey8LSDnINOPdC0wUGCYR8JDGKoOx5jQ8FkgnOiYPxuS4bvaxvUsjM9TB65REDIxzDJFVVILA5hArEAs67T+U4DUtfD0rulFd+QxQn7u1+ux8stJAgkgzhczv78tc45vyriDe6/iWN6zPwBOLbPbodYVeldp1eYVX9g4kothgvU8O0K+/sjJBBkG0t5AvrztG8FYsG4JtcKzJ0SySgTNavJCQYg9vapUb4aAfXK3zqlTu59fqRuk4I0AbG8itfiXo/uZf/aIWuHd5ywyt389hgcJA5sFO857G6v994M64rVNMzPBYy0Uo+xOR0e2hMeGrDjJ3FtbAkzUTeju3Tv4S1f3kesFzly8F53gdKGR2RQJojOXytoj2SnSHtYpViVfV8Mm6L4OwtjJI4ZHo0ykRHMdCbsR8pP/z6pKH5XOtcx+LI/FjAg2lk4Uq4dZNOjrLidY3uFFKzDy0/0wlbPGznlnzkO0kvEwaRhZTrzm+pmdNy0XUiIX1lG1N+E7hKX+q4KLqB6N34TpCOMOOmrDhh/JCncubIzeeq46n5boeyzT4rbW9erHyK2KtOKMPgX4dTLcW/v6iK1ufiVftF4WEjjmRoVzlQZzjSycSYXRMhtGspzdBNbX8839cbuBg1HuEnb4g2KLBsc4WkYhFr/jQtuOmNy88JuBAiWfSqWu7FwocvA6wcGUWU6aJ/miLkuk5tWegKwCXEzXVBBhquLV3biedoAPy1mr3m6V5e2KJt4FxF3I1wwce8Ur1gGGstRFu5Ngy98s3OdKFKPau6RBVRfDjOm1s03yfzSs6fqr/fuih2tE0vHUeXFrDJofv19xX+G8Ca9uMf4f6UGvL+eE5h1zaUpmxI5I+lXrL+FvWF7Ce95LKPl+Usf/3hPTjZBKTALEZTxz3nVbNK8EQUQxLEy4dkuGB49qkAFwnM5wEgY7OV6+eO+6N6gKiaJgl3+jy3Hg3e3F+fuYZJ1U8m2ji3c+2HmG8hZbzagzdeJgK34WaObX6kDaXFE+L5VVxcEb7wUmeUlltbpC4elmQBCu61x7+Evfgxkpxo1tcYNvYILrIhnDqas/TJLbqcnJ6I0fQoFQPi3c6DhHkgi4pjwOjur4jS8Sc/h5Nf0s/G6PIoiSlMlKGJbLzw7CpqsQr7709gs3BksMqBYn4vgsCxdmzEHEwwjs1DO9bpb/9cEhFVNn3bkK+za2KiYX1fIvXKLTYchPct1WmNDH0fr4CsjbDNBoK5mBxcoe32ECOJTMv1e5vavvFXh/WlpulBWqZc3e0gVCz1Mwr4wN3B6Ym2Y2sC5MSr/6xCS+kTdGzqf1/c47QAJ74juPOfv6wjkYqbophXhiKH8OYzR0GuNH8d6X1mjdnohiWT95XZznp9TPPrL/cS7xg3hpD23UVkuv+e4GRHRKktiJMsdrroysXjwJML7ptcQeef//QprVQXNec2oZTjGVCSRuC6r8eFOPZ0yb0DT7sPGXvIaeG9bp4V3Bt//f2dKMh7oTAaqI6T6jk06vCxr/2BM5ZWvSxbw2PkCPNVXrrj07O30d2zitKqBlHXXz3Gh5bHF2gFntduLfKpwhLKE2qV7YVvNRv7BNroVcy0NBu7QUoRMV3jqhzDX8I6zzQoCueT/XlkZN3KQpQr6TjxGbrhW1AQvBZNpTeML918E00hhpM0bAowtvqIscQ5zK0PWaXbORaDyThNeS5sySdx1ARu1/f4ZcGKFxfPCISeUKziSFHcGZ+L24gQApI45rvOoRaNv3Gjlh4+kS0e6pwRTsWz5NHtIKq02nO4/oLAuyQ+lSQ2rmBIi7d+/2U38NHHP7AlaieiRbtXibnUF0X2oc/k5GyjUmKA8W5rU0fHCRpMrvR0IRuhdeSYxGK82hqOR8b+CXZVEWWr/HqSgUDtyWBLYDFKqSAQgBe+Me+EOJYhwU1gs3i2LnmqCd/ccIN+t98nUm/QmOfmyPyYqHzqsZsi9bSgGXh7aZ/wanX7OAcPzy3aoX2c4n3NsYaqd7yDQr9IxES1/RZGIOr/r8VIQNwnqqYJ1YQYZ42gAHhhDT+1hyTNPrTtnhtZbwxzahBvKQ8RDYkI/ZOaylrrRB6I2+g1A1GvMI9UHZnhMs8otGvMKEol3G0DEBBQTcGA9+cF0e8GHZ2/PRhpX7/lfUZ5e/Zw9skFd01SKNhHoJ+cYLq9rGkhowAsdDOU1g4gY6ptjiKAJcm7m1IFCsutbyzL8UShIahGcDNuvLMGQXGgAJhKTMtoeaoz5zo/CD9k5iCgy8TGLHIcPbkTG/UaMQ3zUlKeJghAd37oC30uCzZtzmaCtQYvK2xQDNbOCzHrXqFtIHK+O9XrU7t3jRsPnnkSWHffa0pIKnX5EKcgIr84SUc13SmMGNiMWiRZachGCkhULrJjiU7JkonVBIdxTUkupTLDq9j7sPnBm2OZINsahzrpTEq0TwM+u5qD+eVOYOs2CaCZ/I27cxKmbeV85K/s7EVGU0hGpEKF8eaXtwIW09a15apkBAHhVgQ5FTLCzAWK+JBCLz9Hfvi/M6E6RLjbRaA4SSFhyd/hhpcoBQlet8RNYGsV5aR8SoOEcx0K1qAG3/RrDFKGjcvTFv4sPCNhJXF3GjBgj8zgI/3dwvkfIkKyqCONjMjDGmcLHrFll5TxjxsdUD5Nz0TK4igUJ63kwmxNomjPxt2kOmEolDfvdQuaMPYgDIJW2QKxBo2NZUGEHawUG0ZKNFFFoOMnAWDPBmJH3KrJwv+vSaxEtIdw6BFWAS4RG5PIMUUe0jVxJttc7g2uyr4QjbnF8fVAeeEMqe2b5mvMQf6ccoOhXg2iZdd+o9rPJpECG1xLdYRhvV6u45KOfaCNDSFQWbdTTcNhNhw0/ISUgcay9IzITDMLiqncRFOsgENsXSavie4lG2okh3R5dK9ZDYcNzKa8KGcrEVYFboZz3dMPa7uQgsztksBtYmmpXfLxQlxNKke6SbXzbHnSjwm7SWJs7worIM2kCLdO3Gq++PS5E7DcfFMShl2EWJGt6FRMEMA74HXItL/OhcvyDHFiJa3ABEMzBHmWgH+nQm4okIqN5fe3hyu9MPrbTIWLBiu0m5Xg2npkXkd/mui/9R92wXe9evSZmJu3J/z9TUpLnRJhwHk31ENgFktaId30EOaceESi3XRE+gLI/yKlG2FQz3VJ17ziJQDojVXyLa20RKwVq64VH16XMDiVkyEV9MgYQya9LtrO1QJJ1bp7TN2yR1L9rLXGuY0Q0EqGCTCTYjGP7LzlJdtKycrSi49CfS8n7hmeKvIY/CoYlyXJpMJSpgFqy6Wlu1cayc3IYRo6B+cggX2ACrxx+pfa7i201qYMXucPyXzFBKFlMR4oZWtbidjp3FGTF1OA20pzmTIEEXJsRHFXQ4yM9T9YbhJ+zoQ/JHAHAGg4biK+y8euDowBmVUzJqqMC1r90qw3cg9OysLwHGcDP6O7GCDjp37r2VkpZ/vCX3UWgi0EKsLICsOfT5f8KoIeSa6U+j1BlEeY3KBu8FCjlR/t4G0uFpUYAtnOriSgA+VES3CWvMa78z1bBp/9gbek5l1TEk4Nj4I9Wyv3D7bQC/diodzGMWQmW/Wzq7iSOJPfV09h98AGWBVV4TvwwDOLplRh9lY0HyMPr8Rn3PjxXEaz+ypDlC5nFI1YAd5RjWcxjhVmJpgTAtBxOU+6QEUnaGaw7pPUn2nNDVyoTfGPyq5rHO678WhUbQj9zGnro18G/zhBf8QbSci7Jq1OWBh1SFtMBzjXC+y5DNFUnv2lbAAVnvpesaawYU0ZG5GXLooPTSfqxBhJD9y2e1yeNENE3JIPhi9QAjKAJ1aCPS3odViRJQzdlsasvluS9P8qFPYqNltC1FVO4Mu+9UXiS3La/fYDmGcHEg8rkClD9KtuMFgLz0/QMC2q3FiYo/oXeJ/haAi3GfrT99gu59FgY3WN14ajYmaIfoIslWFV/PQIN2aHl7LjAoE1utWN0EeB/BqEL2IoJo2Uaw51OdwlCjhN6g8YdQyS4YBXXm6rRXFweazzX5zc2gxCMpEgLXUtpSFRLIfrjKbEoaUOFK7OiO7HcGw/WDAsoJg3XMdi+3CwqZZAiNCD8wutwpUcMjM0Lt82oekdZ+gKoGje3UMMVXcZEiF1rczAVlJ+DLSxM+hGwExZdrEGPFuyWwCMkli7izfsXi+jf7hk7+dlN+X3qq/xA7gwM5hLgBkVO/oZjazMbpIgDr7Wz4rOrqVLgoLj5bHir2SKVNaJ6USRSt4kLgbTx/AEmbkaiSElkRH+Sk75l1Jb/uJsxpfnCsCkFodppVBy13vNRlya44VZ8RD8rG2ayKf0MDCN6dw9txsZG+qwHULkzPYKJkPcKdZ8JmyCsp4I5bP73n95fyx6tndO1xYr4ouErOZfFdOhoPi0dB3BchmprG1BOXLh4UuZteJOFMGbTRmZLYjonvqNlUp9iyVewCXSTTwPBYawqUFHqdtAMFI9Ik9xSnKNaYw2LAo5vhGuC8RQAsVrMR7+zV4ZQy9oe7k71493gHvKYs1oJODe1GW9gUmUIHPV4Mgt59EUWU30VRLq4qCUGLZ9pmCmdRnEuYFkJWONpGCduaVdj12oHGzAF9z5jDVPlJizjUi31bwB5SgLKNJYiVTJ65qno56ai02jZ5HeIEygcgvdSJOCIIbBl0izr8tLfMrFFPgvfZo+D3C4eBGzYQ6N1M5ppTVzhUmuilQP0Wz1W/DiUsF4BBsdtc5J3/Yw+VYBWQzJ2juIN5jy7MLwAAafutSOQ4RwDTbfom44HufHKDX3Oj+lb1fVSC3sXvpDDj6X+rBavmKwra1dHaVEGWTjlPrZt3+8TW3fdx44tvLUg6B4gLoehffFLM3xQjMtt1E4+wsWzgT3dwdpUCIboZX/3AcrxA2kQ/sIX/jwD+nZ/HdRV/YVSrJEFbzEjrcSQHK1FG2NlGl+hT+ZK9YZpiMvLpaJwdDWv1Ax3ANLKZQJlRVzGW8en9i6ZEAifjC1S8+EXZmshaBoXQTTwtx+3wXbD8v4HO217Iy/fU549rUI9UbvW33M9eZKPPZu32OWe/H94Ld15jKu2mjra87alAlKYy5FYTTpa2Eui3KDjbtIV+UUKASBlXYOwcAFMGhQCSOHYN8kqKoyoVpJdIPv0tYB5OhU7CfmVq8o3ODbAVAgepZtpS3yOwXGGOfjgdIiK1aB+UrBX+Vg3Jd1KGQie5OmImGPUQ1M03ly17qfkaYNpN0hDoKM15qsY0g3t1pCXW3asV2PPKTLISpgLhsTQ18v4/KtTr6ly6/O8/M7kA9wXSYDwex6iViyspE/xcXX+LHCdVUFgwTDyMmtriq21rsX/WW9DBrywfHUK8de+WA26riL7miCy3CSh38gJ/PpIu1pQx9Hnx2oBVAgTQrzl1WtfxhUdJm5FngDX2u74YVjq+eBKEMS+v0k8HiPd+K4G4jVgQQ45/bUZrefPRR3twSWtCLLGlQlgDJC3n5FIL8GVuV4T6l4bSFstXvqVsRf5hHhxG+NhdFrn79Xw44EZhL2qfsF59QNXeemFa6OuCNB7BUjxUIrmoPFYbLF2twm02HQc8EH7ZV4mPnOMCJwI+2mGu7Hpe3rGD9pHUYneaiGJdp1pKo8TWL3w+8uDdQ0YaIOTbqWGYQ5oHaKxlcYlouSHyRR6+Fyh1hRqq8ys5uFH9LPWZvOFRaiPZx839lB+n89PTbLZ17LVoJpxG4bOkV11qe1dKjOotYpKyJURmIVlPFgPICrFxa92JSNXJkV9NYod8XFcN4Pgx/TyaGkDGYKnt4zJJrhsyLgO7lfn7XQgGeqq48ZELUuLP8VAcZ3dJvVXl/ydHoBKnah+Dm2fTHzIlofxXtmBjRhMlqqZI2PZgDZg8eRdnip3oUoIonWxUaWtcLiYqOKVXEEk686aIS/xVoIynjPNA1p5L9RdwzhlRiOvNf5FdOY5xGk5ZH7kCyksLz1txXb978BKfzNd1d6YITilUKNfIh+58HEaY0UeYGWL5vLP3hdLehpgio8qkQ8GydS0O1BHdqbIToxHg4f08D2+LBQao4X9iSYJAwRplE5iEvJv+r41D9sbaScW5W43JzKImkAR/RFeN9sfi29n0kn9VTbluXintzcDx/TzcjNaDDvsw62V5mFIrymTl5hnvSEoPkZ8+NfX3Fv0RbORRxCjUDy+oUVGpbenouuo50vb6AQcFj035pWbEXa5HV6ewXbFzdE6dJSRamzRevpz8Dc83+idoWeYJ3sSDnpld0N2fmtRTj+tc1/z706CIaazdFs7pv1kz1EzibxDQBkR/AokqEaWdR0th//nadfh4SRTFUbnYXZ2K6s90rmq7YLY8JiNZf1eZi4+T8Uj/AYqWN1de2eWFqVovBSCoKtnxuDmRtKPgzSirw1i9D/tcNnFVh5TtCKZBrJGL47yaz9rXmfn5KXN3M/CqDUlhsmeih8ORk06wDp1hQgtIziYtZ4XemaWPLxy+mLT/aTwXDMWHetMVT3udzBLndV5jL5HOU5+N2sSGJKM5UYoGOtKLJdauZXxCvrw9UyGZWFTe9+MKi4vOx/LIku1FZJImS4Nqk70l8yBI+Dvz6uaZamtZSIO72ZBN0/T918ZWP3bTriF8DWWCuM4d+hD2QKMmKCFHZ4yuTjfZfY06nNV58d+lcgyFdkByoe7I3AenkfLp5pWnv2awEgaTzV15g3mGgYFsIqipS4eXvTS6/Ny9vWeIkYF+Gs3mS8MCtwLFmaenheKNB+ffwnICPvQGv8hD0RfOiniQC7xs8zCR12iK8aJTI3Qq3vmlqjZpd6pzRKirUHwsIOxcYLV4C7pFbMzQwnRnznKa2WeZDw5XC8225HPm5b3T2fL8ZSatC4LXy2yb0hDkffPxc4XMGs+/KimtPcmr5cdZS1OWbY7OnMX9E86l2KqcYWM2VFKVr5XQoFi7yY1fkm0DFIxY712WkKrZpclMOV8+/24DFcj6K31/Ph7/8L+VwTS1x8c6e1DTFWo5u79AQESW+rPB+7tTtQURNiyoLN0nwrxL04VLANN1xqZggtZSwZ88mmdW6Ajbx1AJn2URDcbOvyeLVxTXGr6zaQGkmHSet+ThZWqrARro4hCiRNTL2zr8NpwI6OrdA2Ou4kgutElA12y5n5JeI7j0zCJ0YdZ4+z4UK5sxECmBmEH3pi0dgJgycQiyj9xnA3A+vnCwK95bBRFK/dZxK8RnqOIHQJxV+8+Su5hbk6ogZPEvVvijPR38Lt5ZdiWRHi3YOhgregXKTsNhfKwJRd69g7zk8GdqSsRPhqfrflXqZh8JpRqXwu9NpoIdfMT9o9N17edCM+/cNOR7gmqOltSikq62qqbWhQsUcZLt7F24NcIhHZoQUhYyo20+refV1JgaVI3N93FRCS2hIy3dEebp185C3P7gl5Z/j1kqJiqMiz7ZefD4X94N8W8b3BFoJbEgT2pXGbWia2Rp5rUvf+pCKPlMaSLdUpDM7/FOauo2oyoE9doGIn11OC0iLoLn5wCfLz8dyPiH5Qns1uF9TuCcrTeFxUxkqhOkgFBLz0RiuR6v32YwQMt5vUVyS8Jqy7391vtTnq75dLOHXC1wY0zVKBH53wW+HftuWotDqWzzSUiiS/2X73FQTj9z0VWraenfuv4Q5T/dX7YqO8AadvX/gO0gTQ8PBiaqNzukV+CYajxIkts+1ZLjP/38NFf+CpaXAC1hTajDbF00CCvkIVFWUfvQgJzx3T5KQeMiH3p9TekHzBrSQY2CrqumsXNB8UY7O7wQBq/mFk1APf5VEKsq9uoKMkPuiRM3OfEuZ6WSwUJUiR53owwKj+8FJfCZF7FyVBihnWckKVV12oDLtZySh/D+jrsqxG4z1kPNl8htsWIqPNiTbzE7wLdw/72Q+dnDKF92NLX6fEyWhGCQN1eJZ4Q14DRjiyCDuwHZGAI87vNN3tyIe1e7Bo7vwaXbklwdfQfnfg0NKEYMnLxfMrpbBSWVdZddesTF5VD4V/ZUVpmQffqzR60VucqiXyohM1fJ2w+9TT4D8657qL9tjyqwRsVGvpltLuVJBcru7b2Ai741KkDsqT5JVS7V69eAL4SbLaKbYo0EXqspCo9ZrwvFCIynCCHSjrnWbphiH0mKc/z3g/18Bjhkg7FqsdlTtF5M2fu22wU52ovfYSOUF1brthf2OuhNc2o8+WycvvuTQfepsxJD7F8eB4GU2TvE15IrLhP+L+LwJcuYdtJAYVeq20t+KhYq/tKABPIloGrLX4tnsKM5mWq+ZI36SCKVWW+rh0FnYOjLfefG7c0VIH/GsvkQAQuyyD95lZe2HkUhrXYLMxs76nvIjmb1QBBSdg8Xpe8aBDVZK09j56OOBe647GeNtMMbdT83vVtfbQ1O3/OsvsaYaFSyvuEwVkAeHKAygUHhKTZUswRuavdeNPeIgo8qzyGaRjJpKXs4qEmUdQLR8gf/PCevodFsxCkyLV2aKDFEG3fnur9fJ+vJ62C3H1FjmZrVp9QHVAYyeXyBJEZUI7hXzkbl9AHNADm7Jr8bqzPydrRa8LqEJz38wtTcMKr8qHY6ifqqluJozphiAscaJ5xsUPNdws8yHYO4rnCHS2Dvvm7T8vUFwoRElGeYBdQy8PsZRxBwVGcwgp0L/pzfefw8+AxVpOhCB3LtSTXkEX4AUBMfxwEz2DdydIGzx3DF6Vexf8Evn72+WXRJ/JnwxuceMiX+/e1Ztlmy1VpYQUBMTBz7ZD082ppsmVZsyKK8aZ3cv63V9WWIU8DPx99s/h59gNS4xqyZLzwNmOjMi+73SDcp5OnKgRKcgvXirXM7LmrAQzWfJY9wSZSQOB9bbsrTQ9LX+2wxbO4vMYOIoQl1xc+6ORC687ZHQ84ubDb42iM6LYyNrJaQrexbyOBc5Bratff9MZWGpYevmCIKItgs+BJXY+tdtOx7/+QBljkb2GXTo2wLJpm7jQ73R+bxyEPY+LkhrSIvi1Kh+k/fA3gTayKwgUS0b9IPWx5UrXuizDsSVLm4x1+ZuDc6lH8FnESk6r7gkjsiLecEnkJOsSuKLEpLeMHvk7D/jknVfcpC/3c0xLSndgKPgjj/hijy8JwwS2Xhr6efGRisSjL9oKOTKw0rvfehwKI4PKsAAzjt/yJ9iTk8aDaW1AyLtVtNJMw7IjqZWeuwq9sALBq3cLycKw4nUcuZ3ljqC+eIbLJxSuHXizp7SV7cZkrKtZph1OHYwKgyBfllX9nfnlO5Y9Z2r+u+rV5Ck9FYtlBnGU4/YTx8fd6QKCX1yMLYb5jddgiw48FXGDfn5eRlkxghN7OvKfbEjMf9FWvtvy78Ztvkmnri3JWySynOf9iS40n1Bx9fJiBPatXyDUcGeJDtXye6oPEn6QEBodRVWEl1d/dxxirqNekK8z5A/LB4dC3JCuNflcOK1a5Mv04dG/0Rvs5zj9v01icR3YQKFnvlOXKhFFl4vuh8ql/cxv6+CZkRVN7Lf8ALn+raecpa2+cTh+kl2A4hj3sMhDC1IekaLR9xtkzhDH1nryR28oTtLbhS7KuOCZ+8gR1sJl1rafg7d+ogf+JqHytgfMn4OeKn4QeYFQP9WDNX3DurT/E7YBxndtHxysk7QK+MeOxlgIiJpHwwi7Ys+mDEcVbJ5rov44hcx6+ybLOlJ4z1zxwPOFbDBE4dSbKdbb9E1822x/skLhS7TUJ99Uu9mYpc9lGJEsjk0xvPme/wwRgN/dMx9+7uTU6Kmno64QI/Y8Xqeg8cwJIjtLi1GTHvPDSpdZK05RgJkedZ2T5Ma0pcuewo3XchOOzVyLYXF7UdmRZboq5SLJI3LjqsmO4KShmEv3eEXTwE9qabs6OWcY6K8JzGTS2sfyHnKTo7S89Xpa5VjG70dom/4/Y2mDjlimcwsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF761B4790>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showw(list_inp[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2994, 0.2759, 0.2791,  ..., 0.2721, 0.2846, 0.4138],\n",
       "         [0.2734, 0.2828, 0.2757,  ..., 0.2718, 0.2710, 0.3225],\n",
       "         [0.2796, 0.2791, 0.2721,  ..., 0.7311, 0.6665, 0.7143],\n",
       "         ...,\n",
       "         [0.2744, 0.2731, 0.2750,  ..., 0.2856, 0.2727, 0.2754],\n",
       "         [0.2814, 0.2817, 0.4608,  ..., 0.2812, 0.2744, 0.2727],\n",
       "         [0.4516, 0.4771, 0.6946,  ..., 0.2752, 0.2810, 0.2974]],\n",
       "\n",
       "        [[0.7006, 0.7241, 0.7209,  ..., 0.7279, 0.7154, 0.5862],\n",
       "         [0.7266, 0.7172, 0.7243,  ..., 0.7282, 0.7290, 0.6775],\n",
       "         [0.7204, 0.7209, 0.7279,  ..., 0.2689, 0.3335, 0.2857],\n",
       "         ...,\n",
       "         [0.7256, 0.7269, 0.7250,  ..., 0.7144, 0.7273, 0.7246],\n",
       "         [0.7186, 0.7183, 0.5392,  ..., 0.7188, 0.7256, 0.7273],\n",
       "         [0.5484, 0.5229, 0.3054,  ..., 0.7248, 0.7190, 0.7026]]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showw(list_out[0][0])\n",
    "list_out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 3 \n",
    "for i in range(len(list_out)):\n",
    "    test_out = showw(list_out[i][2][1])\n",
    "    test_out.save(\"../test_r_unet/data/test_output/frame%d.png\" % index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0.2994, 0.2759, 0.2791,  ..., 0.2721, 0.2846, 0.4138],\n",
       "           [0.2734, 0.2828, 0.2757,  ..., 0.2718, 0.2710, 0.3225],\n",
       "           [0.2796, 0.2791, 0.2721,  ..., 0.7311, 0.6665, 0.7143],\n",
       "           ...,\n",
       "           [0.2744, 0.2731, 0.2750,  ..., 0.2856, 0.2727, 0.2754],\n",
       "           [0.2814, 0.2817, 0.4608,  ..., 0.2812, 0.2744, 0.2727],\n",
       "           [0.4516, 0.4771, 0.6946,  ..., 0.2752, 0.2810, 0.2974]],\n",
       " \n",
       "          [[0.7006, 0.7241, 0.7209,  ..., 0.7279, 0.7154, 0.5862],\n",
       "           [0.7266, 0.7172, 0.7243,  ..., 0.7282, 0.7290, 0.6775],\n",
       "           [0.7204, 0.7209, 0.7279,  ..., 0.2689, 0.3335, 0.2857],\n",
       "           ...,\n",
       "           [0.7256, 0.7269, 0.7250,  ..., 0.7144, 0.7273, 0.7246],\n",
       "           [0.7186, 0.7183, 0.5392,  ..., 0.7188, 0.7256, 0.7273],\n",
       "           [0.5484, 0.5229, 0.3054,  ..., 0.7248, 0.7190, 0.7026]]],\n",
       " \n",
       " \n",
       "         [[[0.3320, 0.2783, 0.2726,  ..., 0.7310, 0.6626, 0.4572],\n",
       "           [0.2963, 0.2817, 0.2745,  ..., 0.3194, 0.2729, 0.2831],\n",
       "           [0.2847, 0.2716, 0.2706,  ..., 0.2918, 0.2752, 0.2833],\n",
       "           ...,\n",
       "           [0.3148, 0.3525, 0.7284,  ..., 0.2816, 0.2736, 0.2723],\n",
       "           [0.2826, 0.2738, 0.3913,  ..., 0.2727, 0.2762, 0.2927],\n",
       "           [0.3074, 0.2781, 0.3356,  ..., 0.2787, 0.2856, 0.4361]],\n",
       " \n",
       "          [[0.6680, 0.7217, 0.7274,  ..., 0.2690, 0.3374, 0.5428],\n",
       "           [0.7037, 0.7183, 0.7255,  ..., 0.6806, 0.7271, 0.7169],\n",
       "           [0.7153, 0.7284, 0.7294,  ..., 0.7082, 0.7248, 0.7167],\n",
       "           ...,\n",
       "           [0.6852, 0.6475, 0.2716,  ..., 0.7184, 0.7264, 0.7277],\n",
       "           [0.7174, 0.7262, 0.6087,  ..., 0.7273, 0.7238, 0.7073],\n",
       "           [0.6926, 0.7219, 0.6644,  ..., 0.7213, 0.7144, 0.5639]]],\n",
       " \n",
       " \n",
       "         [[[0.2998, 0.2801, 0.2795,  ..., 0.2895, 0.2736, 0.3045],\n",
       "           [0.2751, 0.2753, 0.2744,  ..., 0.2739, 0.2712, 0.2766],\n",
       "           [0.2765, 0.2730, 0.2745,  ..., 0.2732, 0.2726, 0.2759],\n",
       "           ...,\n",
       "           [0.2751, 0.2773, 0.2785,  ..., 0.2736, 0.2754, 0.2856],\n",
       "           [0.2956, 0.2758, 0.3105,  ..., 0.2875, 0.2779, 0.3007],\n",
       "           [0.4214, 0.3776, 0.6688,  ..., 0.2731, 0.2741, 0.3199]],\n",
       " \n",
       "          [[0.7002, 0.7199, 0.7205,  ..., 0.7105, 0.7264, 0.6955],\n",
       "           [0.7249, 0.7247, 0.7256,  ..., 0.7261, 0.7288, 0.7234],\n",
       "           [0.7235, 0.7270, 0.7255,  ..., 0.7268, 0.7274, 0.7241],\n",
       "           ...,\n",
       "           [0.7249, 0.7227, 0.7215,  ..., 0.7264, 0.7246, 0.7144],\n",
       "           [0.7044, 0.7242, 0.6895,  ..., 0.7125, 0.7221, 0.6993],\n",
       "           [0.5786, 0.6224, 0.3312,  ..., 0.7269, 0.7259, 0.6801]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3220, 0.2970, 0.2907,  ..., 0.7310, 0.6368, 0.3960],\n",
       "           [0.2785, 0.2828, 0.2727,  ..., 0.5513, 0.2773, 0.2876],\n",
       "           [0.2784, 0.2808, 0.2713,  ..., 0.2778, 0.2741, 0.2783],\n",
       "           ...,\n",
       "           [0.5910, 0.4772, 0.7308,  ..., 0.2750, 0.2712, 0.2728],\n",
       "           [0.2809, 0.2721, 0.3115,  ..., 0.2704, 0.2721, 0.2817],\n",
       "           [0.3120, 0.3113, 0.2983,  ..., 0.2780, 0.3217, 0.3254]],\n",
       " \n",
       "          [[0.6780, 0.7030, 0.7093,  ..., 0.2690, 0.3632, 0.6040],\n",
       "           [0.7215, 0.7172, 0.7273,  ..., 0.4487, 0.7227, 0.7124],\n",
       "           [0.7216, 0.7192, 0.7287,  ..., 0.7222, 0.7259, 0.7217],\n",
       "           ...,\n",
       "           [0.4090, 0.5228, 0.2692,  ..., 0.7250, 0.7288, 0.7272],\n",
       "           [0.7191, 0.7279, 0.6885,  ..., 0.7296, 0.7279, 0.7183],\n",
       "           [0.6880, 0.6887, 0.7017,  ..., 0.7220, 0.6783, 0.6746]]],\n",
       " \n",
       " \n",
       "         [[[0.3177, 0.2705, 0.2776,  ..., 0.3011, 0.3156, 0.4911],\n",
       "           [0.2787, 0.2779, 0.2749,  ..., 0.2706, 0.2722, 0.2948],\n",
       "           [0.2715, 0.2719, 0.2717,  ..., 0.2758, 0.2728, 0.2768],\n",
       "           ...,\n",
       "           [0.3080, 0.2887, 0.2850,  ..., 0.2717, 0.2743, 0.2740],\n",
       "           [0.3062, 0.2763, 0.3341,  ..., 0.2779, 0.2817, 0.3447],\n",
       "           [0.4325, 0.3943, 0.7029,  ..., 0.2750, 0.2874, 0.3377]],\n",
       " \n",
       "          [[0.6823, 0.7295, 0.7224,  ..., 0.6989, 0.6844, 0.5089],\n",
       "           [0.7213, 0.7221, 0.7251,  ..., 0.7294, 0.7278, 0.7052],\n",
       "           [0.7285, 0.7281, 0.7283,  ..., 0.7242, 0.7272, 0.7232],\n",
       "           ...,\n",
       "           [0.6920, 0.7113, 0.7150,  ..., 0.7283, 0.7257, 0.7260],\n",
       "           [0.6938, 0.7237, 0.6659,  ..., 0.7221, 0.7183, 0.6553],\n",
       "           [0.5675, 0.6057, 0.2971,  ..., 0.7250, 0.7126, 0.6623]]],\n",
       " \n",
       " \n",
       "         [[[0.3116, 0.2741, 0.2756,  ..., 0.2730, 0.2709, 0.3087],\n",
       "           [0.2786, 0.2745, 0.2723,  ..., 0.2813, 0.2752, 0.2773],\n",
       "           [0.2801, 0.2853, 0.2728,  ..., 0.3008, 0.2861, 0.2863],\n",
       "           ...,\n",
       "           [0.3111, 0.2769, 0.2755,  ..., 0.2752, 0.2821, 0.2764],\n",
       "           [0.3641, 0.2768, 0.2782,  ..., 0.2748, 0.2806, 0.2907],\n",
       "           [0.4363, 0.2869, 0.2725,  ..., 0.2784, 0.2783, 0.2988]],\n",
       " \n",
       "          [[0.6884, 0.7259, 0.7244,  ..., 0.7270, 0.7291, 0.6913],\n",
       "           [0.7214, 0.7255, 0.7277,  ..., 0.7187, 0.7248, 0.7227],\n",
       "           [0.7199, 0.7147, 0.7272,  ..., 0.6992, 0.7139, 0.7137],\n",
       "           ...,\n",
       "           [0.6889, 0.7231, 0.7245,  ..., 0.7248, 0.7179, 0.7236],\n",
       "           [0.6359, 0.7232, 0.7218,  ..., 0.7252, 0.7194, 0.7093],\n",
       "           [0.5637, 0.7131, 0.7275,  ..., 0.7216, 0.7217, 0.7012]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3325, 0.2866, 0.2872,  ..., 0.2982, 0.3076, 0.4143],\n",
       "           [0.2760, 0.2741, 0.2796,  ..., 0.2736, 0.2721, 0.2843],\n",
       "           [0.2733, 0.2733, 0.2729,  ..., 0.2725, 0.2749, 0.2818],\n",
       "           ...,\n",
       "           [0.2794, 0.2832, 0.3117,  ..., 0.2727, 0.2928, 0.2799],\n",
       "           [0.2848, 0.2799, 0.4876,  ..., 0.7287, 0.6341, 0.4410],\n",
       "           [0.4982, 0.5800, 0.7308,  ..., 0.2848, 0.2987, 0.4401]],\n",
       " \n",
       "          [[0.6675, 0.7134, 0.7128,  ..., 0.7018, 0.6924, 0.5857],\n",
       "           [0.7240, 0.7259, 0.7204,  ..., 0.7264, 0.7279, 0.7157],\n",
       "           [0.7267, 0.7267, 0.7271,  ..., 0.7275, 0.7251, 0.7182],\n",
       "           ...,\n",
       "           [0.7206, 0.7168, 0.6883,  ..., 0.7273, 0.7072, 0.7201],\n",
       "           [0.7152, 0.7201, 0.5124,  ..., 0.2713, 0.3659, 0.5590],\n",
       "           [0.5018, 0.4200, 0.2692,  ..., 0.7152, 0.7013, 0.5599]]],\n",
       " \n",
       " \n",
       "         [[[0.3353, 0.2913, 0.2944,  ..., 0.2758, 0.2731, 0.3290],\n",
       "           [0.2854, 0.2816, 0.2795,  ..., 0.2707, 0.2763, 0.2736],\n",
       "           [0.2813, 0.2795, 0.2753,  ..., 0.2709, 0.2711, 0.2716],\n",
       "           ...,\n",
       "           [0.3054, 0.2883, 0.2828,  ..., 0.2750, 0.2747, 0.2841],\n",
       "           [0.3351, 0.2902, 0.2941,  ..., 0.2754, 0.2847, 0.3373],\n",
       "           [0.3946, 0.2895, 0.2812,  ..., 0.2901, 0.3059, 0.3880]],\n",
       " \n",
       "          [[0.6647, 0.7087, 0.7056,  ..., 0.7242, 0.7269, 0.6710],\n",
       "           [0.7146, 0.7184, 0.7205,  ..., 0.7293, 0.7237, 0.7264],\n",
       "           [0.7187, 0.7205, 0.7247,  ..., 0.7291, 0.7289, 0.7284],\n",
       "           ...,\n",
       "           [0.6946, 0.7117, 0.7172,  ..., 0.7250, 0.7253, 0.7159],\n",
       "           [0.6649, 0.7098, 0.7059,  ..., 0.7246, 0.7153, 0.6627],\n",
       "           [0.6054, 0.7105, 0.7188,  ..., 0.7099, 0.6941, 0.6120]]],\n",
       " \n",
       " \n",
       "         [[[0.3449, 0.2775, 0.2792,  ..., 0.3576, 0.6864, 0.5141],\n",
       "           [0.3044, 0.2748, 0.3005,  ..., 0.2843, 0.3090, 0.3258],\n",
       "           [0.2791, 0.2721, 0.2740,  ..., 0.2793, 0.2857, 0.3141],\n",
       "           ...,\n",
       "           [0.2993, 0.3373, 0.2887,  ..., 0.2713, 0.2715, 0.2721],\n",
       "           [0.3127, 0.2898, 0.2739,  ..., 0.2738, 0.2749, 0.2738],\n",
       "           [0.3524, 0.2821, 0.2861,  ..., 0.2712, 0.2793, 0.3239]],\n",
       " \n",
       "          [[0.6551, 0.7225, 0.7208,  ..., 0.6424, 0.3136, 0.4859],\n",
       "           [0.6956, 0.7252, 0.6995,  ..., 0.7157, 0.6910, 0.6742],\n",
       "           [0.7209, 0.7279, 0.7260,  ..., 0.7207, 0.7143, 0.6859],\n",
       "           ...,\n",
       "           [0.7007, 0.6627, 0.7113,  ..., 0.7287, 0.7285, 0.7279],\n",
       "           [0.6873, 0.7102, 0.7261,  ..., 0.7262, 0.7251, 0.7262],\n",
       "           [0.6476, 0.7179, 0.7139,  ..., 0.7288, 0.7207, 0.6761]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3603, 0.2903, 0.2765,  ..., 0.3011, 0.2776, 0.3696],\n",
       "           [0.3033, 0.2843, 0.2793,  ..., 0.2784, 0.2716, 0.2785],\n",
       "           [0.2876, 0.3060, 0.2780,  ..., 0.2814, 0.2793, 0.2791],\n",
       "           ...,\n",
       "           [0.2866, 0.2736, 0.2776,  ..., 0.2746, 0.2719, 0.2785],\n",
       "           [0.3246, 0.2870, 0.2853,  ..., 0.2725, 0.2741, 0.3438],\n",
       "           [0.4817, 0.3296, 0.2801,  ..., 0.2787, 0.2771, 0.3618]],\n",
       " \n",
       "          [[0.6397, 0.7097, 0.7235,  ..., 0.6989, 0.7224, 0.6304],\n",
       "           [0.6967, 0.7157, 0.7207,  ..., 0.7216, 0.7284, 0.7215],\n",
       "           [0.7124, 0.6940, 0.7220,  ..., 0.7186, 0.7207, 0.7209],\n",
       "           ...,\n",
       "           [0.7134, 0.7264, 0.7224,  ..., 0.7254, 0.7281, 0.7215],\n",
       "           [0.6754, 0.7130, 0.7147,  ..., 0.7275, 0.7259, 0.6562],\n",
       "           [0.5183, 0.6704, 0.7199,  ..., 0.7213, 0.7229, 0.6382]]],\n",
       " \n",
       " \n",
       "         [[[0.3307, 0.2738, 0.2842,  ..., 0.6450, 0.6787, 0.4081],\n",
       "           [0.2878, 0.2742, 0.2755,  ..., 0.2937, 0.3496, 0.3002],\n",
       "           [0.2726, 0.2714, 0.2744,  ..., 0.2734, 0.2981, 0.3564],\n",
       "           ...,\n",
       "           [0.2887, 0.2802, 0.2855,  ..., 0.2746, 0.2740, 0.2817],\n",
       "           [0.3280, 0.2848, 0.2755,  ..., 0.2804, 0.2728, 0.2762],\n",
       "           [0.3522, 0.2791, 0.2768,  ..., 0.2787, 0.2732, 0.3087]],\n",
       " \n",
       "          [[0.6693, 0.7262, 0.7158,  ..., 0.3550, 0.3213, 0.5919],\n",
       "           [0.7122, 0.7258, 0.7245,  ..., 0.7063, 0.6504, 0.6998],\n",
       "           [0.7274, 0.7286, 0.7256,  ..., 0.7266, 0.7019, 0.6436],\n",
       "           ...,\n",
       "           [0.7113, 0.7198, 0.7145,  ..., 0.7254, 0.7260, 0.7183],\n",
       "           [0.6720, 0.7152, 0.7245,  ..., 0.7196, 0.7272, 0.7238],\n",
       "           [0.6478, 0.7209, 0.7232,  ..., 0.7213, 0.7268, 0.6913]]],\n",
       " \n",
       " \n",
       "         [[[0.3403, 0.2965, 0.3503,  ..., 0.2993, 0.7304, 0.7283],\n",
       "           [0.2914, 0.2993, 0.3092,  ..., 0.7311, 0.7311, 0.7279],\n",
       "           [0.2906, 0.2749, 0.2795,  ..., 0.7311, 0.6798, 0.3788],\n",
       "           ...,\n",
       "           [0.2724, 0.2829, 0.2752,  ..., 0.2803, 0.2763, 0.2790],\n",
       "           [0.3281, 0.2907, 0.2751,  ..., 0.2862, 0.2739, 0.2970],\n",
       "           [0.3058, 0.2863, 0.2790,  ..., 0.2809, 0.2842, 0.3960]],\n",
       " \n",
       "          [[0.6597, 0.7035, 0.6497,  ..., 0.7007, 0.2696, 0.2717],\n",
       "           [0.7086, 0.7007, 0.6908,  ..., 0.2689, 0.2689, 0.2721],\n",
       "           [0.7094, 0.7251, 0.7205,  ..., 0.2689, 0.3202, 0.6212],\n",
       "           ...,\n",
       "           [0.7276, 0.7171, 0.7248,  ..., 0.7197, 0.7237, 0.7210],\n",
       "           [0.6719, 0.7093, 0.7249,  ..., 0.7138, 0.7261, 0.7030],\n",
       "           [0.6942, 0.7137, 0.7210,  ..., 0.7191, 0.7158, 0.6040]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3609, 0.2800, 0.2836,  ..., 0.2724, 0.3516, 0.3039],\n",
       "           [0.2810, 0.2748, 0.2750,  ..., 0.2795, 0.2852, 0.2801],\n",
       "           [0.2807, 0.2739, 0.2719,  ..., 0.2756, 0.2729, 0.2742],\n",
       "           ...,\n",
       "           [0.2751, 0.2706, 0.2716,  ..., 0.2808, 0.2725, 0.2972],\n",
       "           [0.2774, 0.2739, 0.2759,  ..., 0.2927, 0.2723, 0.2801],\n",
       "           [0.3044, 0.2917, 0.2723,  ..., 0.2793, 0.2758, 0.2871]],\n",
       " \n",
       "          [[0.6391, 0.7200, 0.7164,  ..., 0.7276, 0.6484, 0.6961],\n",
       "           [0.7190, 0.7252, 0.7250,  ..., 0.7205, 0.7148, 0.7199],\n",
       "           [0.7193, 0.7261, 0.7281,  ..., 0.7244, 0.7271, 0.7258],\n",
       "           ...,\n",
       "           [0.7249, 0.7294, 0.7284,  ..., 0.7192, 0.7275, 0.7028],\n",
       "           [0.7226, 0.7261, 0.7241,  ..., 0.7073, 0.7277, 0.7199],\n",
       "           [0.6956, 0.7083, 0.7277,  ..., 0.7207, 0.7242, 0.7129]]],\n",
       " \n",
       " \n",
       "         [[[0.3160, 0.2986, 0.6411,  ..., 0.2852, 0.5609, 0.5447],\n",
       "           [0.2965, 0.2891, 0.2905,  ..., 0.7310, 0.7307, 0.6704],\n",
       "           [0.2845, 0.2892, 0.2744,  ..., 0.7311, 0.2848, 0.2941],\n",
       "           ...,\n",
       "           [0.2854, 0.2713, 0.2747,  ..., 0.2711, 0.2734, 0.2763],\n",
       "           [0.2879, 0.2724, 0.2738,  ..., 0.2734, 0.2794, 0.2843],\n",
       "           [0.2948, 0.2747, 0.2791,  ..., 0.2736, 0.2771, 0.3561]],\n",
       " \n",
       "          [[0.6840, 0.7014, 0.3589,  ..., 0.7148, 0.4391, 0.4553],\n",
       "           [0.7035, 0.7109, 0.7095,  ..., 0.2690, 0.2693, 0.3296],\n",
       "           [0.7155, 0.7108, 0.7256,  ..., 0.2689, 0.7152, 0.7059],\n",
       "           ...,\n",
       "           [0.7146, 0.7287, 0.7253,  ..., 0.7289, 0.7266, 0.7237],\n",
       "           [0.7121, 0.7276, 0.7262,  ..., 0.7266, 0.7206, 0.7157],\n",
       "           [0.7052, 0.7253, 0.7209,  ..., 0.7264, 0.7229, 0.6439]]],\n",
       " \n",
       " \n",
       "         [[[0.5704, 0.2962, 0.3054,  ..., 0.7310, 0.2758, 0.3097],\n",
       "           [0.2899, 0.2741, 0.2752,  ..., 0.7243, 0.2745, 0.2812],\n",
       "           [0.2826, 0.2794, 0.2900,  ..., 0.3075, 0.3188, 0.2918],\n",
       "           ...,\n",
       "           [0.2841, 0.2848, 0.2758,  ..., 0.2749, 0.2775, 0.2764],\n",
       "           [0.2919, 0.2844, 0.2728,  ..., 0.2711, 0.2728, 0.2730],\n",
       "           [0.3378, 0.3029, 0.2750,  ..., 0.2719, 0.2910, 0.2924]],\n",
       " \n",
       "          [[0.4296, 0.7038, 0.6946,  ..., 0.2690, 0.7242, 0.6903],\n",
       "           [0.7101, 0.7259, 0.7248,  ..., 0.2757, 0.7255, 0.7188],\n",
       "           [0.7174, 0.7206, 0.7100,  ..., 0.6925, 0.6812, 0.7082],\n",
       "           ...,\n",
       "           [0.7159, 0.7152, 0.7242,  ..., 0.7251, 0.7225, 0.7236],\n",
       "           [0.7081, 0.7156, 0.7272,  ..., 0.7289, 0.7272, 0.7270],\n",
       "           [0.6622, 0.6971, 0.7250,  ..., 0.7281, 0.7090, 0.7076]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3638, 0.3059, 0.5239,  ..., 0.2862, 0.5083, 0.6035],\n",
       "           [0.2851, 0.2784, 0.2790,  ..., 0.7309, 0.7304, 0.6344],\n",
       "           [0.3009, 0.2894, 0.2803,  ..., 0.7311, 0.2775, 0.2877],\n",
       "           ...,\n",
       "           [0.2780, 0.2742, 0.2714,  ..., 0.2812, 0.2768, 0.2747],\n",
       "           [0.3103, 0.2795, 0.2744,  ..., 0.2711, 0.2742, 0.3223],\n",
       "           [0.3557, 0.2900, 0.2834,  ..., 0.2735, 0.2839, 0.4011]],\n",
       " \n",
       "          [[0.6362, 0.6941, 0.4761,  ..., 0.7138, 0.4917, 0.3965],\n",
       "           [0.7149, 0.7216, 0.7210,  ..., 0.2691, 0.2696, 0.3656],\n",
       "           [0.6991, 0.7106, 0.7197,  ..., 0.2689, 0.7225, 0.7123],\n",
       "           ...,\n",
       "           [0.7220, 0.7258, 0.7286,  ..., 0.7188, 0.7232, 0.7253],\n",
       "           [0.6897, 0.7205, 0.7256,  ..., 0.7289, 0.7258, 0.6777],\n",
       "           [0.6443, 0.7100, 0.7166,  ..., 0.7265, 0.7161, 0.5989]]],\n",
       " \n",
       " \n",
       "         [[[0.3782, 0.2802, 0.3173,  ..., 0.7304, 0.2745, 0.2907],\n",
       "           [0.2787, 0.2730, 0.2710,  ..., 0.6019, 0.2713, 0.2795],\n",
       "           [0.2776, 0.2735, 0.2752,  ..., 0.2880, 0.2777, 0.2865],\n",
       "           ...,\n",
       "           [0.2750, 0.2704, 0.2716,  ..., 0.2777, 0.2756, 0.2761],\n",
       "           [0.2781, 0.2712, 0.2867,  ..., 0.2783, 0.2731, 0.2767],\n",
       "           [0.3046, 0.2897, 0.2821,  ..., 0.2777, 0.2909, 0.2959]],\n",
       " \n",
       "          [[0.6218, 0.7198, 0.6827,  ..., 0.2696, 0.7255, 0.7093],\n",
       "           [0.7213, 0.7270, 0.7290,  ..., 0.3981, 0.7287, 0.7205],\n",
       "           [0.7224, 0.7265, 0.7248,  ..., 0.7120, 0.7223, 0.7135],\n",
       "           ...,\n",
       "           [0.7250, 0.7296, 0.7284,  ..., 0.7223, 0.7244, 0.7239],\n",
       "           [0.7219, 0.7288, 0.7133,  ..., 0.7217, 0.7269, 0.7233],\n",
       "           [0.6954, 0.7103, 0.7179,  ..., 0.7223, 0.7091, 0.7041]]],\n",
       " \n",
       " \n",
       "         [[[0.2832, 0.2713, 0.2776,  ..., 0.7310, 0.2797, 0.3077],\n",
       "           [0.2736, 0.2738, 0.2714,  ..., 0.7309, 0.2718, 0.2826],\n",
       "           [0.2732, 0.2723, 0.2760,  ..., 0.7141, 0.2805, 0.2796],\n",
       "           ...,\n",
       "           [0.2730, 0.2721, 0.2728,  ..., 0.2730, 0.2702, 0.2737],\n",
       "           [0.2835, 0.2730, 0.2761,  ..., 0.2737, 0.2710, 0.2746],\n",
       "           [0.3012, 0.2803, 0.2740,  ..., 0.2728, 0.2793, 0.2961]],\n",
       " \n",
       "          [[0.7168, 0.7287, 0.7224,  ..., 0.2690, 0.7203, 0.6923],\n",
       "           [0.7264, 0.7262, 0.7286,  ..., 0.2691, 0.7282, 0.7174],\n",
       "           [0.7268, 0.7277, 0.7240,  ..., 0.2859, 0.7195, 0.7204],\n",
       "           ...,\n",
       "           [0.7270, 0.7279, 0.7272,  ..., 0.7270, 0.7298, 0.7263],\n",
       "           [0.7165, 0.7270, 0.7239,  ..., 0.7263, 0.7290, 0.7254],\n",
       "           [0.6988, 0.7197, 0.7260,  ..., 0.7272, 0.7207, 0.7039]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3677, 0.2762, 0.2739,  ..., 0.6006, 0.2707, 0.2898],\n",
       "           [0.2745, 0.2723, 0.2735,  ..., 0.3124, 0.2715, 0.2768],\n",
       "           [0.2752, 0.2724, 0.2740,  ..., 0.2737, 0.2787, 0.2806],\n",
       "           ...,\n",
       "           [0.2723, 0.2736, 0.2713,  ..., 0.2751, 0.2713, 0.2715],\n",
       "           [0.2811, 0.2727, 0.2764,  ..., 0.2704, 0.2711, 0.2751],\n",
       "           [0.2957, 0.2806, 0.2753,  ..., 0.2792, 0.2763, 0.3106]],\n",
       " \n",
       "          [[0.6323, 0.7238, 0.7261,  ..., 0.3994, 0.7293, 0.7102],\n",
       "           [0.7255, 0.7277, 0.7265,  ..., 0.6876, 0.7285, 0.7232],\n",
       "           [0.7248, 0.7276, 0.7260,  ..., 0.7263, 0.7213, 0.7194],\n",
       "           ...,\n",
       "           [0.7277, 0.7264, 0.7287,  ..., 0.7249, 0.7287, 0.7285],\n",
       "           [0.7189, 0.7273, 0.7236,  ..., 0.7296, 0.7289, 0.7249],\n",
       "           [0.7043, 0.7194, 0.7247,  ..., 0.7208, 0.7237, 0.6894]]],\n",
       " \n",
       " \n",
       "         [[[0.2960, 0.2764, 0.2798,  ..., 0.6884, 0.2712, 0.2742],\n",
       "           [0.2770, 0.2771, 0.2783,  ..., 0.4742, 0.2722, 0.2732],\n",
       "           [0.2724, 0.2742, 0.2935,  ..., 0.3903, 0.3033, 0.2832],\n",
       "           ...,\n",
       "           [0.2719, 0.2709, 0.2724,  ..., 0.2718, 0.2708, 0.2730],\n",
       "           [0.2754, 0.2723, 0.2722,  ..., 0.2710, 0.2708, 0.2728],\n",
       "           [0.2895, 0.2735, 0.2719,  ..., 0.2717, 0.2738, 0.2948]],\n",
       " \n",
       "          [[0.7040, 0.7236, 0.7202,  ..., 0.3116, 0.7288, 0.7258],\n",
       "           [0.7230, 0.7229, 0.7217,  ..., 0.5258, 0.7278, 0.7268],\n",
       "           [0.7276, 0.7258, 0.7065,  ..., 0.6097, 0.6967, 0.7168],\n",
       "           ...,\n",
       "           [0.7281, 0.7291, 0.7276,  ..., 0.7282, 0.7292, 0.7270],\n",
       "           [0.7246, 0.7277, 0.7278,  ..., 0.7290, 0.7292, 0.7272],\n",
       "           [0.7105, 0.7265, 0.7281,  ..., 0.7283, 0.7262, 0.7052]]],\n",
       " \n",
       " \n",
       "         [[[0.2918, 0.2717, 0.2732,  ..., 0.2760, 0.2755, 0.3747],\n",
       "           [0.2732, 0.2752, 0.2720,  ..., 0.2819, 0.2739, 0.2853],\n",
       "           [0.2754, 0.2795, 0.2765,  ..., 0.2702, 0.2729, 0.2824],\n",
       "           ...,\n",
       "           [0.2760, 0.2733, 0.2714,  ..., 0.2699, 0.2711, 0.2729],\n",
       "           [0.2775, 0.2708, 0.2708,  ..., 0.2707, 0.2717, 0.2747],\n",
       "           [0.2918, 0.2774, 0.2729,  ..., 0.2722, 0.2748, 0.2944]],\n",
       " \n",
       "          [[0.7082, 0.7283, 0.7268,  ..., 0.7240, 0.7245, 0.6253],\n",
       "           [0.7268, 0.7248, 0.7280,  ..., 0.7181, 0.7261, 0.7147],\n",
       "           [0.7246, 0.7205, 0.7235,  ..., 0.7298, 0.7271, 0.7176],\n",
       "           ...,\n",
       "           [0.7240, 0.7267, 0.7286,  ..., 0.7301, 0.7289, 0.7271],\n",
       "           [0.7225, 0.7292, 0.7292,  ..., 0.7293, 0.7283, 0.7253],\n",
       "           [0.7082, 0.7226, 0.7271,  ..., 0.7278, 0.7252, 0.7056]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.2835, 0.2729, 0.2744,  ..., 0.6833, 0.2780, 0.2995],\n",
       "           [0.2744, 0.2732, 0.2723,  ..., 0.4193, 0.2739, 0.2801],\n",
       "           [0.2839, 0.2768, 0.2747,  ..., 0.2748, 0.2727, 0.2787],\n",
       "           ...,\n",
       "           [0.2769, 0.2721, 0.2707,  ..., 0.2757, 0.2702, 0.2718],\n",
       "           [0.2801, 0.2749, 0.2727,  ..., 0.2733, 0.2703, 0.2714],\n",
       "           [0.2924, 0.2850, 0.2763,  ..., 0.2761, 0.2754, 0.3097]],\n",
       " \n",
       "          [[0.7165, 0.7271, 0.7256,  ..., 0.3167, 0.7220, 0.7005],\n",
       "           [0.7256, 0.7268, 0.7277,  ..., 0.5807, 0.7261, 0.7199],\n",
       "           [0.7161, 0.7232, 0.7253,  ..., 0.7252, 0.7273, 0.7213],\n",
       "           ...,\n",
       "           [0.7231, 0.7279, 0.7293,  ..., 0.7243, 0.7298, 0.7282],\n",
       "           [0.7199, 0.7251, 0.7273,  ..., 0.7267, 0.7297, 0.7286],\n",
       "           [0.7076, 0.7150, 0.7237,  ..., 0.7239, 0.7246, 0.6903]]],\n",
       " \n",
       " \n",
       "         [[[0.2880, 0.2842, 0.2806,  ..., 0.2858, 0.2740, 0.2997],\n",
       "           [0.2790, 0.2810, 0.2705,  ..., 0.2751, 0.2722, 0.2772],\n",
       "           [0.2778, 0.2834, 0.2746,  ..., 0.2713, 0.2756, 0.2758],\n",
       "           ...,\n",
       "           [0.2759, 0.2756, 0.2710,  ..., 0.2727, 0.2699, 0.2719],\n",
       "           [0.2774, 0.2758, 0.2735,  ..., 0.2713, 0.2708, 0.2751],\n",
       "           [0.2982, 0.2761, 0.2740,  ..., 0.2737, 0.2717, 0.2760]],\n",
       " \n",
       "          [[0.7120, 0.7158, 0.7194,  ..., 0.7142, 0.7260, 0.7003],\n",
       "           [0.7210, 0.7190, 0.7295,  ..., 0.7249, 0.7278, 0.7228],\n",
       "           [0.7222, 0.7166, 0.7254,  ..., 0.7287, 0.7244, 0.7242],\n",
       "           ...,\n",
       "           [0.7241, 0.7244, 0.7290,  ..., 0.7273, 0.7301, 0.7281],\n",
       "           [0.7226, 0.7242, 0.7265,  ..., 0.7287, 0.7292, 0.7249],\n",
       "           [0.7018, 0.7239, 0.7260,  ..., 0.7263, 0.7283, 0.7240]]],\n",
       " \n",
       " \n",
       "         [[[0.2886, 0.2721, 0.3739,  ..., 0.2886, 0.3013, 0.3978],\n",
       "           [0.2716, 0.2713, 0.6862,  ..., 0.2804, 0.3258, 0.5589],\n",
       "           [0.2838, 0.2781, 0.7310,  ..., 0.2739, 0.2772, 0.3602],\n",
       "           ...,\n",
       "           [0.2724, 0.2731, 0.2741,  ..., 0.2719, 0.2713, 0.2738],\n",
       "           [0.2720, 0.2769, 0.2714,  ..., 0.2726, 0.2715, 0.2785],\n",
       "           [0.2831, 0.2903, 0.2780,  ..., 0.2707, 0.2726, 0.2928]],\n",
       " \n",
       "          [[0.7114, 0.7279, 0.6261,  ..., 0.7114, 0.6987, 0.6022],\n",
       "           [0.7284, 0.7287, 0.3138,  ..., 0.7196, 0.6742, 0.4411],\n",
       "           [0.7162, 0.7219, 0.2690,  ..., 0.7261, 0.7228, 0.6398],\n",
       "           ...,\n",
       "           [0.7276, 0.7269, 0.7259,  ..., 0.7281, 0.7287, 0.7262],\n",
       "           [0.7280, 0.7231, 0.7286,  ..., 0.7274, 0.7285, 0.7215],\n",
       "           [0.7169, 0.7097, 0.7220,  ..., 0.7293, 0.7274, 0.7072]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3489, 0.2773, 0.2821,  ..., 0.2732, 0.2746, 0.3361],\n",
       "           [0.2794, 0.2760, 0.2734,  ..., 0.2719, 0.2729, 0.2877],\n",
       "           [0.2904, 0.2890, 0.2791,  ..., 0.2738, 0.2774, 0.2754],\n",
       "           ...,\n",
       "           [0.2782, 0.2771, 0.2757,  ..., 0.2708, 0.2707, 0.2755],\n",
       "           [0.2747, 0.2714, 0.2720,  ..., 0.2722, 0.2734, 0.2771],\n",
       "           [0.3133, 0.2812, 0.2775,  ..., 0.2892, 0.2906, 0.3030]],\n",
       " \n",
       "          [[0.6511, 0.7227, 0.7179,  ..., 0.7268, 0.7254, 0.6639],\n",
       "           [0.7206, 0.7240, 0.7266,  ..., 0.7281, 0.7271, 0.7123],\n",
       "           [0.7096, 0.7110, 0.7209,  ..., 0.7262, 0.7226, 0.7246],\n",
       "           ...,\n",
       "           [0.7218, 0.7229, 0.7243,  ..., 0.7292, 0.7293, 0.7245],\n",
       "           [0.7253, 0.7286, 0.7280,  ..., 0.7278, 0.7266, 0.7229],\n",
       "           [0.6867, 0.7188, 0.7225,  ..., 0.7108, 0.7094, 0.6970]]],\n",
       " \n",
       " \n",
       "         [[[0.3013, 0.2705, 0.3247,  ..., 0.3240, 0.5518, 0.6345],\n",
       "           [0.2801, 0.2707, 0.7108,  ..., 0.2741, 0.3506, 0.5903],\n",
       "           [0.2917, 0.2797, 0.7310,  ..., 0.2813, 0.5027, 0.7110],\n",
       "           ...,\n",
       "           [0.2799, 0.2716, 0.2774,  ..., 0.2737, 0.2720, 0.2734],\n",
       "           [0.2785, 0.2775, 0.2802,  ..., 0.2819, 0.2738, 0.2997],\n",
       "           [0.3290, 0.2829, 0.2744,  ..., 0.2713, 0.2761, 0.3131]],\n",
       " \n",
       "          [[0.6987, 0.7295, 0.6753,  ..., 0.6760, 0.4482, 0.3655],\n",
       "           [0.7199, 0.7293, 0.2892,  ..., 0.7259, 0.6494, 0.4097],\n",
       "           [0.7083, 0.7203, 0.2690,  ..., 0.7187, 0.4973, 0.2890],\n",
       "           ...,\n",
       "           [0.7201, 0.7284, 0.7226,  ..., 0.7263, 0.7280, 0.7266],\n",
       "           [0.7215, 0.7225, 0.7198,  ..., 0.7181, 0.7262, 0.7003],\n",
       "           [0.6710, 0.7171, 0.7256,  ..., 0.7287, 0.7239, 0.6869]]],\n",
       " \n",
       " \n",
       "         [[[0.2863, 0.2719, 0.7150,  ..., 0.2788, 0.2746, 0.3271],\n",
       "           [0.2729, 0.2709, 0.7310,  ..., 0.2807, 0.2786, 0.3071],\n",
       "           [0.2932, 0.2844, 0.7311,  ..., 0.2737, 0.2761, 0.3108],\n",
       "           ...,\n",
       "           [0.2750, 0.2812, 0.2790,  ..., 0.2707, 0.2722, 0.2729],\n",
       "           [0.2758, 0.2940, 0.2760,  ..., 0.2745, 0.2734, 0.2718],\n",
       "           [0.2959, 0.3215, 0.2849,  ..., 0.2803, 0.2776, 0.3098]],\n",
       " \n",
       "          [[0.7137, 0.7281, 0.2850,  ..., 0.7212, 0.7254, 0.6729],\n",
       "           [0.7271, 0.7291, 0.2690,  ..., 0.7193, 0.7214, 0.6929],\n",
       "           [0.7068, 0.7156, 0.2689,  ..., 0.7263, 0.7239, 0.6892],\n",
       "           ...,\n",
       "           [0.7250, 0.7188, 0.7210,  ..., 0.7293, 0.7278, 0.7271],\n",
       "           [0.7242, 0.7060, 0.7240,  ..., 0.7255, 0.7266, 0.7282],\n",
       "           [0.7041, 0.6785, 0.7151,  ..., 0.7197, 0.7224, 0.6902]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.2853, 0.2805, 0.3019,  ..., 0.3196, 0.4894, 0.5921],\n",
       "           [0.2748, 0.2724, 0.3702,  ..., 0.2891, 0.3702, 0.6599],\n",
       "           [0.2819, 0.2824, 0.7270,  ..., 0.2762, 0.3150, 0.6366],\n",
       "           ...,\n",
       "           [0.2859, 0.2720, 0.2743,  ..., 0.2742, 0.2757, 0.2763],\n",
       "           [0.2767, 0.2765, 0.2740,  ..., 0.2845, 0.2803, 0.2867],\n",
       "           [0.2981, 0.2880, 0.2809,  ..., 0.2797, 0.2841, 0.3263]],\n",
       " \n",
       "          [[0.7147, 0.7195, 0.6981,  ..., 0.6804, 0.5106, 0.4079],\n",
       "           [0.7252, 0.7276, 0.6298,  ..., 0.7109, 0.6298, 0.3401],\n",
       "           [0.7181, 0.7176, 0.2730,  ..., 0.7238, 0.6850, 0.3634],\n",
       "           ...,\n",
       "           [0.7141, 0.7280, 0.7257,  ..., 0.7258, 0.7243, 0.7237],\n",
       "           [0.7233, 0.7235, 0.7260,  ..., 0.7155, 0.7197, 0.7133],\n",
       "           [0.7019, 0.7120, 0.7191,  ..., 0.7203, 0.7159, 0.6737]]],\n",
       " \n",
       " \n",
       "         [[[0.3027, 0.2844, 0.7214,  ..., 0.2729, 0.2733, 0.3031],\n",
       "           [0.2838, 0.2771, 0.7310,  ..., 0.2708, 0.2720, 0.2775],\n",
       "           [0.2793, 0.2754, 0.7310,  ..., 0.2747, 0.2764, 0.2840],\n",
       "           ...,\n",
       "           [0.2765, 0.3148, 0.2749,  ..., 0.2723, 0.2719, 0.2833],\n",
       "           [0.2768, 0.2741, 0.2714,  ..., 0.2721, 0.2715, 0.2835],\n",
       "           [0.6178, 0.3247, 0.2829,  ..., 0.2735, 0.2746, 0.3379]],\n",
       " \n",
       "          [[0.6973, 0.7156, 0.2786,  ..., 0.7271, 0.7267, 0.6969],\n",
       "           [0.7162, 0.7229, 0.2690,  ..., 0.7292, 0.7280, 0.7225],\n",
       "           [0.7207, 0.7246, 0.2690,  ..., 0.7253, 0.7236, 0.7160],\n",
       "           ...,\n",
       "           [0.7235, 0.6852, 0.7251,  ..., 0.7277, 0.7281, 0.7167],\n",
       "           [0.7232, 0.7259, 0.7286,  ..., 0.7279, 0.7285, 0.7165],\n",
       "           [0.3822, 0.6753, 0.7171,  ..., 0.7265, 0.7254, 0.6621]]],\n",
       " \n",
       " \n",
       "         [[[0.2871, 0.2739, 0.6686,  ..., 0.4020, 0.3640, 0.4877],\n",
       "           [0.2844, 0.2780, 0.4056,  ..., 0.2897, 0.2767, 0.3004],\n",
       "           [0.2785, 0.2754, 0.4713,  ..., 0.2797, 0.2886, 0.2758],\n",
       "           ...,\n",
       "           [0.2732, 0.2774, 0.2741,  ..., 0.2766, 0.2729, 0.2754],\n",
       "           [0.2880, 0.2804, 0.3428,  ..., 0.2835, 0.2842, 0.2785],\n",
       "           [0.3114, 0.4071, 0.4824,  ..., 0.2815, 0.2930, 0.2907]],\n",
       " \n",
       "          [[0.7129, 0.7261, 0.3314,  ..., 0.5980, 0.6360, 0.5123],\n",
       "           [0.7156, 0.7220, 0.5944,  ..., 0.7103, 0.7233, 0.6996],\n",
       "           [0.7215, 0.7246, 0.5287,  ..., 0.7203, 0.7114, 0.7242],\n",
       "           ...,\n",
       "           [0.7268, 0.7226, 0.7259,  ..., 0.7234, 0.7271, 0.7246],\n",
       "           [0.7120, 0.7196, 0.6572,  ..., 0.7165, 0.7158, 0.7215],\n",
       "           [0.6886, 0.5929, 0.5176,  ..., 0.7185, 0.7070, 0.7093]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.2853, 0.2725, 0.3443,  ..., 0.2751, 0.2801, 0.2927],\n",
       "           [0.2769, 0.2711, 0.4556,  ..., 0.2811, 0.2861, 0.2774],\n",
       "           [0.2851, 0.2717, 0.4755,  ..., 0.2792, 0.2764, 0.2769],\n",
       "           ...,\n",
       "           [0.2703, 0.2735, 0.2735,  ..., 0.2720, 0.2712, 0.2798],\n",
       "           [0.2738, 0.2747, 0.2724,  ..., 0.2810, 0.2780, 0.2800],\n",
       "           [0.4164, 0.2919, 0.2777,  ..., 0.2824, 0.2796, 0.3687]],\n",
       " \n",
       "          [[0.7147, 0.7275, 0.6557,  ..., 0.7249, 0.7199, 0.7073],\n",
       "           [0.7231, 0.7289, 0.5444,  ..., 0.7189, 0.7139, 0.7226],\n",
       "           [0.7149, 0.7283, 0.5245,  ..., 0.7208, 0.7236, 0.7231],\n",
       "           ...,\n",
       "           [0.7297, 0.7265, 0.7265,  ..., 0.7280, 0.7288, 0.7202],\n",
       "           [0.7262, 0.7253, 0.7276,  ..., 0.7190, 0.7220, 0.7200],\n",
       "           [0.5836, 0.7081, 0.7223,  ..., 0.7176, 0.7204, 0.6313]]],\n",
       " \n",
       " \n",
       "         [[[0.2753, 0.2732, 0.3324,  ..., 0.6611, 0.2836, 0.3184],\n",
       "           [0.2713, 0.2724, 0.3004,  ..., 0.3826, 0.2855, 0.2907],\n",
       "           [0.2776, 0.2841, 0.2861,  ..., 0.2830, 0.3015, 0.2755],\n",
       "           ...,\n",
       "           [0.2735, 0.2797, 0.2718,  ..., 0.2760, 0.2733, 0.2803],\n",
       "           [0.2815, 0.2947, 0.3598,  ..., 0.2745, 0.2714, 0.2742],\n",
       "           [0.3453, 0.3809, 0.3275,  ..., 0.2743, 0.2720, 0.3222]],\n",
       " \n",
       "          [[0.7247, 0.7268, 0.6676,  ..., 0.3389, 0.7164, 0.6816],\n",
       "           [0.7287, 0.7276, 0.6996,  ..., 0.6174, 0.7145, 0.7093],\n",
       "           [0.7224, 0.7159, 0.7139,  ..., 0.7170, 0.6985, 0.7245],\n",
       "           ...,\n",
       "           [0.7265, 0.7203, 0.7282,  ..., 0.7240, 0.7267, 0.7197],\n",
       "           [0.7185, 0.7053, 0.6402,  ..., 0.7255, 0.7286, 0.7258],\n",
       "           [0.6547, 0.6191, 0.6725,  ..., 0.7257, 0.7280, 0.6778]]],\n",
       " \n",
       " \n",
       "         [[[0.2801, 0.2760, 0.3458,  ..., 0.3104, 0.3155, 0.5357],\n",
       "           [0.2822, 0.2759, 0.3374,  ..., 0.2732, 0.2778, 0.2967],\n",
       "           [0.2828, 0.2856, 0.3836,  ..., 0.2876, 0.2962, 0.3318],\n",
       "           ...,\n",
       "           [0.2795, 0.2784, 0.2809,  ..., 0.2716, 0.2706, 0.2742],\n",
       "           [0.2855, 0.2778, 0.2750,  ..., 0.2740, 0.2788, 0.2767],\n",
       "           [0.3168, 0.2755, 0.2801,  ..., 0.2781, 0.2940, 0.3043]],\n",
       " \n",
       "          [[0.7199, 0.7240, 0.6542,  ..., 0.6896, 0.6845, 0.4643],\n",
       "           [0.7178, 0.7241, 0.6626,  ..., 0.7268, 0.7222, 0.7033],\n",
       "           [0.7172, 0.7144, 0.6164,  ..., 0.7124, 0.7038, 0.6682],\n",
       "           ...,\n",
       "           [0.7205, 0.7216, 0.7191,  ..., 0.7284, 0.7294, 0.7258],\n",
       "           [0.7145, 0.7222, 0.7250,  ..., 0.7260, 0.7212, 0.7233],\n",
       "           [0.6832, 0.7245, 0.7199,  ..., 0.7219, 0.7060, 0.6957]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3111, 0.3056, 0.4534,  ..., 0.5894, 0.3234, 0.3356],\n",
       "           [0.2735, 0.2748, 0.3180,  ..., 0.3101, 0.2776, 0.2790],\n",
       "           [0.2728, 0.2785, 0.6742,  ..., 0.2811, 0.2780, 0.2723],\n",
       "           ...,\n",
       "           [0.2736, 0.2755, 0.2742,  ..., 0.2752, 0.2751, 0.2806],\n",
       "           [0.2794, 0.2786, 0.2960,  ..., 0.2804, 0.2714, 0.2848],\n",
       "           [0.3658, 0.3018, 0.2839,  ..., 0.2720, 0.2766, 0.3530]],\n",
       " \n",
       "          [[0.6889, 0.6944, 0.5466,  ..., 0.4106, 0.6766, 0.6644],\n",
       "           [0.7265, 0.7252, 0.6820,  ..., 0.6899, 0.7224, 0.7210],\n",
       "           [0.7272, 0.7215, 0.3258,  ..., 0.7189, 0.7220, 0.7277],\n",
       "           ...,\n",
       "           [0.7264, 0.7245, 0.7258,  ..., 0.7248, 0.7249, 0.7194],\n",
       "           [0.7206, 0.7214, 0.7040,  ..., 0.7196, 0.7286, 0.7152],\n",
       "           [0.6342, 0.6982, 0.7161,  ..., 0.7280, 0.7234, 0.6470]]],\n",
       " \n",
       " \n",
       "         [[[0.2896, 0.2719, 0.4109,  ..., 0.2854, 0.3461, 0.5520],\n",
       "           [0.2742, 0.2717, 0.4385,  ..., 0.2708, 0.2730, 0.2996],\n",
       "           [0.2799, 0.2768, 0.4329,  ..., 0.2840, 0.2884, 0.3037],\n",
       "           ...,\n",
       "           [0.2884, 0.2733, 0.2779,  ..., 0.2790, 0.2864, 0.2878],\n",
       "           [0.2897, 0.2737, 0.2778,  ..., 0.2789, 0.2805, 0.2868],\n",
       "           [0.3742, 0.2967, 0.2766,  ..., 0.2816, 0.2935, 0.3560]],\n",
       " \n",
       "          [[0.7104, 0.7281, 0.5891,  ..., 0.7146, 0.6539, 0.4480],\n",
       "           [0.7258, 0.7283, 0.5615,  ..., 0.7292, 0.7270, 0.7004],\n",
       "           [0.7201, 0.7232, 0.5671,  ..., 0.7160, 0.7116, 0.6963],\n",
       "           ...,\n",
       "           [0.7116, 0.7267, 0.7221,  ..., 0.7210, 0.7136, 0.7122],\n",
       "           [0.7103, 0.7263, 0.7222,  ..., 0.7211, 0.7195, 0.7132],\n",
       "           [0.6258, 0.7033, 0.7234,  ..., 0.7184, 0.7065, 0.6440]]],\n",
       " \n",
       " \n",
       "         [[[0.2936, 0.2829, 0.2951,  ..., 0.2750, 0.2792, 0.2958],\n",
       "           [0.2979, 0.2799, 0.2786,  ..., 0.2744, 0.2742, 0.2767],\n",
       "           [0.2741, 0.2750, 0.2803,  ..., 0.2730, 0.2747, 0.2747],\n",
       "           ...,\n",
       "           [0.3467, 0.2760, 0.3122,  ..., 0.2731, 0.2718, 0.2760],\n",
       "           [0.3095, 0.2708, 0.2763,  ..., 0.2760, 0.2725, 0.2737],\n",
       "           [0.4988, 0.2849, 0.3065,  ..., 0.2753, 0.2754, 0.3113]],\n",
       " \n",
       "          [[0.7064, 0.7171, 0.7049,  ..., 0.7250, 0.7208, 0.7042],\n",
       "           [0.7021, 0.7201, 0.7214,  ..., 0.7256, 0.7258, 0.7233],\n",
       "           [0.7259, 0.7250, 0.7197,  ..., 0.7270, 0.7253, 0.7253],\n",
       "           ...,\n",
       "           [0.6533, 0.7240, 0.6878,  ..., 0.7269, 0.7282, 0.7240],\n",
       "           [0.6905, 0.7292, 0.7237,  ..., 0.7240, 0.7275, 0.7263],\n",
       "           [0.5012, 0.7151, 0.6935,  ..., 0.7247, 0.7246, 0.6887]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.2797, 0.2730, 0.3523,  ..., 0.3018, 0.2922, 0.4891],\n",
       "           [0.2812, 0.2785, 0.3044,  ..., 0.2711, 0.2713, 0.2796],\n",
       "           [0.2828, 0.2818, 0.2839,  ..., 0.3082, 0.2998, 0.2797],\n",
       "           ...,\n",
       "           [0.2738, 0.2720, 0.2799,  ..., 0.2731, 0.2762, 0.2994],\n",
       "           [0.2738, 0.2793, 0.2800,  ..., 0.2750, 0.2878, 0.2801],\n",
       "           [0.3609, 0.2780, 0.2845,  ..., 0.2797, 0.2897, 0.3166]],\n",
       " \n",
       "          [[0.7203, 0.7270, 0.6477,  ..., 0.6982, 0.7078, 0.5109],\n",
       "           [0.7188, 0.7215, 0.6956,  ..., 0.7289, 0.7287, 0.7204],\n",
       "           [0.7172, 0.7182, 0.7161,  ..., 0.6918, 0.7002, 0.7203],\n",
       "           ...,\n",
       "           [0.7262, 0.7280, 0.7201,  ..., 0.7269, 0.7238, 0.7006],\n",
       "           [0.7262, 0.7207, 0.7200,  ..., 0.7250, 0.7122, 0.7199],\n",
       "           [0.6391, 0.7220, 0.7155,  ..., 0.7203, 0.7103, 0.6834]]],\n",
       " \n",
       " \n",
       "         [[[0.3078, 0.2750, 0.2815,  ..., 0.3085, 0.3146, 0.4692],\n",
       "           [0.2830, 0.2782, 0.2784,  ..., 0.2731, 0.2778, 0.3307],\n",
       "           [0.2833, 0.2894, 0.2731,  ..., 0.2747, 0.2738, 0.2800],\n",
       "           ...,\n",
       "           [0.3028, 0.2763, 0.3002,  ..., 0.2721, 0.2702, 0.2786],\n",
       "           [0.2947, 0.2712, 0.2833,  ..., 0.2726, 0.2726, 0.2817],\n",
       "           [0.4276, 0.2828, 0.2804,  ..., 0.2750, 0.2793, 0.3511]],\n",
       " \n",
       "          [[0.6922, 0.7250, 0.7185,  ..., 0.6915, 0.6854, 0.5308],\n",
       "           [0.7170, 0.7218, 0.7216,  ..., 0.7269, 0.7222, 0.6693],\n",
       "           [0.7167, 0.7106, 0.7269,  ..., 0.7253, 0.7262, 0.7200],\n",
       "           ...,\n",
       "           [0.6972, 0.7237, 0.6998,  ..., 0.7279, 0.7298, 0.7214],\n",
       "           [0.7053, 0.7288, 0.7167,  ..., 0.7274, 0.7274, 0.7183],\n",
       "           [0.5724, 0.7172, 0.7196,  ..., 0.7250, 0.7207, 0.6489]]],\n",
       " \n",
       " \n",
       "         [[[0.3419, 0.2803, 0.3070,  ..., 0.2845, 0.3133, 0.4364],\n",
       "           [0.2756, 0.2788, 0.2861,  ..., 0.2726, 0.2710, 0.2799],\n",
       "           [0.2791, 0.2741, 0.2787,  ..., 0.2704, 0.2714, 0.2785],\n",
       "           ...,\n",
       "           [0.2784, 0.2789, 0.2728,  ..., 0.2729, 0.2734, 0.2801],\n",
       "           [0.2780, 0.2766, 0.2728,  ..., 0.2743, 0.2733, 0.2731],\n",
       "           [0.3351, 0.2920, 0.2773,  ..., 0.2768, 0.2832, 0.3463]],\n",
       " \n",
       "          [[0.6581, 0.7197, 0.6930,  ..., 0.7155, 0.6867, 0.5636],\n",
       "           [0.7244, 0.7212, 0.7139,  ..., 0.7274, 0.7290, 0.7201],\n",
       "           [0.7209, 0.7259, 0.7213,  ..., 0.7296, 0.7286, 0.7215],\n",
       "           ...,\n",
       "           [0.7216, 0.7211, 0.7272,  ..., 0.7271, 0.7266, 0.7199],\n",
       "           [0.7220, 0.7234, 0.7272,  ..., 0.7257, 0.7267, 0.7269],\n",
       "           [0.6649, 0.7080, 0.7227,  ..., 0.7232, 0.7168, 0.6537]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3113, 0.2827, 0.2917,  ..., 0.2907, 0.2904, 0.3344],\n",
       "           [0.2742, 0.2952, 0.2859,  ..., 0.2736, 0.2773, 0.2904],\n",
       "           [0.2753, 0.3076, 0.2802,  ..., 0.2716, 0.2763, 0.2964],\n",
       "           ...,\n",
       "           [0.2970, 0.2757, 0.2743,  ..., 0.2863, 0.2982, 0.2958],\n",
       "           [0.3154, 0.2753, 0.2715,  ..., 0.2758, 0.2727, 0.2862],\n",
       "           [0.3823, 0.2779, 0.2768,  ..., 0.2877, 0.2823, 0.3144]],\n",
       " \n",
       "          [[0.6887, 0.7173, 0.7083,  ..., 0.7093, 0.7096, 0.6656],\n",
       "           [0.7258, 0.7048, 0.7141,  ..., 0.7264, 0.7227, 0.7096],\n",
       "           [0.7247, 0.6924, 0.7198,  ..., 0.7284, 0.7237, 0.7036],\n",
       "           ...,\n",
       "           [0.7030, 0.7243, 0.7257,  ..., 0.7137, 0.7018, 0.7042],\n",
       "           [0.6846, 0.7247, 0.7285,  ..., 0.7242, 0.7273, 0.7138],\n",
       "           [0.6177, 0.7221, 0.7232,  ..., 0.7123, 0.7177, 0.6856]]],\n",
       " \n",
       " \n",
       "         [[[0.3565, 0.2858, 0.2885,  ..., 0.2767, 0.2838, 0.4164],\n",
       "           [0.2883, 0.2746, 0.2913,  ..., 0.2730, 0.2835, 0.3582],\n",
       "           [0.2726, 0.2716, 0.2791,  ..., 0.2784, 0.2728, 0.3189],\n",
       "           ...,\n",
       "           [0.2775, 0.2953, 0.2784,  ..., 0.2704, 0.2819, 0.2847],\n",
       "           [0.2762, 0.2917, 0.2773,  ..., 0.2715, 0.2709, 0.2737],\n",
       "           [0.3844, 0.2983, 0.2823,  ..., 0.2721, 0.2758, 0.3030]],\n",
       " \n",
       "          [[0.6435, 0.7142, 0.7115,  ..., 0.7233, 0.7162, 0.5836],\n",
       "           [0.7117, 0.7254, 0.7087,  ..., 0.7270, 0.7165, 0.6418],\n",
       "           [0.7274, 0.7284, 0.7209,  ..., 0.7216, 0.7272, 0.6811],\n",
       "           ...,\n",
       "           [0.7225, 0.7047, 0.7216,  ..., 0.7296, 0.7181, 0.7153],\n",
       "           [0.7238, 0.7083, 0.7227,  ..., 0.7285, 0.7291, 0.7263],\n",
       "           [0.6156, 0.7017, 0.7177,  ..., 0.7279, 0.7242, 0.6970]]],\n",
       " \n",
       " \n",
       "         [[[0.3996, 0.2967, 0.2775,  ..., 0.4274, 0.7038, 0.6035],\n",
       "           [0.2868, 0.2774, 0.2743,  ..., 0.2772, 0.3583, 0.6336],\n",
       "           [0.2813, 0.2720, 0.2704,  ..., 0.2729, 0.2755, 0.4112],\n",
       "           ...,\n",
       "           [0.2973, 0.2899, 0.2733,  ..., 0.2717, 0.2705, 0.2759],\n",
       "           [0.2882, 0.3091, 0.2809,  ..., 0.2709, 0.2699, 0.2761],\n",
       "           [0.3345, 0.3257, 0.3541,  ..., 0.2748, 0.2775, 0.3150]],\n",
       " \n",
       "          [[0.6004, 0.7033, 0.7225,  ..., 0.5726, 0.2962, 0.3965],\n",
       "           [0.7132, 0.7226, 0.7257,  ..., 0.7228, 0.6417, 0.3664],\n",
       "           [0.7187, 0.7280, 0.7296,  ..., 0.7271, 0.7245, 0.5888],\n",
       "           ...,\n",
       "           [0.7027, 0.7101, 0.7267,  ..., 0.7283, 0.7295, 0.7241],\n",
       "           [0.7118, 0.6909, 0.7191,  ..., 0.7291, 0.7301, 0.7239],\n",
       "           [0.6655, 0.6743, 0.6459,  ..., 0.7252, 0.7225, 0.6850]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.4776, 0.2873, 0.2928,  ..., 0.2895, 0.3219, 0.5176],\n",
       "           [0.2763, 0.2715, 0.2842,  ..., 0.2767, 0.2756, 0.2980],\n",
       "           [0.2721, 0.2700, 0.2832,  ..., 0.2772, 0.2761, 0.2890],\n",
       "           ...,\n",
       "           [0.2762, 0.2939, 0.2866,  ..., 0.2835, 0.2743, 0.2828],\n",
       "           [0.2882, 0.2960, 0.2832,  ..., 0.2809, 0.2726, 0.2907],\n",
       "           [0.3260, 0.3072, 0.2764,  ..., 0.2830, 0.2834, 0.3671]],\n",
       " \n",
       "          [[0.5224, 0.7127, 0.7072,  ..., 0.7105, 0.6781, 0.4824],\n",
       "           [0.7237, 0.7285, 0.7158,  ..., 0.7233, 0.7244, 0.7020],\n",
       "           [0.7279, 0.7300, 0.7168,  ..., 0.7228, 0.7239, 0.7110],\n",
       "           ...,\n",
       "           [0.7238, 0.7061, 0.7134,  ..., 0.7165, 0.7257, 0.7172],\n",
       "           [0.7118, 0.7040, 0.7168,  ..., 0.7191, 0.7274, 0.7093],\n",
       "           [0.6740, 0.6928, 0.7236,  ..., 0.7170, 0.7166, 0.6329]]],\n",
       " \n",
       " \n",
       "         [[[0.3030, 0.2756, 0.2767,  ..., 0.4306, 0.7214, 0.5981],\n",
       "           [0.2797, 0.2820, 0.2782,  ..., 0.2901, 0.5027, 0.6728],\n",
       "           [0.2774, 0.2756, 0.2753,  ..., 0.2713, 0.2790, 0.4037],\n",
       "           ...,\n",
       "           [0.2815, 0.2761, 0.2801,  ..., 0.2716, 0.2771, 0.2768],\n",
       "           [0.2905, 0.2744, 0.2775,  ..., 0.2728, 0.2779, 0.2758],\n",
       "           [0.4487, 0.2784, 0.2837,  ..., 0.2849, 0.2771, 0.3232]],\n",
       " \n",
       "          [[0.6970, 0.7244, 0.7233,  ..., 0.5694, 0.2786, 0.4019],\n",
       "           [0.7203, 0.7180, 0.7218,  ..., 0.7099, 0.4973, 0.3272],\n",
       "           [0.7226, 0.7244, 0.7247,  ..., 0.7287, 0.7210, 0.5963],\n",
       "           ...,\n",
       "           [0.7185, 0.7239, 0.7199,  ..., 0.7284, 0.7229, 0.7232],\n",
       "           [0.7095, 0.7256, 0.7225,  ..., 0.7272, 0.7221, 0.7242],\n",
       "           [0.5513, 0.7216, 0.7163,  ..., 0.7151, 0.7229, 0.6768]]],\n",
       " \n",
       " \n",
       "         [[[0.4451, 0.2915, 0.2964,  ..., 0.7311, 0.3288, 0.3303],\n",
       "           [0.2854, 0.2754, 0.2797,  ..., 0.7310, 0.2982, 0.2815],\n",
       "           [0.2762, 0.2710, 0.2753,  ..., 0.5670, 0.7189, 0.5158],\n",
       "           ...,\n",
       "           [0.2774, 0.2707, 0.2737,  ..., 0.2716, 0.2779, 0.2799],\n",
       "           [0.5315, 0.2867, 0.2794,  ..., 0.2747, 0.2733, 0.2848],\n",
       "           [0.6917, 0.4353, 0.2854,  ..., 0.2762, 0.2740, 0.3006]],\n",
       " \n",
       "          [[0.5549, 0.7085, 0.7036,  ..., 0.2689, 0.6712, 0.6697],\n",
       "           [0.7146, 0.7246, 0.7203,  ..., 0.2690, 0.7018, 0.7185],\n",
       "           [0.7238, 0.7290, 0.7247,  ..., 0.4330, 0.2811, 0.4842],\n",
       "           ...,\n",
       "           [0.7226, 0.7293, 0.7263,  ..., 0.7284, 0.7221, 0.7201],\n",
       "           [0.4685, 0.7133, 0.7206,  ..., 0.7253, 0.7267, 0.7152],\n",
       "           [0.3083, 0.5647, 0.7146,  ..., 0.7238, 0.7260, 0.6994]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.4318, 0.2800, 0.2738,  ..., 0.3206, 0.5959, 0.5062],\n",
       "           [0.2775, 0.2734, 0.2719,  ..., 0.2813, 0.4796, 0.7057],\n",
       "           [0.2747, 0.2722, 0.2752,  ..., 0.2783, 0.2768, 0.3401],\n",
       "           ...,\n",
       "           [0.2732, 0.2740, 0.2731,  ..., 0.2756, 0.2766, 0.2958],\n",
       "           [0.3159, 0.2791, 0.2766,  ..., 0.2726, 0.2721, 0.2849],\n",
       "           [0.3213, 0.2852, 0.3040,  ..., 0.2762, 0.2803, 0.3564]],\n",
       " \n",
       "          [[0.5682, 0.7200, 0.7262,  ..., 0.6794, 0.4041, 0.4938],\n",
       "           [0.7225, 0.7266, 0.7281,  ..., 0.7187, 0.5204, 0.2943],\n",
       "           [0.7253, 0.7278, 0.7248,  ..., 0.7217, 0.7232, 0.6599],\n",
       "           ...,\n",
       "           [0.7268, 0.7260, 0.7269,  ..., 0.7244, 0.7234, 0.7042],\n",
       "           [0.6841, 0.7209, 0.7234,  ..., 0.7274, 0.7279, 0.7151],\n",
       "           [0.6787, 0.7148, 0.6960,  ..., 0.7238, 0.7197, 0.6436]]],\n",
       " \n",
       " \n",
       "         [[[0.4262, 0.3028, 0.2944,  ..., 0.7310, 0.2710, 0.2824],\n",
       "           [0.3515, 0.2760, 0.2770,  ..., 0.7310, 0.2876, 0.2808],\n",
       "           [0.3052, 0.2788, 0.2789,  ..., 0.7254, 0.7278, 0.5458],\n",
       "           ...,\n",
       "           [0.2835, 0.2717, 0.2770,  ..., 0.2742, 0.2736, 0.2849],\n",
       "           [0.2852, 0.2730, 0.2755,  ..., 0.2713, 0.2731, 0.2823],\n",
       "           [0.5972, 0.3523, 0.2900,  ..., 0.2750, 0.2889, 0.4294]],\n",
       " \n",
       "          [[0.5738, 0.6972, 0.7056,  ..., 0.2690, 0.7290, 0.7176],\n",
       "           [0.6485, 0.7240, 0.7230,  ..., 0.2690, 0.7124, 0.7192],\n",
       "           [0.6948, 0.7212, 0.7211,  ..., 0.2746, 0.2722, 0.4542],\n",
       "           ...,\n",
       "           [0.7165, 0.7283, 0.7230,  ..., 0.7258, 0.7264, 0.7151],\n",
       "           [0.7148, 0.7270, 0.7245,  ..., 0.7287, 0.7269, 0.7177],\n",
       "           [0.4028, 0.6477, 0.7100,  ..., 0.7250, 0.7111, 0.5706]]],\n",
       " \n",
       " \n",
       "         [[[0.4269, 0.2821, 0.2713,  ..., 0.2759, 0.2776, 0.2985],\n",
       "           [0.3171, 0.2759, 0.2757,  ..., 0.2812, 0.2762, 0.2873],\n",
       "           [0.2960, 0.2754, 0.2718,  ..., 0.7242, 0.2936, 0.2808],\n",
       "           ...,\n",
       "           [0.2842, 0.2903, 0.2945,  ..., 0.2929, 0.3532, 0.3257],\n",
       "           [0.7148, 0.7018, 0.5174,  ..., 0.2749, 0.2761, 0.2889],\n",
       "           [0.7214, 0.7181, 0.3288,  ..., 0.2726, 0.2743, 0.3489]],\n",
       " \n",
       "          [[0.5731, 0.7179, 0.7287,  ..., 0.7241, 0.7224, 0.7015],\n",
       "           [0.6829, 0.7241, 0.7243,  ..., 0.7188, 0.7238, 0.7127],\n",
       "           [0.7040, 0.7246, 0.7282,  ..., 0.2758, 0.7064, 0.7192],\n",
       "           ...,\n",
       "           [0.7158, 0.7097, 0.7055,  ..., 0.7071, 0.6468, 0.6743],\n",
       "           [0.2852, 0.2982, 0.4826,  ..., 0.7251, 0.7239, 0.7111],\n",
       "           [0.2786, 0.2819, 0.6712,  ..., 0.7274, 0.7257, 0.6511]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.4537, 0.3079, 0.2972,  ..., 0.7309, 0.2747, 0.2967],\n",
       "           [0.2958, 0.2799, 0.2886,  ..., 0.7302, 0.2828, 0.2823],\n",
       "           [0.2928, 0.2748, 0.3242,  ..., 0.4666, 0.7062, 0.4501],\n",
       "           ...,\n",
       "           [0.2720, 0.2753, 0.2896,  ..., 0.2798, 0.2766, 0.2958],\n",
       "           [0.2780, 0.2731, 0.2773,  ..., 0.2728, 0.2708, 0.2856],\n",
       "           [0.4915, 0.3936, 0.2852,  ..., 0.2812, 0.2907, 0.4238]],\n",
       " \n",
       "          [[0.5463, 0.6921, 0.7028,  ..., 0.2691, 0.7253, 0.7033],\n",
       "           [0.7042, 0.7201, 0.7114,  ..., 0.2698, 0.7172, 0.7177],\n",
       "           [0.7072, 0.7252, 0.6758,  ..., 0.5334, 0.2938, 0.5499],\n",
       "           ...,\n",
       "           [0.7280, 0.7247, 0.7104,  ..., 0.7202, 0.7234, 0.7042],\n",
       "           [0.7220, 0.7269, 0.7227,  ..., 0.7272, 0.7292, 0.7144],\n",
       "           [0.5085, 0.6064, 0.7148,  ..., 0.7188, 0.7093, 0.5762]]],\n",
       " \n",
       " \n",
       "         [[[0.3840, 0.2742, 0.2741,  ..., 0.2957, 0.2714, 0.2825],\n",
       "           [0.2986, 0.2727, 0.2751,  ..., 0.2941, 0.2706, 0.2859],\n",
       "           [0.3183, 0.2943, 0.2789,  ..., 0.7204, 0.2798, 0.2763],\n",
       "           ...,\n",
       "           [0.2838, 0.2702, 0.2766,  ..., 0.5297, 0.5199, 0.3579],\n",
       "           [0.7104, 0.7077, 0.4015,  ..., 0.2746, 0.2817, 0.3351],\n",
       "           [0.6438, 0.7175, 0.3047,  ..., 0.2767, 0.2875, 0.4203]],\n",
       " \n",
       "          [[0.6160, 0.7258, 0.7259,  ..., 0.7043, 0.7286, 0.7175],\n",
       "           [0.7014, 0.7273, 0.7249,  ..., 0.7059, 0.7294, 0.7141],\n",
       "           [0.6817, 0.7057, 0.7211,  ..., 0.2796, 0.7202, 0.7237],\n",
       "           ...,\n",
       "           [0.7162, 0.7298, 0.7234,  ..., 0.4703, 0.4801, 0.6421],\n",
       "           [0.2896, 0.2923, 0.5985,  ..., 0.7254, 0.7183, 0.6649],\n",
       "           [0.3562, 0.2825, 0.6953,  ..., 0.7233, 0.7125, 0.5797]]],\n",
       " \n",
       " \n",
       "         [[[0.6580, 0.3323, 0.2922,  ..., 0.7288, 0.2974, 0.3060],\n",
       "           [0.3205, 0.2706, 0.2717,  ..., 0.6312, 0.3231, 0.3550],\n",
       "           [0.3047, 0.2748, 0.2709,  ..., 0.3350, 0.7201, 0.4131],\n",
       "           ...,\n",
       "           [0.7305, 0.2941, 0.2847,  ..., 0.2707, 0.2723, 0.2873],\n",
       "           [0.7310, 0.6937, 0.4140,  ..., 0.2732, 0.2764, 0.3127],\n",
       "           [0.6932, 0.6976, 0.6883,  ..., 0.2776, 0.2838, 0.3310]],\n",
       " \n",
       "          [[0.3420, 0.6677, 0.7078,  ..., 0.2712, 0.7026, 0.6940],\n",
       "           [0.6795, 0.7294, 0.7283,  ..., 0.3688, 0.6769, 0.6450],\n",
       "           [0.6953, 0.7252, 0.7291,  ..., 0.6650, 0.2799, 0.5869],\n",
       "           ...,\n",
       "           [0.2695, 0.7059, 0.7153,  ..., 0.7293, 0.7277, 0.7127],\n",
       "           [0.2690, 0.3063, 0.5860,  ..., 0.7268, 0.7236, 0.6873],\n",
       "           [0.3068, 0.3024, 0.3117,  ..., 0.7224, 0.7162, 0.6690]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.5286, 0.2754, 0.2814,  ..., 0.2746, 0.2704, 0.3045],\n",
       "           [0.3406, 0.2713, 0.2797,  ..., 0.3063, 0.2863, 0.3273],\n",
       "           [0.3326, 0.2905, 0.2928,  ..., 0.7279, 0.3346, 0.2828],\n",
       "           ...,\n",
       "           [0.2790, 0.2756, 0.2861,  ..., 0.7178, 0.7214, 0.5133],\n",
       "           [0.7235, 0.7104, 0.6613,  ..., 0.2771, 0.2736, 0.3314],\n",
       "           [0.7063, 0.7011, 0.4484,  ..., 0.2780, 0.2840, 0.3299]],\n",
       " \n",
       "          [[0.4714, 0.7246, 0.7186,  ..., 0.7254, 0.7296, 0.6955],\n",
       "           [0.6594, 0.7287, 0.7203,  ..., 0.6937, 0.7137, 0.6727],\n",
       "           [0.6674, 0.7095, 0.7072,  ..., 0.2721, 0.6654, 0.7172],\n",
       "           ...,\n",
       "           [0.7210, 0.7244, 0.7139,  ..., 0.2822, 0.2786, 0.4867],\n",
       "           [0.2765, 0.2896, 0.3387,  ..., 0.7229, 0.7264, 0.6686],\n",
       "           [0.2937, 0.2989, 0.5516,  ..., 0.7220, 0.7160, 0.6701]]],\n",
       " \n",
       " \n",
       "         [[[0.6632, 0.3020, 0.2804,  ..., 0.7308, 0.3766, 0.3086],\n",
       "           [0.4339, 0.2710, 0.2709,  ..., 0.7167, 0.6315, 0.3632],\n",
       "           [0.2897, 0.2704, 0.2708,  ..., 0.4184, 0.7307, 0.4350],\n",
       "           ...,\n",
       "           [0.7307, 0.2810, 0.2751,  ..., 0.2765, 0.2712, 0.2738],\n",
       "           [0.7310, 0.6913, 0.6362,  ..., 0.3330, 0.2730, 0.2752],\n",
       "           [0.7042, 0.6402, 0.7240,  ..., 0.3281, 0.2840, 0.3305]],\n",
       " \n",
       "          [[0.3368, 0.6980, 0.7196,  ..., 0.2692, 0.6234, 0.6914],\n",
       "           [0.5661, 0.7290, 0.7291,  ..., 0.2833, 0.3685, 0.6368],\n",
       "           [0.7103, 0.7296, 0.7292,  ..., 0.5816, 0.2693, 0.5650],\n",
       "           ...,\n",
       "           [0.2693, 0.7190, 0.7249,  ..., 0.7235, 0.7288, 0.7262],\n",
       "           [0.2690, 0.3087, 0.3638,  ..., 0.6670, 0.7270, 0.7248],\n",
       "           [0.2958, 0.3598, 0.2760,  ..., 0.6719, 0.7160, 0.6695]]],\n",
       " \n",
       " \n",
       "         [[[0.3335, 0.2745, 0.2850,  ..., 0.2825, 0.2784, 0.3627],\n",
       "           [0.2939, 0.2751, 0.2783,  ..., 0.2752, 0.2805, 0.2765],\n",
       "           [0.2948, 0.2807, 0.3072,  ..., 0.2838, 0.2783, 0.2850],\n",
       "           ...,\n",
       "           [0.7246, 0.7285, 0.7287,  ..., 0.2767, 0.2712, 0.2738],\n",
       "           [0.3973, 0.3196, 0.6370,  ..., 0.2748, 0.2803, 0.2834],\n",
       "           [0.3664, 0.2813, 0.3043,  ..., 0.2819, 0.2869, 0.3436]],\n",
       " \n",
       "          [[0.6665, 0.7255, 0.7150,  ..., 0.7175, 0.7216, 0.6373],\n",
       "           [0.7061, 0.7249, 0.7217,  ..., 0.7248, 0.7195, 0.7235],\n",
       "           [0.7052, 0.7193, 0.6928,  ..., 0.7162, 0.7217, 0.7150],\n",
       "           ...,\n",
       "           [0.2754, 0.2715, 0.2713,  ..., 0.7233, 0.7288, 0.7262],\n",
       "           [0.6027, 0.6804, 0.3630,  ..., 0.7252, 0.7197, 0.7166],\n",
       "           [0.6336, 0.7187, 0.6957,  ..., 0.7181, 0.7131, 0.6564]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.7093, 0.4933, 0.3371,  ..., 0.7309, 0.2823, 0.2803],\n",
       "           [0.3924, 0.2757, 0.2720,  ..., 0.7130, 0.2946, 0.2946],\n",
       "           [0.3248, 0.2748, 0.2767,  ..., 0.3478, 0.7060, 0.3768],\n",
       "           ...,\n",
       "           [0.7310, 0.3630, 0.3215,  ..., 0.2892, 0.2774, 0.2970],\n",
       "           [0.7310, 0.6894, 0.6762,  ..., 0.2967, 0.2740, 0.2879],\n",
       "           [0.7200, 0.7161, 0.7300,  ..., 0.3300, 0.2819, 0.4151]],\n",
       " \n",
       "          [[0.2907, 0.5067, 0.6629,  ..., 0.2691, 0.7177, 0.7197],\n",
       "           [0.6076, 0.7243, 0.7280,  ..., 0.2870, 0.7054, 0.7054],\n",
       "           [0.6752, 0.7252, 0.7233,  ..., 0.6522, 0.2940, 0.6232],\n",
       "           ...,\n",
       "           [0.2690, 0.6370, 0.6785,  ..., 0.7108, 0.7226, 0.7030],\n",
       "           [0.2690, 0.3106, 0.3238,  ..., 0.7033, 0.7260, 0.7121],\n",
       "           [0.2800, 0.2839, 0.2700,  ..., 0.6700, 0.7181, 0.5849]]],\n",
       " \n",
       " \n",
       "         [[[0.2923, 0.2707, 0.2758,  ..., 0.2871, 0.2784, 0.3129],\n",
       "           [0.2716, 0.2705, 0.2758,  ..., 0.2816, 0.2889, 0.3030],\n",
       "           [0.2938, 0.3073, 0.2838,  ..., 0.2879, 0.2743, 0.2790],\n",
       "           ...,\n",
       "           [0.7309, 0.7310, 0.7311,  ..., 0.2785, 0.2744, 0.2781],\n",
       "           [0.7234, 0.7246, 0.7310,  ..., 0.2786, 0.2824, 0.2970],\n",
       "           [0.4079, 0.2965, 0.3164,  ..., 0.2878, 0.3000, 0.3563]],\n",
       " \n",
       "          [[0.7077, 0.7293, 0.7242,  ..., 0.7129, 0.7216, 0.6871],\n",
       "           [0.7284, 0.7295, 0.7242,  ..., 0.7184, 0.7111, 0.6970],\n",
       "           [0.7062, 0.6927, 0.7162,  ..., 0.7121, 0.7257, 0.7210],\n",
       "           ...,\n",
       "           [0.2691, 0.2690, 0.2689,  ..., 0.7215, 0.7256, 0.7219],\n",
       "           [0.2766, 0.2754, 0.2690,  ..., 0.7214, 0.7176, 0.7030],\n",
       "           [0.5921, 0.7035, 0.6836,  ..., 0.7122, 0.7000, 0.6437]]],\n",
       " \n",
       " \n",
       "         [[[0.3055, 0.2753, 0.2741,  ..., 0.7039, 0.6283, 0.6694],\n",
       "           [0.2731, 0.2752, 0.2735,  ..., 0.5348, 0.2815, 0.3018],\n",
       "           [0.2772, 0.2864, 0.2724,  ..., 0.2853, 0.2781, 0.2749],\n",
       "           ...,\n",
       "           [0.2827, 0.2761, 0.2752,  ..., 0.2729, 0.2744, 0.2819],\n",
       "           [0.4032, 0.2746, 0.2843,  ..., 0.2844, 0.2782, 0.2902],\n",
       "           [0.7026, 0.5060, 0.4196,  ..., 0.2733, 0.2764, 0.3322]],\n",
       " \n",
       "          [[0.6945, 0.7247, 0.7259,  ..., 0.2961, 0.3717, 0.3306],\n",
       "           [0.7269, 0.7248, 0.7265,  ..., 0.4652, 0.7185, 0.6982],\n",
       "           [0.7228, 0.7136, 0.7276,  ..., 0.7147, 0.7219, 0.7251],\n",
       "           ...,\n",
       "           [0.7173, 0.7239, 0.7248,  ..., 0.7271, 0.7256, 0.7181],\n",
       "           [0.5968, 0.7254, 0.7157,  ..., 0.7156, 0.7218, 0.7098],\n",
       "           [0.2974, 0.4940, 0.5804,  ..., 0.7267, 0.7236, 0.6678]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3115, 0.2823, 0.2979,  ..., 0.2812, 0.2838, 0.3839],\n",
       "           [0.2844, 0.2778, 0.2978,  ..., 0.2946, 0.3812, 0.3000],\n",
       "           [0.2887, 0.2850, 0.3229,  ..., 0.2979, 0.2908, 0.2913],\n",
       "           ...,\n",
       "           [0.7294, 0.7295, 0.7308,  ..., 0.2842, 0.2917, 0.3066],\n",
       "           [0.6568, 0.6922, 0.7256,  ..., 0.2895, 0.2842, 0.3303],\n",
       "           [0.5405, 0.3154, 0.3220,  ..., 0.2926, 0.3105, 0.5621]],\n",
       " \n",
       "          [[0.6885, 0.7177, 0.7021,  ..., 0.7188, 0.7162, 0.6161],\n",
       "           [0.7156, 0.7222, 0.7022,  ..., 0.7054, 0.6188, 0.7000],\n",
       "           [0.7113, 0.7150, 0.6771,  ..., 0.7021, 0.7092, 0.7087],\n",
       "           ...,\n",
       "           [0.2706, 0.2705, 0.2692,  ..., 0.7158, 0.7083, 0.6934],\n",
       "           [0.3432, 0.3078, 0.2744,  ..., 0.7105, 0.7158, 0.6697],\n",
       "           [0.4595, 0.6846, 0.6780,  ..., 0.7074, 0.6895, 0.4379]]],\n",
       " \n",
       " \n",
       "         [[[0.2989, 0.2771, 0.3044,  ..., 0.7280, 0.6057, 0.6191],\n",
       "           [0.2802, 0.2764, 0.2841,  ..., 0.4807, 0.2808, 0.3723],\n",
       "           [0.2720, 0.2715, 0.2747,  ..., 0.3454, 0.2791, 0.3026],\n",
       "           ...,\n",
       "           [0.2846, 0.3946, 0.2879,  ..., 0.2838, 0.3024, 0.2792],\n",
       "           [0.2953, 0.3263, 0.3698,  ..., 0.2972, 0.3178, 0.2795],\n",
       "           [0.6848, 0.5822, 0.5401,  ..., 0.2899, 0.2932, 0.4631]],\n",
       " \n",
       "          [[0.7011, 0.7229, 0.6956,  ..., 0.2720, 0.3943, 0.3809],\n",
       "           [0.7198, 0.7236, 0.7159,  ..., 0.5193, 0.7192, 0.6277],\n",
       "           [0.7280, 0.7285, 0.7253,  ..., 0.6546, 0.7209, 0.6974],\n",
       "           ...,\n",
       "           [0.7154, 0.6054, 0.7121,  ..., 0.7162, 0.6976, 0.7208],\n",
       "           [0.7047, 0.6737, 0.6302,  ..., 0.7028, 0.6822, 0.7205],\n",
       "           [0.3152, 0.4178, 0.4599,  ..., 0.7101, 0.7068, 0.5369]]],\n",
       " \n",
       " \n",
       "         [[[0.7304, 0.3442, 0.2881,  ..., 0.2802, 0.2826, 0.4755],\n",
       "           [0.4726, 0.2749, 0.3016,  ..., 0.2814, 0.2762, 0.2853],\n",
       "           [0.3196, 0.2766, 0.2835,  ..., 0.5170, 0.2913, 0.5137],\n",
       "           ...,\n",
       "           [0.2722, 0.2776, 0.2772,  ..., 0.2857, 0.2724, 0.2816],\n",
       "           [0.2878, 0.2853, 0.2886,  ..., 0.2728, 0.2721, 0.2851],\n",
       "           [0.5969, 0.2993, 0.3209,  ..., 0.2873, 0.2846, 0.3810]],\n",
       " \n",
       "          [[0.2696, 0.6558, 0.7119,  ..., 0.7198, 0.7174, 0.5245],\n",
       "           [0.5274, 0.7251, 0.6984,  ..., 0.7186, 0.7238, 0.7147],\n",
       "           [0.6804, 0.7234, 0.7165,  ..., 0.4830, 0.7087, 0.4863],\n",
       "           ...,\n",
       "           [0.7278, 0.7224, 0.7228,  ..., 0.7143, 0.7276, 0.7184],\n",
       "           [0.7122, 0.7147, 0.7114,  ..., 0.7272, 0.7279, 0.7149],\n",
       "           [0.4031, 0.7007, 0.6791,  ..., 0.7127, 0.7154, 0.6190]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3300, 0.2913, 0.3479,  ..., 0.7291, 0.6387, 0.7030],\n",
       "           [0.2805, 0.2722, 0.2767,  ..., 0.3790, 0.2724, 0.3179],\n",
       "           [0.2779, 0.2743, 0.2744,  ..., 0.2922, 0.2933, 0.2939],\n",
       "           ...,\n",
       "           [0.2784, 0.2909, 0.3535,  ..., 0.2960, 0.2791, 0.2787],\n",
       "           [0.3160, 0.2756, 0.3127,  ..., 0.2777, 0.2795, 0.2839],\n",
       "           [0.6989, 0.6694, 0.5549,  ..., 0.2791, 0.3084, 0.4514]],\n",
       " \n",
       "          [[0.6700, 0.7087, 0.6521,  ..., 0.2709, 0.3613, 0.2970],\n",
       "           [0.7195, 0.7278, 0.7233,  ..., 0.6210, 0.7276, 0.6821],\n",
       "           [0.7221, 0.7257, 0.7256,  ..., 0.7078, 0.7067, 0.7061],\n",
       "           ...,\n",
       "           [0.7216, 0.7091, 0.6465,  ..., 0.7040, 0.7209, 0.7213],\n",
       "           [0.6840, 0.7244, 0.6873,  ..., 0.7223, 0.7205, 0.7161],\n",
       "           [0.3011, 0.3306, 0.4451,  ..., 0.7209, 0.6916, 0.5486]]],\n",
       " \n",
       " \n",
       "         [[[0.7307, 0.3220, 0.2752,  ..., 0.2872, 0.2800, 0.3688],\n",
       "           [0.6031, 0.2723, 0.2846,  ..., 0.2832, 0.2760, 0.2763],\n",
       "           [0.3531, 0.2772, 0.2756,  ..., 0.2828, 0.2869, 0.4118],\n",
       "           ...,\n",
       "           [0.2740, 0.2924, 0.2786,  ..., 0.2793, 0.2849, 0.2774],\n",
       "           [0.2759, 0.3011, 0.2740,  ..., 0.3022, 0.3021, 0.2876],\n",
       "           [0.5185, 0.3596, 0.3035,  ..., 0.3376, 0.3050, 0.5195]],\n",
       " \n",
       "          [[0.2693, 0.6780, 0.7248,  ..., 0.7128, 0.7200, 0.6312],\n",
       "           [0.3969, 0.7277, 0.7154,  ..., 0.7168, 0.7240, 0.7237],\n",
       "           [0.6469, 0.7228, 0.7244,  ..., 0.7172, 0.7131, 0.5882],\n",
       "           ...,\n",
       "           [0.7260, 0.7076, 0.7214,  ..., 0.7207, 0.7151, 0.7226],\n",
       "           [0.7241, 0.6989, 0.7260,  ..., 0.6978, 0.6979, 0.7124],\n",
       "           [0.4815, 0.6404, 0.6965,  ..., 0.6624, 0.6950, 0.4805]]],\n",
       " \n",
       " \n",
       "         [[[0.7110, 0.3456, 0.2754,  ..., 0.3244, 0.2742, 0.3949],\n",
       "           [0.7219, 0.3087, 0.2737,  ..., 0.2729, 0.2716, 0.2990],\n",
       "           [0.4451, 0.2899, 0.2817,  ..., 0.2989, 0.2879, 0.3036],\n",
       "           ...,\n",
       "           [0.3796, 0.2844, 0.2912,  ..., 0.2747, 0.2879, 0.4634],\n",
       "           [0.3276, 0.3085, 0.2880,  ..., 0.2803, 0.2861, 0.5148],\n",
       "           [0.4392, 0.3651, 0.3861,  ..., 0.2874, 0.3288, 0.6164]],\n",
       " \n",
       "          [[0.2890, 0.6544, 0.7246,  ..., 0.6756, 0.7258, 0.6051],\n",
       "           [0.2781, 0.6913, 0.7263,  ..., 0.7271, 0.7284, 0.7010],\n",
       "           [0.5549, 0.7101, 0.7183,  ..., 0.7011, 0.7121, 0.6964],\n",
       "           ...,\n",
       "           [0.6204, 0.7156, 0.7088,  ..., 0.7253, 0.7121, 0.5366],\n",
       "           [0.6724, 0.6915, 0.7120,  ..., 0.7197, 0.7139, 0.4852],\n",
       "           [0.5608, 0.6349, 0.6139,  ..., 0.7126, 0.6712, 0.3836]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.7308, 0.3111, 0.2769,  ..., 0.2787, 0.2715, 0.2969],\n",
       "           [0.4141, 0.2713, 0.2795,  ..., 0.2706, 0.2737, 0.2862],\n",
       "           [0.2975, 0.2778, 0.2845,  ..., 0.2981, 0.2913, 0.3023],\n",
       "           ...,\n",
       "           [0.2785, 0.2780, 0.2769,  ..., 0.2728, 0.2784, 0.3327],\n",
       "           [0.2826, 0.2809, 0.2722,  ..., 0.2757, 0.2763, 0.2819],\n",
       "           [0.3881, 0.2964, 0.3023,  ..., 0.2945, 0.2828, 0.3190]],\n",
       " \n",
       "          [[0.2692, 0.6889, 0.7231,  ..., 0.7213, 0.7285, 0.7031],\n",
       "           [0.5859, 0.7287, 0.7205,  ..., 0.7294, 0.7263, 0.7138],\n",
       "           [0.7025, 0.7222, 0.7155,  ..., 0.7019, 0.7087, 0.6977],\n",
       "           ...,\n",
       "           [0.7215, 0.7220, 0.7231,  ..., 0.7272, 0.7216, 0.6673],\n",
       "           [0.7174, 0.7191, 0.7278,  ..., 0.7243, 0.7237, 0.7181],\n",
       "           [0.6119, 0.7036, 0.6977,  ..., 0.7055, 0.7172, 0.6810]]],\n",
       " \n",
       " \n",
       "         [[[0.7243, 0.3348, 0.2758,  ..., 0.4678, 0.2721, 0.3304],\n",
       "           [0.7191, 0.2775, 0.2745,  ..., 0.2729, 0.2738, 0.2814],\n",
       "           [0.6820, 0.4195, 0.2990,  ..., 0.2870, 0.2742, 0.2870],\n",
       "           ...,\n",
       "           [0.3238, 0.2751, 0.2736,  ..., 0.2793, 0.2764, 0.3523],\n",
       "           [0.3017, 0.2768, 0.2772,  ..., 0.2763, 0.2716, 0.3280],\n",
       "           [0.3851, 0.2919, 0.2813,  ..., 0.2749, 0.2799, 0.6429]],\n",
       " \n",
       "          [[0.2757, 0.6652, 0.7242,  ..., 0.5322, 0.7279, 0.6696],\n",
       "           [0.2809, 0.7225, 0.7255,  ..., 0.7271, 0.7262, 0.7186],\n",
       "           [0.3180, 0.5805, 0.7010,  ..., 0.7130, 0.7258, 0.7130],\n",
       "           ...,\n",
       "           [0.6762, 0.7249, 0.7264,  ..., 0.7207, 0.7236, 0.6477],\n",
       "           [0.6983, 0.7232, 0.7228,  ..., 0.7237, 0.7284, 0.6720],\n",
       "           [0.6149, 0.7081, 0.7187,  ..., 0.7251, 0.7201, 0.3571]]],\n",
       " \n",
       " \n",
       "         [[[0.3166, 0.2805, 0.2715,  ..., 0.2717, 0.2738, 0.3197],\n",
       "           [0.2997, 0.3176, 0.2772,  ..., 0.2769, 0.2728, 0.2780],\n",
       "           [0.2807, 0.2760, 0.3021,  ..., 0.3892, 0.2924, 0.2892],\n",
       "           ...,\n",
       "           [0.2779, 0.2747, 0.2770,  ..., 0.3001, 0.4431, 0.4846],\n",
       "           [0.2807, 0.2802, 0.3067,  ..., 0.2747, 0.2750, 0.5956],\n",
       "           [0.3490, 0.3286, 0.3176,  ..., 0.2744, 0.2816, 0.5069]],\n",
       " \n",
       "          [[0.6834, 0.7195, 0.7285,  ..., 0.7283, 0.7262, 0.6803],\n",
       "           [0.7003, 0.6824, 0.7228,  ..., 0.7231, 0.7272, 0.7220],\n",
       "           [0.7193, 0.7240, 0.6979,  ..., 0.6108, 0.7076, 0.7108],\n",
       "           ...,\n",
       "           [0.7221, 0.7253, 0.7230,  ..., 0.6999, 0.5569, 0.5154],\n",
       "           [0.7193, 0.7198, 0.6933,  ..., 0.7253, 0.7250, 0.4044],\n",
       "           [0.6510, 0.6714, 0.6824,  ..., 0.7256, 0.7184, 0.4931]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.7076, 0.3051, 0.2721,  ..., 0.2724, 0.2706, 0.3301],\n",
       "           [0.5744, 0.2727, 0.2710,  ..., 0.2732, 0.2739, 0.2746],\n",
       "           [0.3301, 0.2782, 0.2729,  ..., 0.2905, 0.2740, 0.2751],\n",
       "           ...,\n",
       "           [0.2859, 0.2782, 0.2905,  ..., 0.2736, 0.2721, 0.2789],\n",
       "           [0.2810, 0.2765, 0.2747,  ..., 0.2725, 0.2703, 0.2827],\n",
       "           [0.3973, 0.2828, 0.2730,  ..., 0.2868, 0.2807, 0.3729]],\n",
       " \n",
       "          [[0.2924, 0.6949, 0.7279,  ..., 0.7276, 0.7294, 0.6699],\n",
       "           [0.4256, 0.7273, 0.7290,  ..., 0.7268, 0.7261, 0.7254],\n",
       "           [0.6699, 0.7218, 0.7271,  ..., 0.7095, 0.7260, 0.7249],\n",
       "           ...,\n",
       "           [0.7141, 0.7218, 0.7095,  ..., 0.7264, 0.7279, 0.7211],\n",
       "           [0.7190, 0.7235, 0.7253,  ..., 0.7275, 0.7297, 0.7173],\n",
       "           [0.6027, 0.7172, 0.7270,  ..., 0.7132, 0.7193, 0.6271]]],\n",
       " \n",
       " \n",
       "         [[[0.2873, 0.2715, 0.2727,  ..., 0.2714, 0.2787, 0.3067],\n",
       "           [0.2748, 0.2725, 0.2754,  ..., 0.2741, 0.2796, 0.3481],\n",
       "           [0.2839, 0.2733, 0.2734,  ..., 0.7235, 0.5033, 0.3280],\n",
       "           ...,\n",
       "           [0.2744, 0.2740, 0.2710,  ..., 0.2760, 0.2749, 0.2853],\n",
       "           [0.2741, 0.2718, 0.2806,  ..., 0.2712, 0.2753, 0.3101],\n",
       "           [0.3024, 0.2794, 0.2927,  ..., 0.2740, 0.2872, 0.3552]],\n",
       " \n",
       "          [[0.7127, 0.7285, 0.7273,  ..., 0.7286, 0.7213, 0.6933],\n",
       "           [0.7252, 0.7275, 0.7246,  ..., 0.7259, 0.7204, 0.6519],\n",
       "           [0.7161, 0.7267, 0.7266,  ..., 0.2765, 0.4967, 0.6720],\n",
       "           ...,\n",
       "           [0.7256, 0.7260, 0.7290,  ..., 0.7240, 0.7251, 0.7147],\n",
       "           [0.7259, 0.7282, 0.7194,  ..., 0.7288, 0.7247, 0.6899],\n",
       "           [0.6976, 0.7206, 0.7073,  ..., 0.7260, 0.7128, 0.6448]]],\n",
       " \n",
       " \n",
       "         [[[0.4682, 0.2853, 0.3385,  ..., 0.3009, 0.6764, 0.6576],\n",
       "           [0.3263, 0.2739, 0.2758,  ..., 0.7302, 0.7311, 0.7219],\n",
       "           [0.3418, 0.2714, 0.2733,  ..., 0.7311, 0.7310, 0.3657],\n",
       "           ...,\n",
       "           [0.2768, 0.2787, 0.2781,  ..., 0.2743, 0.2730, 0.2734],\n",
       "           [0.2761, 0.2730, 0.2741,  ..., 0.2716, 0.2701, 0.2775],\n",
       "           [0.3781, 0.3285, 0.5192,  ..., 0.2751, 0.2746, 0.3025]],\n",
       " \n",
       "          [[0.5318, 0.7147, 0.6615,  ..., 0.6991, 0.3236, 0.3424],\n",
       "           [0.6737, 0.7261, 0.7242,  ..., 0.2698, 0.2689, 0.2781],\n",
       "           [0.6582, 0.7286, 0.7267,  ..., 0.2689, 0.2690, 0.6343],\n",
       "           ...,\n",
       "           [0.7232, 0.7213, 0.7219,  ..., 0.7257, 0.7270, 0.7266],\n",
       "           [0.7239, 0.7270, 0.7259,  ..., 0.7284, 0.7299, 0.7225],\n",
       "           [0.6219, 0.6715, 0.4808,  ..., 0.7249, 0.7254, 0.6975]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3147, 0.2740, 0.2736,  ..., 0.2844, 0.2830, 0.3449],\n",
       "           [0.2825, 0.2809, 0.2817,  ..., 0.2717, 0.2841, 0.3057],\n",
       "           [0.2947, 0.2713, 0.2717,  ..., 0.6210, 0.3861, 0.3385],\n",
       "           ...,\n",
       "           [0.2762, 0.2783, 0.2746,  ..., 0.2730, 0.2808, 0.2869],\n",
       "           [0.2869, 0.2889, 0.3312,  ..., 0.2716, 0.2750, 0.2925],\n",
       "           [0.3314, 0.2958, 0.3257,  ..., 0.2783, 0.3061, 0.4110]],\n",
       " \n",
       "          [[0.6853, 0.7260, 0.7264,  ..., 0.7156, 0.7170, 0.6551],\n",
       "           [0.7175, 0.7191, 0.7183,  ..., 0.7283, 0.7159, 0.6943],\n",
       "           [0.7053, 0.7287, 0.7283,  ..., 0.3790, 0.6139, 0.6615],\n",
       "           ...,\n",
       "           [0.7238, 0.7217, 0.7254,  ..., 0.7270, 0.7192, 0.7131],\n",
       "           [0.7131, 0.7111, 0.6688,  ..., 0.7284, 0.7250, 0.7075],\n",
       "           [0.6686, 0.7042, 0.6743,  ..., 0.7217, 0.6939, 0.5890]]],\n",
       " \n",
       " \n",
       "         [[[0.6409, 0.4981, 0.5716,  ..., 0.3741, 0.5351, 0.5189],\n",
       "           [0.3511, 0.2736, 0.3027,  ..., 0.7310, 0.7310, 0.7152],\n",
       "           [0.3159, 0.2731, 0.2787,  ..., 0.7311, 0.7311, 0.4771],\n",
       "           ...,\n",
       "           [0.2845, 0.2954, 0.2935,  ..., 0.2701, 0.2707, 0.2784],\n",
       "           [0.2885, 0.2899, 0.2883,  ..., 0.2706, 0.2716, 0.3027],\n",
       "           [0.4192, 0.3057, 0.3413,  ..., 0.2776, 0.2799, 0.3982]],\n",
       " \n",
       "          [[0.3591, 0.5019, 0.4284,  ..., 0.6259, 0.4649, 0.4811],\n",
       "           [0.6489, 0.7264, 0.6973,  ..., 0.2690, 0.2690, 0.2848],\n",
       "           [0.6841, 0.7269, 0.7213,  ..., 0.2689, 0.2689, 0.5229],\n",
       "           ...,\n",
       "           [0.7155, 0.7046, 0.7065,  ..., 0.7299, 0.7293, 0.7216],\n",
       "           [0.7115, 0.7101, 0.7117,  ..., 0.7294, 0.7284, 0.6973],\n",
       "           [0.5808, 0.6943, 0.6587,  ..., 0.7224, 0.7201, 0.6018]]],\n",
       " \n",
       " \n",
       "         [[[0.5263, 0.3003, 0.3119,  ..., 0.2774, 0.2830, 0.3766],\n",
       "           [0.2875, 0.2834, 0.2912,  ..., 0.2755, 0.2900, 0.3103],\n",
       "           [0.2750, 0.2768, 0.2991,  ..., 0.2761, 0.2925, 0.3578],\n",
       "           ...,\n",
       "           [0.2759, 0.2756, 0.2744,  ..., 0.2705, 0.2761, 0.2760],\n",
       "           [0.2868, 0.2878, 0.2838,  ..., 0.2721, 0.2741, 0.2814],\n",
       "           [0.5461, 0.3333, 0.3108,  ..., 0.2790, 0.2781, 0.3406]],\n",
       " \n",
       "          [[0.4737, 0.6997, 0.6881,  ..., 0.7226, 0.7170, 0.6234],\n",
       "           [0.7125, 0.7166, 0.7088,  ..., 0.7245, 0.7100, 0.6897],\n",
       "           [0.7250, 0.7232, 0.7009,  ..., 0.7239, 0.7075, 0.6422],\n",
       "           ...,\n",
       "           [0.7241, 0.7244, 0.7256,  ..., 0.7295, 0.7239, 0.7240],\n",
       "           [0.7132, 0.7122, 0.7162,  ..., 0.7279, 0.7259, 0.7186],\n",
       "           [0.4539, 0.6667, 0.6892,  ..., 0.7210, 0.7219, 0.6594]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3950, 0.2885, 0.2770,  ..., 0.3652, 0.6859, 0.6248],\n",
       "           [0.2859, 0.2703, 0.2714,  ..., 0.7231, 0.7310, 0.7043],\n",
       "           [0.2767, 0.2702, 0.2764,  ..., 0.7311, 0.7311, 0.5808],\n",
       "           ...,\n",
       "           [0.2737, 0.2822, 0.2957,  ..., 0.2767, 0.2821, 0.2774],\n",
       "           [0.2810, 0.2797, 0.2911,  ..., 0.2728, 0.2746, 0.2743],\n",
       "           [0.3357, 0.3101, 0.5994,  ..., 0.2776, 0.2763, 0.3475]],\n",
       " \n",
       "          [[0.6050, 0.7115, 0.7230,  ..., 0.6348, 0.3141, 0.3752],\n",
       "           [0.7141, 0.7297, 0.7286,  ..., 0.2769, 0.2690, 0.2957],\n",
       "           [0.7233, 0.7298, 0.7236,  ..., 0.2689, 0.2689, 0.4192],\n",
       "           ...,\n",
       "           [0.7263, 0.7178, 0.7043,  ..., 0.7233, 0.7179, 0.7226],\n",
       "           [0.7190, 0.7203, 0.7089,  ..., 0.7272, 0.7254, 0.7257],\n",
       "           [0.6643, 0.6899, 0.4006,  ..., 0.7224, 0.7237, 0.6525]]],\n",
       " \n",
       " \n",
       "         [[[0.5231, 0.2917, 0.2881,  ..., 0.2720, 0.2787, 0.3475],\n",
       "           [0.2828, 0.2746, 0.2946,  ..., 0.2732, 0.2746, 0.2957],\n",
       "           [0.2737, 0.2728, 0.2984,  ..., 0.2707, 0.2794, 0.5169],\n",
       "           ...,\n",
       "           [0.2728, 0.2726, 0.2728,  ..., 0.2788, 0.2731, 0.2773],\n",
       "           [0.2998, 0.2756, 0.2726,  ..., 0.2751, 0.2724, 0.2767],\n",
       "           [0.3858, 0.2999, 0.2822,  ..., 0.2847, 0.2796, 0.3378]],\n",
       " \n",
       "          [[0.4769, 0.7083, 0.7119,  ..., 0.7280, 0.7213, 0.6525],\n",
       "           [0.7172, 0.7254, 0.7054,  ..., 0.7268, 0.7254, 0.7043],\n",
       "           [0.7263, 0.7272, 0.7016,  ..., 0.7293, 0.7206, 0.4831],\n",
       "           ...,\n",
       "           [0.7272, 0.7274, 0.7272,  ..., 0.7212, 0.7269, 0.7227],\n",
       "           [0.7002, 0.7244, 0.7274,  ..., 0.7249, 0.7276, 0.7233],\n",
       "           [0.6142, 0.7001, 0.7178,  ..., 0.7153, 0.7204, 0.6622]]],\n",
       " \n",
       " \n",
       "         [[[0.2911, 0.2734, 0.2811,  ..., 0.7310, 0.4021, 0.3463],\n",
       "           [0.2824, 0.2868, 0.2936,  ..., 0.7311, 0.7310, 0.5622],\n",
       "           [0.2811, 0.3059, 0.2946,  ..., 0.7311, 0.7299, 0.3741],\n",
       "           ...,\n",
       "           [0.2809, 0.2977, 0.6195,  ..., 0.2722, 0.2777, 0.2746],\n",
       "           [0.7148, 0.7309, 0.7310,  ..., 0.2709, 0.2709, 0.2787],\n",
       "           [0.7098, 0.7226, 0.3056,  ..., 0.2718, 0.2731, 0.2923]],\n",
       " \n",
       "          [[0.7089, 0.7266, 0.7189,  ..., 0.2690, 0.5979, 0.6537],\n",
       "           [0.7176, 0.7132, 0.7064,  ..., 0.2689, 0.2690, 0.4378],\n",
       "           [0.7189, 0.6941, 0.7054,  ..., 0.2689, 0.2701, 0.6259],\n",
       "           ...,\n",
       "           [0.7191, 0.7023, 0.3805,  ..., 0.7278, 0.7223, 0.7254],\n",
       "           [0.2852, 0.2691, 0.2690,  ..., 0.7291, 0.7291, 0.7213],\n",
       "           [0.2902, 0.2774, 0.6944,  ..., 0.7282, 0.7269, 0.7077]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.5456, 0.3226, 0.4163,  ..., 0.2717, 0.2726, 0.2993],\n",
       "           [0.2958, 0.2776, 0.3816,  ..., 0.2741, 0.2790, 0.2949],\n",
       "           [0.2752, 0.2801, 0.5582,  ..., 0.2748, 0.2930, 0.5555],\n",
       "           ...,\n",
       "           [0.2848, 0.2849, 0.2831,  ..., 0.2719, 0.2716, 0.2728],\n",
       "           [0.2820, 0.2818, 0.3145,  ..., 0.2718, 0.2726, 0.2757],\n",
       "           [0.4537, 0.3056, 0.3341,  ..., 0.2795, 0.2928, 0.3104]],\n",
       " \n",
       "          [[0.4544, 0.6774, 0.5837,  ..., 0.7283, 0.7274, 0.7007],\n",
       "           [0.7042, 0.7224, 0.6184,  ..., 0.7259, 0.7210, 0.7051],\n",
       "           [0.7248, 0.7199, 0.4418,  ..., 0.7252, 0.7070, 0.4445],\n",
       "           ...,\n",
       "           [0.7152, 0.7151, 0.7169,  ..., 0.7281, 0.7284, 0.7272],\n",
       "           [0.7180, 0.7182, 0.6855,  ..., 0.7282, 0.7274, 0.7243],\n",
       "           [0.5463, 0.6944, 0.6659,  ..., 0.7205, 0.7072, 0.6896]]],\n",
       " \n",
       " \n",
       "         [[[0.3591, 0.2785, 0.3071,  ..., 0.7310, 0.3434, 0.4383],\n",
       "           [0.2768, 0.2830, 0.2818,  ..., 0.7311, 0.7311, 0.6575],\n",
       "           [0.2829, 0.3518, 0.2992,  ..., 0.7311, 0.7293, 0.3793],\n",
       "           ...,\n",
       "           [0.3131, 0.2777, 0.5507,  ..., 0.2773, 0.2776, 0.2757],\n",
       "           [0.7307, 0.7310, 0.7308,  ..., 0.2739, 0.2784, 0.2770],\n",
       "           [0.7308, 0.7276, 0.2960,  ..., 0.2751, 0.3160, 0.3905]],\n",
       " \n",
       "          [[0.6409, 0.7215, 0.6929,  ..., 0.2690, 0.6566, 0.5617],\n",
       "           [0.7232, 0.7170, 0.7182,  ..., 0.2689, 0.2689, 0.3425],\n",
       "           [0.7171, 0.6482, 0.7008,  ..., 0.2689, 0.2707, 0.6207],\n",
       "           ...,\n",
       "           [0.6869, 0.7223, 0.4493,  ..., 0.7227, 0.7224, 0.7243],\n",
       "           [0.2693, 0.2690, 0.2692,  ..., 0.7261, 0.7216, 0.7230],\n",
       "           [0.2692, 0.2724, 0.7040,  ..., 0.7249, 0.6840, 0.6095]]],\n",
       " \n",
       " \n",
       "         [[[0.3081, 0.2748, 0.2768,  ..., 0.2845, 0.5854, 0.6713],\n",
       "           [0.2761, 0.2738, 0.2746,  ..., 0.3169, 0.7311, 0.7310],\n",
       "           [0.2813, 0.2729, 0.2739,  ..., 0.7311, 0.7311, 0.7311],\n",
       "           ...,\n",
       "           [0.6958, 0.2945, 0.4492,  ..., 0.2833, 0.3204, 0.2796],\n",
       "           [0.3694, 0.2749, 0.2831,  ..., 0.2714, 0.2789, 0.2887],\n",
       "           [0.5137, 0.2857, 0.2774,  ..., 0.2711, 0.2937, 0.3790]],\n",
       " \n",
       "          [[0.6919, 0.7252, 0.7232,  ..., 0.7155, 0.4146, 0.3287],\n",
       "           [0.7239, 0.7262, 0.7254,  ..., 0.6831, 0.2689, 0.2690],\n",
       "           [0.7187, 0.7271, 0.7261,  ..., 0.2689, 0.2689, 0.2689],\n",
       "           ...,\n",
       "           [0.3042, 0.7055, 0.5508,  ..., 0.7167, 0.6796, 0.7204],\n",
       "           [0.6306, 0.7251, 0.7169,  ..., 0.7286, 0.7211, 0.7113],\n",
       "           [0.4863, 0.7143, 0.7226,  ..., 0.7289, 0.7063, 0.6210]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3189, 0.2736, 0.2954,  ..., 0.7303, 0.4674, 0.3427],\n",
       "           [0.2997, 0.2966, 0.2722,  ..., 0.7311, 0.7311, 0.7164],\n",
       "           [0.2975, 0.2942, 0.2764,  ..., 0.7311, 0.7290, 0.3134],\n",
       "           ...,\n",
       "           [0.2739, 0.2764, 0.3484,  ..., 0.2801, 0.2798, 0.2750],\n",
       "           [0.6005, 0.7222, 0.7223,  ..., 0.2781, 0.2725, 0.2766],\n",
       "           [0.6189, 0.6336, 0.2880,  ..., 0.2891, 0.2850, 0.3725]],\n",
       " \n",
       "          [[0.6811, 0.7264, 0.7046,  ..., 0.2697, 0.5326, 0.6573],\n",
       "           [0.7003, 0.7034, 0.7278,  ..., 0.2689, 0.2689, 0.2836],\n",
       "           [0.7025, 0.7058, 0.7236,  ..., 0.2689, 0.2710, 0.6866],\n",
       "           ...,\n",
       "           [0.7261, 0.7236, 0.6516,  ..., 0.7199, 0.7202, 0.7250],\n",
       "           [0.3995, 0.2778, 0.2777,  ..., 0.7219, 0.7275, 0.7234],\n",
       "           [0.3811, 0.3664, 0.7120,  ..., 0.7109, 0.7150, 0.6275]]],\n",
       " \n",
       " \n",
       "         [[[0.4352, 0.2787, 0.2776,  ..., 0.2733, 0.3244, 0.6677],\n",
       "           [0.2886, 0.2809, 0.2797,  ..., 0.2794, 0.7178, 0.7302],\n",
       "           [0.2770, 0.2909, 0.3123,  ..., 0.7311, 0.7311, 0.7310],\n",
       "           ...,\n",
       "           [0.6454, 0.2779, 0.2761,  ..., 0.3407, 0.2941, 0.2839],\n",
       "           [0.4824, 0.2723, 0.2769,  ..., 0.2709, 0.2728, 0.2797],\n",
       "           [0.4772, 0.2791, 0.2851,  ..., 0.2720, 0.2872, 0.2965]],\n",
       " \n",
       "          [[0.5648, 0.7213, 0.7224,  ..., 0.7267, 0.6756, 0.3323],\n",
       "           [0.7114, 0.7191, 0.7203,  ..., 0.7206, 0.2822, 0.2698],\n",
       "           [0.7230, 0.7091, 0.6877,  ..., 0.2689, 0.2689, 0.2690],\n",
       "           ...,\n",
       "           [0.3546, 0.7221, 0.7239,  ..., 0.6593, 0.7059, 0.7161],\n",
       "           [0.5176, 0.7277, 0.7231,  ..., 0.7291, 0.7272, 0.7203],\n",
       "           [0.5228, 0.7209, 0.7149,  ..., 0.7280, 0.7128, 0.7035]]],\n",
       " \n",
       " \n",
       "         [[[0.3168, 0.2728, 0.2761,  ..., 0.3199, 0.2782, 0.3913],\n",
       "           [0.2774, 0.2720, 0.2822,  ..., 0.3195, 0.2792, 0.3013],\n",
       "           [0.2785, 0.2804, 0.2728,  ..., 0.3532, 0.2907, 0.2846],\n",
       "           ...,\n",
       "           [0.2998, 0.2751, 0.2819,  ..., 0.2800, 0.2704, 0.2711],\n",
       "           [0.3134, 0.2841, 0.2778,  ..., 0.2711, 0.2697, 0.2772],\n",
       "           [0.5153, 0.3163, 0.2750,  ..., 0.2707, 0.2717, 0.2933]],\n",
       " \n",
       "          [[0.6832, 0.7272, 0.7239,  ..., 0.6801, 0.7218, 0.6087],\n",
       "           [0.7226, 0.7280, 0.7178,  ..., 0.6805, 0.7208, 0.6987],\n",
       "           [0.7215, 0.7196, 0.7272,  ..., 0.6468, 0.7093, 0.7154],\n",
       "           ...,\n",
       "           [0.7002, 0.7249, 0.7181,  ..., 0.7200, 0.7296, 0.7289],\n",
       "           [0.6866, 0.7159, 0.7222,  ..., 0.7289, 0.7303, 0.7228],\n",
       "           [0.4847, 0.6837, 0.7250,  ..., 0.7293, 0.7283, 0.7067]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>),\n",
       " tensor([[[[0.3470, 0.2761, 0.2734,  ..., 0.2740, 0.3174, 0.5173],\n",
       "           [0.2765, 0.2757, 0.2832,  ..., 0.2765, 0.6754, 0.7052],\n",
       "           [0.2752, 0.2813, 0.2724,  ..., 0.7311, 0.7311, 0.7227],\n",
       "           ...,\n",
       "           [0.3142, 0.2829, 0.3070,  ..., 0.5951, 0.6366, 0.5363],\n",
       "           [0.2940, 0.2867, 0.2802,  ..., 0.2757, 0.2729, 0.2829],\n",
       "           [0.3600, 0.2995, 0.2795,  ..., 0.2797, 0.2956, 0.3439]],\n",
       " \n",
       "          [[0.6530, 0.7239, 0.7266,  ..., 0.7260, 0.6826, 0.4827],\n",
       "           [0.7235, 0.7243, 0.7168,  ..., 0.7235, 0.3246, 0.2948],\n",
       "           [0.7248, 0.7187, 0.7276,  ..., 0.2689, 0.2689, 0.2773],\n",
       "           ...,\n",
       "           [0.6858, 0.7171, 0.6930,  ..., 0.4049, 0.3634, 0.4637],\n",
       "           [0.7060, 0.7133, 0.7198,  ..., 0.7243, 0.7271, 0.7171],\n",
       "           [0.6400, 0.7005, 0.7205,  ..., 0.7203, 0.7044, 0.6561]]],\n",
       " \n",
       " \n",
       "         [[[0.3453, 0.3031, 0.2800,  ..., 0.3349, 0.2840, 0.4652],\n",
       "           [0.2831, 0.2837, 0.2915,  ..., 0.2898, 0.2738, 0.2991],\n",
       "           [0.2765, 0.2720, 0.2778,  ..., 0.3230, 0.2876, 0.3013],\n",
       "           ...,\n",
       "           [0.3591, 0.2826, 0.2785,  ..., 0.2708, 0.2849, 0.2993],\n",
       "           [0.3680, 0.3033, 0.2736,  ..., 0.2711, 0.2758, 0.2759],\n",
       "           [0.4254, 0.3341, 0.2761,  ..., 0.2758, 0.2872, 0.3254]],\n",
       " \n",
       "          [[0.6547, 0.6969, 0.7200,  ..., 0.6651, 0.7160, 0.5348],\n",
       "           [0.7169, 0.7163, 0.7085,  ..., 0.7102, 0.7262, 0.7009],\n",
       "           [0.7235, 0.7280, 0.7222,  ..., 0.6770, 0.7124, 0.6987],\n",
       "           ...,\n",
       "           [0.6409, 0.7174, 0.7215,  ..., 0.7292, 0.7151, 0.7007],\n",
       "           [0.6320, 0.6967, 0.7264,  ..., 0.7289, 0.7242, 0.7241],\n",
       "           [0.5746, 0.6659, 0.7239,  ..., 0.7242, 0.7128, 0.6746]]],\n",
       " \n",
       " \n",
       "         [[[0.3489, 0.2809, 0.3381,  ..., 0.2985, 0.2793, 0.3580],\n",
       "           [0.2862, 0.2736, 0.3020,  ..., 0.2998, 0.2763, 0.2875],\n",
       "           [0.2958, 0.2716, 0.3042,  ..., 0.2814, 0.2845, 0.4307],\n",
       "           ...,\n",
       "           [0.4762, 0.2738, 0.2736,  ..., 0.2800, 0.2768, 0.2764],\n",
       "           [0.7304, 0.7179, 0.4451,  ..., 0.2777, 0.2780, 0.2925],\n",
       "           [0.6605, 0.6081, 0.6823,  ..., 0.2710, 0.2730, 0.3084]],\n",
       " \n",
       "          [[0.6511, 0.7191, 0.6619,  ..., 0.7015, 0.7207, 0.6420],\n",
       "           [0.7138, 0.7264, 0.6980,  ..., 0.7002, 0.7237, 0.7125],\n",
       "           [0.7042, 0.7284, 0.6958,  ..., 0.7186, 0.7155, 0.5693],\n",
       "           ...,\n",
       "           [0.5238, 0.7262, 0.7264,  ..., 0.7200, 0.7232, 0.7236],\n",
       "           [0.2696, 0.2821, 0.5549,  ..., 0.7223, 0.7220, 0.7075],\n",
       "           [0.3395, 0.3919, 0.3177,  ..., 0.7290, 0.7270, 0.6916]]]],\n",
       "        device='cuda:0', grad_fn=<SoftmaxBackward>)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Medical_test_unet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
