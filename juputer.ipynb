{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'test', 'images']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "os.listdir('../test_r_unet/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "timesteps = 3\n",
    "batch_size = 4\n",
    "num_epochs = 10\n",
    "input_size = 128\n",
    "\n",
    "gru_nan = False\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                              transforms.Resize((input_size, input_size)),\n",
    "                              transforms.ToTensor(),\n",
    "                              ])\n",
    "\n",
    "# decive\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way to the data folders\n",
    "folder_data = \"../test_r_unet/data/images\"\n",
    "folder_mask = \"../test_r_unet/data/labels\"\n",
    "folder_test = \"../test_r_unet/data/test\"\n",
    "\n",
    "file_names = os.listdir('../test_r_unet/data/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time = timesteps\n",
    "        self.folder_data = folder_data\n",
    "        self.folder_mask = folder_mask\n",
    "        self.file_names = file_names\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_data + '/' + file_names[idx+i])).unsqueeze(0))\n",
    "        gif_data = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_mask + '/' + file_names[idx+i])).unsqueeze(0))\n",
    "        gif_mask = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        return gif_data, gif_mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MedData()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=2,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GruCell(nn.Module):\n",
    "    \n",
    "    def __init__(self, channel):\n",
    "        super(GruCell, self).__init__()\n",
    "        self.conv_relu = nn.Sequential(nn.Conv2d(in_channels=channel, out_channels=channel, kernel_size=3, stride=1, padding=1),\n",
    "                                       nn.ELU(),\n",
    "                                       nn.Dropout(p=0.2))\n",
    "        \n",
    "        self.conv_relu_2x = nn.Sequential(nn.Conv2d(in_channels=channel+channel, out_channels=channel, kernel_size=3, stride=1, padding=1),\n",
    "                                          nn.ELU(),\n",
    "                                          nn.Dropout(p=0.2))\n",
    "        \n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "     \n",
    "    def forward(self, x, hidden):\n",
    "        input = torch.cat([x, hidden],dim=1)\n",
    "\n",
    "        update_gate = self.conv_relu_2x(input)\n",
    "        update_gate = self.sig((update_gate)) ### output after update gate\n",
    "        \n",
    "        reset_gate = self.conv_relu_2x(input)\n",
    "        reset_gate = self.sig((reset_gate)) ### output after reset gate\n",
    "        \n",
    "        memory_gate_for_input = self.conv_relu(x)\n",
    "        memory_gate_for_hidden = self.conv_relu(hidden)\n",
    "\n",
    "        memory_content = self.sig((memory_gate_for_input + (reset_gate * memory_gate_for_hidden))) ### output for reset gate(affects how the reset gate do work)\n",
    "        \n",
    "        hidden = (update_gate * hidden) + ((1 - update_gate) * memory_content) # torch.ones(input_size, hidden_size)\n",
    "\n",
    "        return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class Gru\n",
    "class Gru(nn.Module):\n",
    "\n",
    "    def __init__(self, channels_size, gru_input_size): # arg for gru layer\n",
    "        super(Gru, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.timesteps = timesteps\n",
    "        self.channels_size = channels_size\n",
    "        self.input_size = gru_input_size\n",
    "        self.hidden_size = (self.batch_size, channels_size, gru_input_size, gru_input_size)\n",
    "        \n",
    "        self.gru_layer0 = GruCell(channels_size)\n",
    "        self.init_hidden = torch.zeros(self.hidden_size).to(device)\n",
    "        self.gru_nan = gru_nan\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_cells = None\n",
    "        x_list = []\n",
    "        if self.gru_nan == False:\n",
    "            try:\n",
    "                x = x.reshape(batch_size, timesteps, self.channels_size, self.input_size, self.input_size)\n",
    "                x = x.permute(1, 0, 2, 3, 4)\n",
    "                for i in range(timesteps):\n",
    "                    if x_cells is None:\n",
    "                        print(x[i].shape, self.init_hidden.shape)\n",
    "                        x_cells, hidden = self.gru_layer0(x[i], self.init_hidden)\n",
    "                        x_list.append(x_cells)\n",
    "                    else:\n",
    "                        x_i, hidden = self.gru_layer0(x[i], hidden)\n",
    "                        x_list.append(x_i)\n",
    "                x_cells = torch.stack(x_list)\n",
    "\n",
    "             ##### FOR LAST BATCH\n",
    "            except RuntimeError:\n",
    "                x = x.reshape(1, timesteps, self.channels_size, self.input_size, self.input_size) #last batch is (15), but batch_size = 16, #arg.timesteps = 2 \n",
    "                x = x.permute(1, 0, 2, 3, 4)\n",
    "                hidden_zero = torch.zeros_like(x)\n",
    "                for i in range(timesteps):\n",
    "                    if x_cells is None:\n",
    "                        x_cells, hidden = self.gru_layer0(x[i], hidden_zero[0])\n",
    "                        x_list.append(x_cells)\n",
    "                    else:\n",
    "                        x_i, hidden = self.gru_layer0(x[i], hidden)\n",
    "                        x_list.append(x_i)\n",
    "                x_cells = torch.stack(x_list)\n",
    "             #####\n",
    "        elif self.gru_nan == True:\n",
    "            try:\n",
    "                x = x.reshape(batch_size, timesteps, self.channels_size, self.input_size, self.input_size)\n",
    "                x = x.permute(1, 0, 2, 3, 4)\n",
    "                for i in range(timesteps):\n",
    "                    if x_cells is None:\n",
    "                        x_cells, hidden = self.gru_layer0(x[i], self.init_hidden)\n",
    "                        x_list.append(x_cells)\n",
    "                    else:\n",
    "                        x_i, hidden = self.gru_layer0(x[i], self.init_hidden)\n",
    "                        x_list.append(x_i)\n",
    "                x_cells = torch.stack((x_cells, x_i))\n",
    "            ##### FOR LAST BATCH\n",
    "            except RuntimeError:\n",
    "                x = x.reshape(1, timesteps, self.channels_size, self.input_size, self.input_size) #last batch is (15), but batch_size = 16, #arg.timesteps = 2 \n",
    "                x = x.permute(1, 0, 2, 3, 4)\n",
    "                hidden_zero = torch.zeros_like(x)\n",
    "                for i in range(timesteps):\n",
    "                    if x_cells is None:\n",
    "                        x_cells, hidden = self.gru_layer0(x[i], hidden_zero[0])\n",
    "                        x_list.append(x_cells)\n",
    "                    else:\n",
    "                        x_i, hidden = self.gru_layer0(x[i], hidden)\n",
    "                        x_list.append(x_i)\n",
    "                x_cells = torch.stack((x_cells, x_i))\n",
    "        else:\n",
    "            print('gru_nan can be only True or False')\n",
    "            quit()\n",
    "        x_cells = x_cells.reshape(-1, self.channels_size, self.input_size, self.input_size)\n",
    "\n",
    "        return x_cells  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3x3Small(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(Conv3x3Small, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_feat, out_feat,\n",
    "                                             kernel_size=3,\n",
    "                                             stride=1,\n",
    "                                             padding=1),\n",
    "                                   nn.ELU(),\n",
    "                                   nn.Dropout(p=0.2))\n",
    "\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(out_feat, out_feat,\n",
    "                                             kernel_size=3,\n",
    "                                             stride=1,\n",
    "                                             padding=1),\n",
    "                                   nn.ELU())\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "    \n",
    "class Conv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UpConcat(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(UpConcat, self).__init__()\n",
    "\n",
    "        self.up = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "\n",
    "        # self.deconv = nn.ConvTranspose2d(in_feat, out_feat,\n",
    "        #                                  kernel_size=3,\n",
    "        #                                  stride=1,\n",
    "        #                                  dilation=1)\n",
    "\n",
    "        self.deconv = nn.ConvTranspose2d(in_feat,\n",
    "                                         out_feat,\n",
    "                                         kernel_size=2,\n",
    "                                         stride=2)\n",
    "\n",
    "    def forward(self, inputs, down_outputs):\n",
    "        # TODO: Upsampling required after deconv?\n",
    "        # outputs = self.up(inputs)\n",
    "        outputs = self.deconv(inputs)\n",
    "        out = torch.cat([down_outputs, outputs], 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(UpSample, self).__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "        self.deconv = nn.ConvTranspose2d(in_feat,\n",
    "                                         out_feat,\n",
    "                                         kernel_size=2,\n",
    "                                         stride=2)\n",
    "\n",
    "    def forward(self, inputs, down_outputs):\n",
    "        # TODO: Upsampling required after deconv?\n",
    "        outputs = self.up(inputs)\n",
    "        # outputs = self.deconv(inputs)\n",
    "        out = torch.cat([outputs, down_outputs], 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetSmall(nn.Module):\n",
    "    def __init__(self, num_channels=1, num_classes=2):\n",
    "        super(UNetSmall, self).__init__()\n",
    "        num_feat = [32, 64, 128, 256]\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.down1 = nn.Sequential(DoubleConv(num_channels, num_feat[0]))\n",
    "\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                   Gru(num_feat[0], gru_input_size=64),\n",
    "                                   Conv(num_feat[0], num_feat[1]))\n",
    "\n",
    "        self.down3 = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                   Gru(num_feat[1], gru_input_size=32),\n",
    "                                   Conv(num_feat[1], num_feat[2]))\n",
    "\n",
    "        self.bottom = nn.Sequential(nn.MaxPool2d(kernel_size=2),\n",
    "                                   Gru(num_feat[2], gru_input_size=16),\n",
    "                                   Conv(num_feat[2], num_feat[3]))\n",
    "\n",
    "        self.up1 = UpSample(num_feat[3], num_feat[2])\n",
    "        self.upconv1 = nn.Sequential(Conv3x3Small(num_feat[3] + num_feat[2], num_feat[2]),\n",
    "                                     nn.BatchNorm2d(num_feat[2]))\n",
    "\n",
    "        self.up2 = UpSample(num_feat[2], num_feat[1])\n",
    "        self.upconv2 = nn.Sequential(Conv3x3Small(num_feat[2] + num_feat[1], num_feat[1]),\n",
    "                                     nn.BatchNorm2d(num_feat[1]))\n",
    "\n",
    "        self.up3 = UpSample(num_feat[1], num_feat[0])\n",
    "        self.upconv3 = nn.Sequential(Conv3x3Small(num_feat[1] + num_feat[0], num_feat[0]),\n",
    "                                     nn.BatchNorm2d(num_feat[0]))\n",
    "\n",
    "        self.final = nn.Sequential(nn.Conv2d(num_feat[0],\n",
    "                                             1,\n",
    "                                             kernel_size=1),\n",
    "                                   nn.Sigmoid())\n",
    "\n",
    "    def forward(self, inputs, return_features=False):\n",
    "        inputs = inputs.reshape(-1, 1, self.input_size, self.input_size)\n",
    "        # print(inputs.data.size())\n",
    "        down1_feat = self.down1(inputs)\n",
    "        # print(down1_feat.size())\n",
    "        down2_feat = self.down2(down1_feat)\n",
    "        # print(down2_feat.size())\n",
    "        down3_feat = self.down3(down2_feat)\n",
    "        # print(down3_feat.size())\n",
    "        bottom_feat = self.bottom(down3_feat)\n",
    "\n",
    "        # print(bottom_feat.size())\n",
    "        up1_feat = self.up1(bottom_feat, down3_feat)\n",
    "        # print(up1_feat.size())\n",
    "        up1_feat = self.upconv1(up1_feat)\n",
    "        # print(up1_feat.size())\n",
    "        up2_feat = self.up2(up1_feat, down2_feat)\n",
    "        # print(up2_feat.size())\n",
    "        up2_feat = self.upconv2(up2_feat)\n",
    "        # print(up2_feat.size())\n",
    "        up3_feat = self.up3(up2_feat, down1_feat)\n",
    "        # print(up3_feat.size())\n",
    "        up3_feat = self.upconv3(up3_feat)\n",
    "        # print(up3_feat.size())\n",
    "\n",
    "        if return_features:\n",
    "            outputs = up3_feat\n",
    "        else:\n",
    "            outputs = self.final(up3_feat)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetSmall()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    \n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "def calc_loss(prediction, target, bce_weight=0.3):\n",
    "    try:\n",
    "        prediction = prediction.reshape(timesteps*batch_size, 51, 128, 128)\n",
    "        target = target.reshape(timesteps*batch_size, 51, 128, 128)\n",
    "    except RuntimeError:\n",
    "        prediction = prediction.reshape(timesteps*15, 51, 128, 128) # last_batch = 15\n",
    "        target = target.reshape(timesteps*15, 51, 128, 128)\n",
    "    bce = F.binary_cross_entropy_with_logits(prediction, target)\n",
    "    prediction = F.sigmoid(prediction)\n",
    "    dice = lossy(prediction, target)\n",
    "\n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def lossy(x, y):\n",
    "    return (((x - y)**2).sum(dim=1)).sum()/(256**2)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(5):\n",
    "            print('*'*20)\n",
    "        print('epoch: ', epoch)\n",
    "        iou_metric = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            input, label = data\n",
    "            input = input.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(input)\n",
    "            #loss = calc_loss(output, label)\n",
    "            try:\n",
    "                loss = lossy(output.reshape(timesteps*batch_size, 1, 128, 128), \n",
    "                                  label.reshape(timesteps*batch_size, 1, 128, 128))\n",
    "            except RuntimeError:\n",
    "                loss = lossy(output.reshape(timesteps*1, 1, 128, 128), \n",
    "                                  label.reshape(timesteps*1, 1, 128, 128))      \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            print('iter: ', i, 'avg iou_metric: ', loss.item())\n",
    "        print('-'*20)\n",
    "        for i in range(5):\n",
    "            print('*'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "********************\n",
      "********************\n",
      "********************\n",
      "********************\n",
      "epoch:  0\n",
      "torch.Size([4, 32, 64, 64]) torch.Size([4, 32, 64, 64])\n",
      "torch.Size([4, 64, 32, 32]) torch.Size([4, 64, 32, 32])\n",
      "torch.Size([4, 128, 16, 16]) torch.Size([4, 128, 16, 16])\n",
      "iter:  0 avg iou_metric:  0.5659788846969604\n",
      "torch.Size([4, 32, 64, 64]) torch.Size([4, 32, 64, 64])\n",
      "torch.Size([4, 64, 32, 32]) torch.Size([4, 64, 32, 32])\n",
      "torch.Size([4, 128, 16, 16]) torch.Size([4, 128, 16, 16])\n",
      "iter:  1 avg iou_metric:  0.5509542226791382\n",
      "torch.Size([4, 32, 64, 64]) torch.Size([4, 32, 64, 64])\n",
      "torch.Size([4, 64, 32, 32]) torch.Size([4, 64, 32, 32])\n",
      "torch.Size([4, 128, 16, 16]) torch.Size([4, 128, 16, 16])\n",
      "iter:  2 avg iou_metric:  0.5391201972961426\n",
      "torch.Size([4, 32, 64, 64]) torch.Size([4, 32, 64, 64])\n",
      "torch.Size([4, 64, 32, 32]) torch.Size([4, 64, 32, 32])\n",
      "torch.Size([4, 128, 16, 16]) torch.Size([4, 128, 16, 16])\n",
      "iter:  3 avg iou_metric:  0.5311733484268188\n",
      "torch.Size([4, 32, 64, 64]) torch.Size([4, 32, 64, 64])\n",
      "torch.Size([4, 64, 32, 32]) torch.Size([4, 64, 32, 32])\n",
      "torch.Size([4, 128, 16, 16]) torch.Size([4, 128, 16, 16])\n",
      "iter:  4 avg iou_metric:  0.5270789861679077\n",
      "torch.Size([4, 32, 64, 64]) torch.Size([4, 32, 64, 64])\n",
      "torch.Size([4, 64, 32, 32]) torch.Size([4, 64, 32, 32])\n",
      "torch.Size([4, 128, 16, 16]) torch.Size([4, 128, 16, 16])\n",
      "iter:  5 avg iou_metric:  0.525498628616333\n",
      "torch.Size([4, 32, 64, 64]) torch.Size([4, 32, 64, 64])\n",
      "torch.Size([4, 64, 32, 32]) torch.Size([4, 64, 32, 32])\n",
      "torch.Size([4, 128, 16, 16]) torch.Size([4, 128, 16, 16])\n",
      "iter:  6 avg iou_metric:  0.5269098877906799\n",
      "--------------------\n",
      "********************\n",
      "********************\n",
      "********************\n",
      "********************\n",
      "********************\n",
      "********************\n",
      "********************\n",
      "********************\n",
      "********************\n",
      "********************\n",
      "epoch:  1\n",
      "torch.Size([4, 32, 64, 64]) torch.Size([4, 32, 64, 64])\n",
      "torch.Size([4, 64, 32, 32]) torch.Size([4, 64, 32, 32])\n",
      "torch.Size([4, 128, 16, 16]) torch.Size([4, 128, 16, 16])\n",
      "iter:  0 avg iou_metric:  0.5225285291671753\n",
      "torch.Size([4, 32, 64, 64]) torch.Size([4, 32, 64, 64])\n",
      "torch.Size([4, 64, 32, 32]) torch.Size([4, 64, 32, 32])\n",
      "torch.Size([4, 128, 16, 16]) torch.Size([4, 128, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
